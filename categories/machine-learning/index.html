<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Machine Learning | aiken's blog</title>
<meta name=keywords content><meta name=description content="Let's learn and innovate together!"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/categories/machine-learning/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://hugotest-phi.vercel.app/categories/machine-learning/index.xml><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/categories/machine-learning/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/categories/machine-learning/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Machine Learning"><meta property="og:description" content="Let's learn and innovate together!"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Machine Learning"><meta name=twitter:description content="Let's learn and innovate together!"></head><body class=list id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/sakana-widget@2.7.0/lib/sakana.min.css><div id=sakana-widget></div><script>function initSakanaWidget(){const e=SakanaWidget.getCharacter("chisato");e.initialState={...e.initialState,controls:!1,t:.8,i:.002,s:1,d:.999,t:.5,w:.05},e.image="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/%E5%B7%B2%E7%A7%BB%E9%99%A4%E8%83%8C%E6%99%AF%E7%9A%84Xnip2024-11-30_00-47-03.png",SakanaWidget.registerCharacter("ronSang",e),new SakanaWidget({character:"ronSang"}).mount("#sakana-widget");const t=SakanaWidget.getCharacter("chisato");t.initialState={...t.initialState,controls:!1,t:.8,i:.002,s:1,d:.999,t:.5,w:.05},t.image="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/%E5%B7%B2%E7%A7%BB%E9%99%A4%E8%83%8C%E6%99%AF%E7%9A%84Xnip2024-11-30_00-36-37.png",SakanaWidget.registerCharacter("xinxin",t),new SakanaWidget({character:"xinxin"}).mount("#sakana-widget")}</script><script async onload=initSakanaWidget() src=https://cdn.jsdmirror.com/npm/sakana-widget@2.7.0/lib/sakana.min.js></script><main class=main><header class=page-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/categories/>Categories</a></div><h1>Machine Learning
<a href=/categories/machine-learning/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover16.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>StableDiffusionWebUI鉴权设计</h2></header><section class=entry-content><p>[> [!summary]+
this article purpose is to build an authority page for stable diffusion webui using nginx & python/js. Which can publish my personal stable diffusion server. Wrote by GPT(try).
Introduction In the digital age, the security and user-friendliness of web services are not just conveniences; they are necessities. Balancing robust security protocols with an engaging user experience is key to maintaining both the integrity and popularity of any online service. This blog post dives into the intricacies of securing web services using Nginx for authentication, coupled with designing an appealing frontend. Our journey begins with a practical scenario:
publishing a stable diffusion webUI service, accessible only to an authenticated audience.
Setting Up Nginx for Secure Authentication Nginx excels in serving web pages and as a reverse proxy, providing enhanced security through authentication mechanisms. Let’s explore a typical Nginx configuration for secure authentication:
/verify_token: This block forwards authentication requests to a dedicated server. By excluding the request body and focusing on essential headers, it ensures that only valid, authenticated requests proceed. location = /verify_token {
proxy_pass http://{your_auth_server}:2424;
proxy_pass_request_body off;
proxy_set_header Content-Length "";
proxy_set_header X-Original-URI $request_uri;
proxy_set_header X-Original-Remote-Addr $remote_addr;
proxy_set_header X-Original-Host $host;
} /login: Catering to login requests, this configuration forwards the necessary details to the authentication server, preserving crucial information about the request’s origin. location /login {
proxy_pass http://{your_auth_server}:2424;
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
} Error Handling (@error401): A clever redirect mechanism that guides unauthenticated users to the login page, keeping the original URL intact. location @error401 {
return 302 {your_domain}/login;
} Root Location (/): The gateway to your service, which rigorously checks each request for authentication, granting access only to verified users. location / {
auth_request /verify_token;
error_page 401 = @error401;
proxy_pass http://{your_server}:2323/;
proxy_http_version 1.1;
proxy_set_header Upgrade $http_upgrade;
proxy_set_header Connection 'upgrade';
proxy_set_header Host $host;
proxy_cache_bypass $http_upgrade;
} This setup not only fortifies your service against unauthorized access but also maintains a seamless user experience, redirecting unauthenticated users without hassle.
...</p></section><footer class=entry-footer><span title='2024-01-27 15:42:36 +0000 UTC'>January 27, 2024</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1693 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/ai> AI</a>&nbsp;·&nbsp;<a href=/tags/aigc> AIGC</a>&nbsp;·&nbsp;<a href=/tags/web> Web</a>&nbsp;·&nbsp;<a href=/tags/flask> Flask</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/ai style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AI
</a><a href=/tags/aigc style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AIGC
</a><a href=/tags/web style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Web
</a><a href=/tags/flask style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Flask</a></div></div></div><a class=entry-link aria-label="post link to StableDiffusionWebUI鉴权设计" href=https://hugotest-phi.vercel.app/posts/stablediffusionwebui%E9%89%B4%E6%9D%83%E8%AE%BE%E8%AE%A1/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover12.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>AIGC05 Stable Diffusion Model Training</h2></header><section class=entry-content><p>该章节主要介绍 Stable-Diffusion 中模型的训练，考虑到硬件条件的限制，实际上这里介绍的训练，都是针对大模型的各种微调技术（Lora，Dreambooth，HyperNetwork, …），这里会以 LoRA 模型的训练为主。
参考文献：
AIGC教程：Stable Diffusion精进，如何训练特定画风LoRA模型？ | 游戏大观 | GameLook.com.cn stable diffusion打造自己专属的LORA模型 - 王清培 - 博客园 (cnblogs.com) sd-scripts/train_README-zh.md at main · kohya-ss/sd-scripts · GitHub Train LoRA LoRA 的优势就是其模型更小，且更加模块化；也就是说其的训练成本和要求都更低，同时使用代价小，可以作为某种风格插件或者角色插件来使用。
使用 LoRA 进行 Stable Diffusion 的高效参数微调 (huggingface.co) [2106.09685] LoRA: Low-Rank Adaptation of Large Language Models (arxiv.org) 其中蓝色的是预训练好的源网络，而橙色的是新加的网络，通过控制 R 的宽度（文章主要论证了大模型的参数可能存在较低维度的秩，因此可以使用较小的 R 来对大模型的参数造成有效的影响），可以有效的减少需要训练的网络的 Size。
事前准备 这里只介绍本地训练，训练也可以在 Colab Notebook 等在线训练集群中进行，这里就不进行介绍了
WebUI + 想训练的基础 SD 模型 .txt 带说明的文本文件 Training Repo（sd-script 、lora-script ） 数据集准备（准备好训练图像） 训练包准备 这里我们使用 lora-script 来进行模型训练，lora-script 实际上是 sd-script 之外在包了一层，新增了一些可视化的功能和一些其他的脚本，让 sd-script 更加易用，它调用 sd 中的脚本来实现训练，但是封装了一些注释和整理，此外还支持的 tensorboard 可视化。
sd-script 本身包含了训练 lora、dreambooth、text-embedding、UNet、Text Encoder、图像生成、模型转换等多种功能。lora-script 还是主要专注于 LoRA 训练
查看 repo 也能知道 lora-script 中包含了 sd-script，所以我们部署的时候只需
1 git clone --recurse-submodules https://github.com/Akegarasu/lora-scripts 即可将需要的库安装下来，然后安装环境和相关以来只需要执行 .\install.ps1 即可（该脚本有 cn 版本，但是可能会出现问题），其会安装 sd-scripts 和 lora-scripts 需要的库。具体的可以参考相关 repo（sd-script 详细说明，lora-script 有简化版说明）。
安装的时候可能会出现虚拟环境未激活的问题，我们可以提前在改目录执行一次 python -m venv venv 一次即可。
Finish.
...</p></section><footer class=entry-footer><span title='2023-05-06 23:43:41 +0000 UTC'>May 6, 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;501 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/ai> AI</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/ai style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AI</a></div></div></div><a class=entry-link aria-label="post link to AIGC05 Stable Diffusion Model Training" href=https://hugotest-phi.vercel.app/posts/stablediffusiontraining/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover2.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>AIGC04 Stable Diffusion Write Prompt Better</h2></header><section class=entry-content><p>该章节主要包括 Promot 生成和部分工作流的分析，旨在了解如何写出更好的关键词，如何生成更好的图片，当我们不知道怎么描述的时候也可以将该工作交给 ChatGPT，让其为我们攥写一般基础的提示词
Prompt 编写范式 参考资料：【Stable Diffusion】Prompt 通常编写可以遵照以下的类别进行组织，主要有 &lt;质量控制> + &lt;前置> + &lt;主体> + &lt;场景词> 几类，其中分别包括以下的几类词：
质量控制：画质、镜头效果、光照效果 前置词：画风、艺术家、风格 主体：人物&对象、姿势、服装、道具 场景：环境、背景、细节 Additional Network：载入额外模型 分割符号： 各个关键词之间用 , 分割，且对应的权重从前到后依次递减，因此在编写关键词的时候也要注意先后顺序。
权重加权符号：各种括号代表各种不同的加权系数，这里建议用 (prompt: weight) 统一来编写提示词的权重规则，整体可读性会更好。
这里的 weight 指的是权重变成原本的 weight 倍，就可以调整加强或减弱。
各个括号的默认系数如下: () -> 1.1 ; {} -> 1.05 ; [] -> 0.952 可以通过(())进行叠加即 1.1*1.1
...</p></section><footer class=entry-footer><span title='2023-04-26 21:22:38 +0000 UTC'>April 26, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;338 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/ai> AI</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/ai style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AI</a></div></div></div><a class=entry-link aria-label="post link to AIGC04 Stable Diffusion Write Prompt Better" href=https://hugotest-phi.vercel.app/posts/stablediffusionprompt/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover13.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>AIGC03 Stable Diffusion Control Net</h2></header><section class=entry-content><p>ControlNet 是 Stable Diffusion 最强力的插件之一，它能够控制 SD 的整个扩散过程，包括让 AI 参考动作/骨架/线条/景深，从而更精准的生成图片。
ControlNet 按照骨架動作繪圖 | Stable Diffusion WebUI使用手冊 骨架人偶 PoseX | Stable Diffusion WebUI 使用手冊 生成多個人物 Latent Couple | Stable Diffusion WebUI使用手冊 拓展地址：Mikubill/sd-webui-controlnet: WebUI extension for ControlNet (github.com) ControlNet 地址：lllyasviel/ControlNet: Let us control diffusion models! (github.com) 模型地址：lllyasviel/ControlNet-v1-1 at main (huggingface.co) ...</p></section><footer class=entry-footer><span title='2023-04-26 21:19:41 +0000 UTC'>April 26, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;221 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/ai> AI</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/ai style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AI</a></div></div></div><a class=entry-link aria-label="post link to AIGC03 Stable Diffusion Control Net" href=https://hugotest-phi.vercel.app/posts/stablediffusioncontrolnet/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover14.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>AIGC02 Stable Diffusion 基础功能介绍</h2></header><section class=entry-content><p>本篇章介绍关于 Stable DIffusion 的一些基础概念和 WebUI 的基本功能元素，同时介绍一些启动项和模型加载的东西。
启动项设置（局域网） 最常用的启动项是 --listen，通过该启动项允许局域网内的其他设备通过 ip 和端口访问部署好的 Stable Diffusion 服务。而设置启动项的方式有以下几种：
命令行执行启动脚本的时候携带 1 2 ./webui.bat --listen # ./webui.sh --listen 修改主入口脚本中的启动选项 vim launch.py 1 2 3 # 修改下面这一行的参数, 将" "中填入需要的参数 # commandline_args = os.environ.get('COMMANDLINE_ARGS', "") commandline_args = os.environ.get('COMMANDLINE_ARGS', "--listen") 其他的启动项介绍可以参考：2.3. 命令列引數 | Stable Diffusion WebUI使用手冊(正體中文)｜Ivon的部落格 (ivonblog.com) ...</p></section><footer class=entry-footer><span title='2023-04-26 11:03:56 +0000 UTC'>April 26, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;355 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/ai> AI</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/ai style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AI</a></div></div></div><a class=entry-link aria-label="post link to AIGC02 Stable Diffusion 基础功能介绍" href=https://hugotest-phi.vercel.app/posts/stable-diffusion-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover10.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>AIGC01 Stable Diffusion and midjourney Setup</h2></header><section class=entry-content><p>This Chapter introduce how to set up stable diffusion and mid-journey, and record some problem I meet when I deploy it.
(Deprecated) midjourney 由于 midjourney 现需要付费使用，同时没有开源，因此我们讲一笔带过该部分内容，该部分内容大多转载于 超详细！AI 绘画神器 Midjourney 基础使用手册 midjourney 的安装步骤主要分成以下的几步：
点击 Join the Beta 注册账号，注册完会跳转到； Discord 首页，亲自创建自己的服务器，仅供我和我的朋友使用； 下载客户端，在默认对话界面讯在或开始新的对话，输入 Midjourney Bot，添加到服务器 付费开启体验。 (Deprecated) DreamStudio 说是可以本地部署，但是实际体验非常不好，应该只是部署了 Webui，然后调用官方提供的免费 API；所以有时候生成不出来，但是又不报错，不知道是不是使用姿势有问题，反正很屎。
https://github.com/Stability-AI/StableStudio 装好 npm 和 yarn 参考 quick start，git clone -> (cd) yarn 安装 -> yarn dev 部署在本地端口上。 官网注册账号-> 获取 API -> 填入并在最上方转到 Generate 页面即可。 Stable Diffusion 部署专题 该部分作为 Intro，仅介绍 Stable Diffusion 的安装和部署，以及一些启用参数等，具体的使用在后面的文章进行进一步的讲解。
...</p></section><footer class=entry-footer><span title='2023-04-19 16:00:00 +0000 UTC'>April 19, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;329 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/ai> AI</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/ai style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#AI</a></div></div></div><a class=entry-link aria-label="post link to AIGC01 Stable Diffusion and midjourney Setup" href=https://hugotest-phi.vercel.app/posts/stable-diffusion/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover10.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Fine Tuning</h2></header><section class=entry-content><p>@Langs: python, torch @reference: d2l-pytorch，transfer_torch This Note focus on the code part. 模型微调和模型预训练，在Pytorch中的使用方式对比汇总。
How to Design the Fine Tune 这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。
基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。
在Transfer任务中，有几种不同的调整方式：
固定Bakcbone，只训练Classifier 同步微调网络 区分学习率，微调Backbone，训练Classifirer 为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。
Code Part 不同lr设置 微调Backbone，训练Classifier作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。
相关的文档可以参考：torch.optim 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # get dataset train_img = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train')) # get new model pretrained_new = model.expand_dim(dim=out_dim,re_init=True) # pre train it 定义一个用于微调的函数 # pytorch可以通过字典的形式来区分对设置lr def train_fine_tuning(net, learning_rate, batch_size=128, num_epoch=5, diff_lr=True): # set dataloader train_iter = torch.utils.Dataloader(train_img, batch_size=batch_size, shuffle=True) test_iter = ... # set loss loss = nn.CrossEntropyLoss(reduction='none') # set diff lr for diff part of it if diff_lr: params_1x = [param for name, param in net.name_parameters() if name not in ["fc.weight", "fc.bias"]] trainer = torch.optim.SGD([{'params': params_1x}, {'params': net.fc.parameters(), 'lr': learning_rate *10}], lr=learning_rate, weight_decay=0.001 ) else: trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001) 同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试
...</p></section><footer class=entry-footer><span title='2022-02-08 14:31:37 +0000 UTC'>February 8, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;281 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/pytorch> Pytorch</a>&nbsp;·&nbsp;<a href=/tags/fine-tune> Fine-Tune</a>&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/pytorch style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Pytorch
</a><a href=/tags/fine-tune style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Fine-Tune
</a><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning</a></div></div></div><a class=entry-link aria-label="post link to Fine Tuning" href=https://hugotest-phi.vercel.app/posts/finetune/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover9.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>IL Collection</h2></header><section class=entry-content><p>@AikenHong 2022
[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.
In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure. 在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发
DER SPPR 没有 get 到方法到底是怎么做的 Introduction 👿 在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。
Incremental 的基本过程可以表示如下[4]： ...</p></section><footer class=entry-footer><span title='2022-01-04 01:38:04 +0000 UTC'>January 4, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;984 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/incremental-learning> Incremental Learning</a>&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/incremental-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Incremental Learning
</a><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/survey style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Survey</a></div></div></div><a class=entry-link aria-label="post link to IL Collection" href=https://hugotest-phi.vercel.app/posts/il-collection/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover2.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>WYZ-IL-Collection</h2></header><section class=entry-content><p>: hammer: 王耀智
Regularization 系列方法 这类方法旨在添加一些正则化损失来解决 catastrophic forgetting 的问题。
Weight Regularization 这类方法一般是对网络中每个参数的重要性进行评估，根据每个参数的重要性和梯度信息更新参数。
典型的文章为 EWC .
PS: 这类文章我也没有读过。
Data Regularization 这类方法专注于记住特征表示，通常是结合 Hinton 的知识蒸馏损失函数使得模型记住旧类别的知识，解决 catastrophic forgetting。
推荐以下几篇文章：
LwF(Learning without forgetting)，这篇文章在我看来是增量学习的开山之作，第一次给增量学习找到了一个比较好的方向，也是第一次将知识蒸馏应用到增量学习上； PODNet CVPR2020 ，这篇文章最大的贡献在我看来是设计了一个全新的蒸馏损失函数，最终结果也是达到了当时的sota，甚至目前也是几个榜单的sota。 Rehearsal 系列方法 这类方法主要的想法是使用一些旧类别的数据，在新类别到来时使用新旧数据一起训练模型，根据旧类别数据的真假分为以下两种方法。
Pseudo rehearsal 这类方法通常是在学习旧类别的同时，训练一个生成模型，可以生成旧的类别数据，在新类别数据到来时，生成相当数量的旧类别数据，一起训练新模型。
这里推荐一篇文章：Continual learning with deep generative replay。
PS：这个小类别的论文我也没有太关注，个人不是很推荐这类方法。
Save real data 这类方法是开辟一个内存空间，空间中保存旧类别的少部分训练数据，在新类别到来时，使用内存空间的数据与新数据共同学习，按照对空间的使用方法不同可分为：
Exemplar Rehearsal 这类方法是将新旧数据混合，共同作为训练数据，一起训练模型，使得模型能够保持旧类别的知识。
但是在训练过程中新旧数据的类别数量是不均衡的，这也催生了我下面会说到的一大类解决方法。
这种方法推荐的论文是 iCaRL，这篇论文是 exemplar rehearsal 的开山之作，第一次提出了内存空间这个概念，也提出了一个非常有效的内存选择策略(herb)，并且也是第一个使用特征作为分类依据的方法，我个人认为是继 LwF 之后又一个将 IL 推到一个新的高度的方法。
Gradient Rectification 这类方法我称之为 Gradient Rectification，其主要思路是模型每次更新的梯度由 shared gradient 和 task-specific gradient 组成。分别代表所有类别的共性信息和某一个类别的特性信息，在新类别学习时借助内存空间中的数据获得旧类别的两项梯度，在更新时对梯度进行修正，力求做到不增加共享梯度代表的损失，尽量减少类别特定梯度代表的损失。
...</p></section><footer class=entry-footer><span title='2022-01-03 10:41:56 +0000 UTC'>January 3, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;154 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/incremental-learning> Incremental Learning</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/incremental-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Incremental Learning
</a><a href=/tags/survey style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Survey</a></div></div></div><a class=entry-link aria-label="post link to WYZ-IL-Collection" href=https://hugotest-phi.vercel.app/posts/il-wyz/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover0.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>LT Collection</h2></header><section class=entry-content><p>LT-Collections @AikenHong 2021
Code of must of those methods We will analysis those tricks on LT situation, and Analysis why it works. 在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。
其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps
Introduction 通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合
首先介绍 bag of tricks 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick
经过该文实验总结，Trick组合应该是[1]`：
在前几个epoch应用input mixup数据增强，然后后面fine-tuning; (基于CAM的)重采样来重新训练分类器; 实际上就是MixUp + Two-Stage的策略，后续对Mix-up这个策略带来的作用要进行补充了解一下
Rebalance 对于ReBalance的方法，实际上就是从 data和 update两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。
...</p></section><footer class=entry-footer><span title='2021-12-22 14:36:16 +0000 UTC'>December 22, 2021</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;690 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;·&nbsp;<a href=/tags/long-tailed-learning> Long-Tailed Learning</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/survey style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Survey
</a><a href=/tags/long-tailed-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Long-Tailed Learning</a></div></div></div><a class=entry-link aria-label="post link to LT Collection" href=https://hugotest-phi.vercel.app/posts/lt-collection/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://hugotest-phi.vercel.app/categories/machine-learning/page/2/>Next&nbsp;2/5&nbsp;»
</a><a class=last-icon href=https://hugotest-phi.vercel.app/categories/machine-learning/page/5/><span>>></span></a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>