<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Long-Tailed Learning on aiken&#39;s blog</title>
    <link>https://aikenh.cn/hugotest/tags/long-tailed-learning/</link>
    <description>Recent content in Long-Tailed Learning on aiken&#39;s blog</description>
    <generator>Hugo -- 0.137.0</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Dec 2021 14:36:16 +0000</lastBuildDate>
    <atom:link href="https://aikenh.cn/hugotest/tags/long-tailed-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LT Collection</title>
      <link>https://aikenh.cn/hugotest/posts/lt-collection/</link>
      <pubDate>Wed, 22 Dec 2021 14:36:16 +0000</pubDate>
      <guid>https://aikenh.cn/hugotest/posts/lt-collection/</guid>
      <description>&lt;h1 id=&#34;lt-collections&#34;&gt;LT-Collections&lt;/h1&gt;
&lt;p&gt;@AikenHong 2021&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mitming/OpenLT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code of must of those methods&lt;/a&gt;

We will analysis those tricks on LT situation, and Analysis why it works.
在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。&lt;/p&gt;
&lt;p&gt;其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;
&lt;div class=&#34;post-img-view&#34;&gt;
  &lt;a data-fancybox=&#34;gallery&#34; href=&#34;https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png&#34;&gt;
    &lt;img alt=&#34;LT&#34; loading=&#34;lazy&#34; src=&#34;https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png&#34;class=&#34;responsive-image&#34; src=&#34;https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png&#34; style=&#34;display: block; margin: 0 auto;&#34;
      alt=&#34;LT&#34;  /&gt;
  &lt;/a&gt;
&lt;/div&gt;


&lt;script&gt;
  document.addEventListener(&#34;DOMContentLoaded&#34;, function() {
      var images = document.querySelectorAll(&#34;.responsive-image&#34;);
      var maxHeight = window.innerHeight / 2.5;
      images.forEach(function(image) {
          image.style.maxHeight = maxHeight + &#34;px&#34;;
      });
  });
&lt;/script&gt;

通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合&lt;/p&gt;
&lt;p&gt;首先介绍 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/416315017&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bag of tricks&lt;/a&gt;
 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick&lt;/p&gt;
&lt;p&gt;经过该文实验总结，Trick组合应该是&lt;sub&gt;[1]`&lt;/sub&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在前几个epoch应用input mixup数据增强，然后后面fine-tuning;&lt;/li&gt;
&lt;li&gt;(基于CAM的)重采样来重新训练分类器;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实际上就是MixUp + Two-Stage的策略，后续对&lt;strong&gt;Mix-up&lt;/strong&gt;这个策略带来的作用要进行补充了解一下&lt;/p&gt;
&lt;h2 id=&#34;rebalance&#34;&gt;Rebalance&lt;/h2&gt;
&lt;!-- more --&gt;
&lt;p&gt;对于ReBalance的方法，实际上就是从 &lt;code&gt;data&lt;/code&gt;和 &lt;code&gt;update&lt;/code&gt;两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
