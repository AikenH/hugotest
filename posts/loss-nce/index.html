<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Loss-NCE | aiken's blog</title>
<meta name=keywords content="Machine Learning,Loss"><meta name=description content='@AikenHong 2021
Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples.
该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。
What&rsquo;s NCE Loss
在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）
首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上j==gt的情况下外层+log也就是ceLoss，也就是 $logSoftmax$

$$ 
S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}
 $$

然后看infoNCE，基础的对比学习损失可以写成：

$$ 
L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]
 $$

其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.
分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。
从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。

但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。

How it Works
NCE的思想是拉近相似的样本，推开不相近的样本，从而学习到一个好的语义表示空间，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。
考虑之前人脸匹配的研究，使用 &ldquo;Alignment and Uniformity on the Hypersphere"中的Alignment and Uniformity，就是一个更好理解他的角度


$$ 
\begin{gathered}
L_{\text {contrast }}=\mathbb{E}\left[-\log \frac{e^{f_{x}^{T} f_{y} / \tau}}{e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \tau}}\right] \\
=\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]+\mathbb{E}\left[\log \left(e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \tau}}\right)\right] \\
\mathbb{P}\left[\left(f_{x}=f_{y}\right)\right]=1 \underbrace{\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]}_{\text {positive alignment }}+\underbrace{\mathbb{E}\left[\log \left(e^{1 / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \tau}\right)\right]}_{\text {uniformity }}
\end{gathered}
 $$

公式经过上面的推导就可以看成下的两个部分，其中alignment只与positive pair有关，相反Uniformity只与negative pair相关，希望所有的点都能尽可能的分布在uni hypersphere上。'><meta name=author content="aikenhong"><link rel=canonical href=https://aikenh.cn/hugotest/posts/loss-nce/><link crossorigin=anonymous href=/hugotest/assets/css/stylesheet.2f85ca17c12c62fa86b1e474b8a51aca4856f0d645debfe4922a4d5ddc6aa978.css integrity="sha256-L4XKF8EsYvqGseR0uKUaykhW8NZF3r/kkipNXdxqqXg=" rel="preload stylesheet" as=style><link rel=icon href=https://aikenh.cn/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://aikenh.cn/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://aikenh.cn/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://aikenh.cn/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://aikenh.cn/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://aikenh.cn/hugotest/posts/loss-nce/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://aikenh.cn/hugotest/posts/loss-nce/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Loss-NCE"><meta property="og:description" content='@AikenHong 2021
Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples. 该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。
What’s NCE Loss 在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）
首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上j==gt的情况下外层+log也就是ceLoss，也就是 $logSoftmax$
$$ S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}$$然后看infoNCE，基础的对比学习损失可以写成：
$$ L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]$$其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.
分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。
从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。
但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。
How it Works NCE的思想是拉近相似的样本，推开不相近的样本，从而学习到一个好的语义表示空间，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。
考虑之前人脸匹配的研究，使用 “Alignment and Uniformity on the Hypersphere"中的Alignment and Uniformity，就是一个更好理解他的角度
$$ \begin{gathered}L_{\text {contrast }}=\mathbb{E}\left[-\log \frac{e^{f_{x}^{T} f_{y} / \tau}}{e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \tau}}\right] \\=\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]+\mathbb{E}\left[\log \left(e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \tau}}\right)\right] \\\mathbb{P}\left[\left(f_{x}=f_{y}\right)\right]=1 \underbrace{\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]}_{\text {positive alignment }}+\underbrace{\mathbb{E}\left[\log \left(e^{1 / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \tau}\right)\right]}_{\text {uniformity }}\end{gathered}$$公式经过上面的推导就可以看成下的两个部分，其中alignment只与positive pair有关，相反Uniformity只与negative pair相关，希望所有的点都能尽可能的分布在uni hypersphere上。'><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-22T13:39:55+00:00"><meta property="article:modified_time" content="2021-12-22T13:39:55+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Loss"><meta property="og:image" content="https://aikenh.cn/cover/cover8.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://aikenh.cn/cover/cover8.jpeg"><meta name=twitter:title content="Loss-NCE"><meta name=twitter:description content='@AikenHong 2021
Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples.
该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。
What&rsquo;s NCE Loss
在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）
首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上j==gt的情况下外层+log也就是ceLoss，也就是 $logSoftmax$

$$ 
S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}
 $$

然后看infoNCE，基础的对比学习损失可以写成：

$$ 
L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]
 $$

其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.
分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。
从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。

但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。

How it Works
NCE的思想是拉近相似的样本，推开不相近的样本，从而学习到一个好的语义表示空间，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。
考虑之前人脸匹配的研究，使用 &ldquo;Alignment and Uniformity on the Hypersphere"中的Alignment and Uniformity，就是一个更好理解他的角度


$$ 
\begin{gathered}
L_{\text {contrast }}=\mathbb{E}\left[-\log \frac{e^{f_{x}^{T} f_{y} / \tau}}{e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \tau}}\right] \\
=\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]+\mathbb{E}\left[\log \left(e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \tau}}\right)\right] \\
\mathbb{P}\left[\left(f_{x}=f_{y}\right)\right]=1 \underbrace{\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]}_{\text {positive alignment }}+\underbrace{\mathbb{E}\left[\log \left(e^{1 / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \tau}\right)\right]}_{\text {uniformity }}
\end{gathered}
 $$

公式经过上面的推导就可以看成下的两个部分，其中alignment只与positive pair有关，相反Uniformity只与negative pair相关，希望所有的点都能尽可能的分布在uni hypersphere上。'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://aikenh.cn/hugotest/posts/"},{"@type":"ListItem","position":2,"name":"Loss-NCE","item":"https://aikenh.cn/hugotest/posts/loss-nce/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Loss-NCE","name":"Loss-NCE","description":"@AikenHong 2021\nNoise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples. 该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。\nWhat\u0026rsquo;s NCE Loss 在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）\n首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上j==gt的情况下外层+log也就是ceLoss，也就是 $logSoftmax$\n$$ S_j = \\frac{e^{a_j}}{\\sum_{k=1}^N e^{a_k}}\r$$\r然后看infoNCE，基础的对比学习损失可以写成：\n$$ L_{contrast} = \\mathbb{E}[-\\log\\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \\sum_i e^{f_x^T f_{y_-^i}/T}}]\r$$\r其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.\n分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。\n从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。\n但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。\nHow it Works NCE的思想是拉近相似的样本，推开不相近的样本，从而学习到一个好的语义表示空间，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。\n考虑之前人脸匹配的研究，使用 \u0026ldquo;Alignment and Uniformity on the Hypersphere\u0026quot;中的Alignment and Uniformity，就是一个更好理解他的角度\n$$ \\begin{gathered}\rL_{\\text {contrast }}=\\mathbb{E}\\left[-\\log \\frac{e^{f_{x}^{T} f_{y} / \\tau}}{e^{f_{x}^{T} f_{y} / \\tau}+\\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \\tau}}\\right] \\\\\r=\\mathbb{E}\\left[-f_{x}^{T} f_{y} / \\tau\\right]+\\mathbb{E}\\left[\\log \\left(e^{f_{x}^{T} f_{y} / \\tau}+\\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \\tau}}\\right)\\right] \\\\\r\\mathbb{P}\\left[\\left(f_{x}=f_{y}\\right)\\right]=1 \\underbrace{\\mathbb{E}\\left[-f_{x}^{T} f_{y} / \\tau\\right]}_{\\text {positive alignment }}+\\underbrace{\\mathbb{E}\\left[\\log \\left(e^{1 / \\tau}+\\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \\tau}\\right)\\right]}_{\\text {uniformity }}\r\\end{gathered}\r$$\r公式经过上面的推导就可以看成下的两个部分，其中alignment只与positive pair有关，相反Uniformity只与negative pair相关，希望所有的点都能尽可能的分布在uni hypersphere上。\n","keywords":["Machine Learning","Loss"],"articleBody":"@AikenHong 2021\nNoise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples. 该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。\nWhat’s NCE Loss 在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）\n首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上j==gt的情况下外层+log也就是ceLoss，也就是 $logSoftmax$\n$$ S_j = \\frac{e^{a_j}}{\\sum_{k=1}^N e^{a_k}}\r$$\r然后看infoNCE，基础的对比学习损失可以写成：\n$$ L_{contrast} = \\mathbb{E}[-\\log\\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \\sum_i e^{f_x^T f_{y_-^i}/T}}]\r$$\r其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.\n分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。\n从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。\n但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。\nHow it Works NCE的思想是拉近相似的样本，推开不相近的样本，从而学习到一个好的语义表示空间，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。\n考虑之前人脸匹配的研究，使用 “Alignment and Uniformity on the Hypersphere\"中的Alignment and Uniformity，就是一个更好理解他的角度\n$$ \\begin{gathered}\rL_{\\text {contrast }}=\\mathbb{E}\\left[-\\log \\frac{e^{f_{x}^{T} f_{y} / \\tau}}{e^{f_{x}^{T} f_{y} / \\tau}+\\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \\tau}}\\right] \\\\\r=\\mathbb{E}\\left[-f_{x}^{T} f_{y} / \\tau\\right]+\\mathbb{E}\\left[\\log \\left(e^{f_{x}^{T} f_{y} / \\tau}+\\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \\tau}}\\right)\\right] \\\\\r\\mathbb{P}\\left[\\left(f_{x}=f_{y}\\right)\\right]=1 \\underbrace{\\mathbb{E}\\left[-f_{x}^{T} f_{y} / \\tau\\right]}_{\\text {positive alignment }}+\\underbrace{\\mathbb{E}\\left[\\log \\left(e^{1 / \\tau}+\\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \\tau}\\right)\\right]}_{\\text {uniformity }}\r\\end{gathered}\r$$\r公式经过上面的推导就可以看成下的两个部分，其中alignment只与positive pair有关，相反Uniformity只与negative pair相关，希望所有的点都能尽可能的分布在uni hypersphere上。\n这样均匀的分布有利于聚类并且线性可分，且经过实验证实无监督对比学习确实能得到强判别力的特征。\nAlignment：指的是相似的例子，也就是正例，映射到单位超球面后，应该有接近的特征，也就是在超球面上距离比较近；\nUniformity：指的是系统应该倾向于在特征里保留尽可能多的信息，这等价于使得映射到单位超球面的特征，尽可能均匀的分布在球面上，分布的越均匀，意味着保留的信息越充分。分布均匀意味着两两有差异，也意味着各自保有独有信息，这代表信息保留充分。\n参考Label Smooth中Soft Label的定义，当我们将特征拉到超球面上均匀分布的时候，特征之间相对的距离关系，远近是否应该保留真实分布中的相似性和度量分布？NCE Loss是否能保留这种关系呢？\n这种额外的Info可能能够对于后续的蒸馏学习有一个比较大的影响\nWith Self-Supervised Learning 自监督学习最重要的就是下游任务的设计，一般分成两种：\n生成式模型：Encode-Decode架构，让输入输出尽可能的相似，或者是后续进化的MIM架构，挖空并还原空中的内容，并在Transformer架构中取代判别式模型方法称为主流。 判别式模型：通过Encoder编码，通过对比学习分析相似性来建立对比损失，自从MoCo出来后判别式模型在一定时间内成为主流。 避免退化解形成 InfoNCE的两部分在理论上是缺一不可的，如果没有Alignment，就无法聚类，如果没有Uniformly，容易使得所有的输入输出又相同的表示，也就是形成退化解。\n参考 Article 对几种自监督的方法解决退化解的方式进行了简要的分析。\n实验中的设置问题 zhihu 对比学习中一般选择一个batch中的其他样本作为负例，如果负例中又很相似的样本怎么办？\n在无监督无标注的情况下，这样的伪负例，其实是不可避免的，首先可以想到的方式是去扩大语料库，去加大batch size，以降低batch训练中采样到伪负例的概率，减少它的影响。\n另外，神经网络是有一定容错能力的，像伪标签方法就是一个很好的印证，但前提是错误标签数据或伪负例占较小的比例。\n也可以考虑使用监督的对比学习方法\n对比学习的infoNCE loss 中的温度系数t的作用是什么？[1]\n温度系数的作用是调节对困难样本的关注程度：越小的温度系数越关注于将本样本和最相似的困难样本分开，去得到更均匀的表示。然而困难样本往往是与本样本相似程度较高的，很多困难负样本其实是潜在的正样本，过分强迫与困难样本分开会破坏学到的潜在语义结构，因此，温度系数不能过小 考虑两个极端情况，温度系数趋向于0时，对比损失退化为只关注最困难的负样本的损失函数；当温度系数趋向于无穷大时，对比损失对所有负样本都一视同仁，失去了困难样本关注的特性。\n也可以用另一个角度理解：\n可以把不同的负样本想像成同极点电荷在不同距离处的受力情况，距离越近的点电荷受到的库伦斥力更大，而距离越远的点电荷受到的斥力越小。 对比损失中，越近的负例受到的斥力越大，具体的表现就是对应的负梯度值越大[4]。这种性质更有利于形成在超球面均匀分布的特征。\n对照公式去理解：\n$$ L_{i}=-\\log \\left(e^{S\\left(z_{i}, z_{i}^{+}\\right) / \\tau} / \\sum_{j=0}^{K} e^{S\\left(z_{i}, _{j}\\right) / \\tau}\\right)\r$$\r当温度系数很小时，越相似也即越困难的负例，对应的坟墓就会越大，在分母叠加项中所占的比重就会越大，对整体loss的影响就会越大，具体的表现就是对应的负梯度值越大\n当然，这仅仅是提供了一种定性的认识，定量的认识和推导可以参见博客zhihu with supervised learning ZHIHU 借鉴了contrastive的设计在监督信息的基础上对其进行改造，设计一个用于监督学习的对比损失。这一点也可以解决我们问题设置中的第一个问题，但是为此也只能在监督的情况下使用。\n$$ \\mathcal{L}_{i}^{s u p}=\\frac{-1}{2 N_{\\tilde{y}_{i}}-1} \\sum_{j=1}^{2 N} 1_{i \\neq j} \\cdot 1_{\\bar{y}_{i}=\\bar{y}_{j}} \\cdot \\log \\frac{\\exp \\left(z_{i} \\cdot z_{j} / \\tau\\right)}{\\sum_{k=1}^{2 N} 1_{i \\neq k} \\cdot \\exp \\left(z_{i} \\cdot z_{k} / \\tau\\right)}\r$$\r其实也就是当标签相同的时候都当作正例，其他时候都是负例，也就是修改了原本状态下positive的情况。\n在训练的过程中，该方法和two-stage会使用同样的策略，也就是在第一阶段使用SCL训练Backbone，在第二阶段固定representation的参数，并只对clf的参数进行训练。\nCode Part understand the code ；Offical Code ；\n如果我们需要理解这串代码如何使用，我们需要阅读官方源码中的数据使用模式，我们需要使用图像的两组不同增强，计算对应的特征，然后整合到n_views维度，再将其传入该损失。 后续我们可以基于NXTent Loss函数来简化和改写该损失，目前我们只需要对其加入Normalization就可以暂时进行使用了，第一步我们使用大的batchsize来代替2Augs，如果效果不好的话可以测试2Augs是否会有更好的增益 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 import torch import torch.nn as nn class SupConLoss(nn.Module): \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf. It also supports the unsupervised contrastive loss in SimCLR\"\"\" def __init__(self, temperature=0.07, contrast_mode='all', base_temperature=0.07): super(SupConLoss, self).__init__() self.temperature = temperature self.contrast_mode = contrast_mode self.base_temperature = base_temperature def forward(self, features, labels=None, mask=None): \"\"\"Compute loss for model. If both `labels` and `mask` are None, it degenerates to SimCLR unsupervised loss: https://arxiv.org/pdf/2002.05709.pdf Args: features: hidden vector of shape [bsz, n_views, ...]. labels: ground truth of shape [bsz]. mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j has the same class as sample i. Can be asymmetric. Returns: A loss scalar. \"\"\" device = (torch.device('cuda') if features.is_cuda else torch.device('cpu')) if len(features.shape) \u003c 3: raise ValueError('`features` needs to be [bsz, n_views, ...],' 'at least 3 dimensions are required') if len(features.shape) \u003e 3: features = features.view(features.shape[0], features.shape[1], -1) batch_size = features.shape[0] if labels is not None and mask is not None: raise ValueError('Cannot define both `labels` and `mask`') elif labels is None and mask is None: mask = torch.eye(batch_size, dtype=torch.float32).to(device) elif labels is not None: labels = labels.contiguous().view(-1, 1) if labels.shape[0] != batch_size: raise ValueError('Num of labels does not match num of features') mask = torch.eq(labels, labels.T).float().to(device) else: mask = mask.float().to(device) contrast_count = features.shape[1] contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0) if self.contrast_mode == 'one': anchor_feature = features[:, 0] anchor_count = 1 elif self.contrast_mode == 'all': anchor_feature = contrast_feature anchor_count = contrast_count else: raise ValueError('Unknown mode: {}'.format(self.contrast_mode)) # compute logits anchor_dot_contrast = torch.div( torch.matmul(anchor_feature, contrast_feature.T), self.temperature) # for numerical stability logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True) logits = anchor_dot_contrast - logits_max.detach() # tile mask mask = mask.repeat(anchor_count, contrast_count) # mask-out self-contrast cases logits_mask = torch.scatter( torch.ones_like(mask), 1, torch.arange(batch_size * anchor_count).view(-1, 1).to(device), 0 ) mask = mask * logits_mask # compute log_prob exp_logits = torch.exp(logits) * logits_mask log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True)) # compute mean of log-likelihood over positive mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1) # loss loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos loss = loss.view(anchor_count, batch_size).mean() return loss with ArcFace 对比学习损失我们知道其目的是为了，拉近相似样本之间的距离，并尽量的将不同的类别之间的样本区分，而这和进行人脸识别中的 $ArcFace Loss$ 系列的Softmax Loss有着相同的目的。\n那么这两种方法之间是否能够相互借鉴，或者说是否NCE本身在自监督学习任务上就更优于ArcFace?（是否会过度关注细节，无法关注到相应的整体架构） 或者说在后续的分类器训练过程中，这样是否能够帮助我们使用聚类的方式进行分类？（结合epoch-control的那种方法）进行fine-tuning等等\nreference “Understanding the Behaviour of Contrastive Loss” CVPR2021 Analysis The InfoNCE-Loss ","wordCount":"655","inLanguage":"en","image":"https://aikenh.cn/cover/cover8.jpeg","datePublished":"2021-12-22T13:39:55Z","dateModified":"2021-12-22T13:39:55Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://aikenh.cn/hugotest/posts/loss-nce/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://aikenh.cn/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://aikenh.cn/hugotest/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://aikenh.cn/hugotest/ title=home><span>home</span></a></li><li><a href=https://aikenh.cn/hugotest/posts/ title=posts><span>posts</span></a></li><li><a href=https://aikenh.cn/hugotest/tags/ title=tags><span>tags</span></a></li><li><a href=https://aikenh.cn/hugotest/categories/ title=categories><span>categories</span></a></li><li><a href=https://aikenh.cn/hugotest/archives/ title=archives><span>archives</span></a></li><li><a href=https://aikenh.cn/hugotest/about/ title=about><span>about</span></a></li><li><a href=https://aikenh.cn/hugotest/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://aikenh.cn/hugotest/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://aikenh.cn/hugotest/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://aikenh.cn/hugotest/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://aikenh.cn/hugotest/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://aikenh.cn/hugotest/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://aikenh.cn/hugotest/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://aikenh.cn/hugotest/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://aikenh.cn/hugotest/>Home</a>&nbsp;»&nbsp;<a href=https://aikenh.cn/hugotest/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Loss-NCE</h1><div class=post-meta><span title='2021-12-22 13:39:55 +0000 UTC'>December 22, 2021</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;655 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/loss> Loss</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/Loss-NCE.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://aikenh.cn/cover/cover8.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#whats-nce-loss aria-label="What&rsquo;s NCE Loss">What&rsquo;s NCE Loss</a></li><li><a href=#how-it-works aria-label="How it Works">How it Works</a></li><li><a href=#with-self-supervised-learning aria-label="With Self-Supervised Learning">With Self-Supervised Learning</a><ul class=header-level-2><li><a href=#%e9%81%bf%e5%85%8d%e9%80%80%e5%8c%96%e8%a7%a3%e5%bd%a2%e6%88%90 aria-label=避免退化解形成>避免退化解形成</a></li><li><a href=#%e5%ae%9e%e9%aa%8c%e4%b8%ad%e7%9a%84%e8%ae%be%e7%bd%ae%e9%97%ae%e9%a2%98 aria-label=实验中的设置问题>实验中的设置问题</a></li></ul></li><li><a href=#with-supervised-learning aria-label="with supervised learning">with supervised learning</a><ul class=header-level-3><ul class=header-level-3><li><a href=#code-part aria-label="Code Part">Code Part</a></li></ul></ul></li><li><a href=#with-arcface aria-label="with ArcFace">with ArcFace</a></li><li><a href=#reference aria-label=reference>reference</a></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>@AikenHong 2021</p><p>Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples.
该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。</p><h2 id=whats-nce-loss>What&rsquo;s NCE Loss<a hidden class=anchor aria-hidden=true href=#whats-nce-loss>#</a></h2><p>在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）</p><p>首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上<code>j==gt</code>的情况下外层+log也就是ceLoss，也就是 $logSoftmax$</p><div>$$
S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}
$$</div><p>然后看infoNCE，基础的对比学习损失可以写成：</p><div>$$
L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]
$$</div><p>其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.</p><p>分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。</p><p>从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。</p><blockquote><p>但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。</p></blockquote><h2 id=how-it-works>How it Works<a hidden class=anchor aria-hidden=true href=#how-it-works>#</a></h2><p>NCE的思想是<strong>拉近相似的样本，推开不相近的样本</strong>，从而学习到一个好的<strong>语义表示空间</strong>，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。</p><p>考虑之前人脸匹配的研究，使用 &ldquo;Alignment and Uniformity on the Hypersphere"中的Alignment and Uniformity，就是一个更好理解他的角度</p><div>$$
\begin{gathered}
L_{\text {contrast }}=\mathbb{E}\left[-\log \frac{e^{f_{x}^{T} f_{y} / \tau}}{e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \tau}}\right] \\
=\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]+\mathbb{E}\left[\log \left(e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \tau}}\right)\right] \\
\mathbb{P}\left[\left(f_{x}=f_{y}\right)\right]=1 \underbrace{\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]}_{\text {positive alignment }}+\underbrace{\mathbb{E}\left[\log \left(e^{1 / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \tau}\right)\right]}_{\text {uniformity }}
\end{gathered}
$$</div><p>公式经过上面的推导就可以看成下的两个部分，其中<strong>alignment</strong>只与<strong>positive pair</strong>有关，相反<strong>Uniformity</strong>只与<strong>negative pair</strong>相关，希望所有的点都能尽可能的分布在uni hypersphere上。</p><p>这样均匀的分布有利于聚类并且线性可分，且经过实验证实无监督对比学习确实能得到强判别力的特征。</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217113936.png><img alt=NCE loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217113936.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217113936.png style="display:block;margin:0 auto" alt=NCE></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>Alignment：指的是相似的例子，也就是正例，映射到单位超球面后，应该有接近的特征，也就是在超球面上距离比较近；</p><p>Uniformity：指的是系统应该倾向于在特征里保留尽可能多的信息，这等价于使得映射到单位超球面的特征，尽可能均匀的分布在球面上，分布的越均匀，意味着保留的信息越充分。分布均匀意味着两两有差异，也意味着各自保有独有信息，这代表信息保留充分。</p><blockquote><p>参考Label Smooth中Soft Label的定义，当我们将特征拉到超球面上均匀分布的时候，特征之间相对的距离关系，远近是否应该保留真实分布中的相似性和度量分布？NCE Loss是否能保留这种关系呢？</p></blockquote><p><em>这种额外的Info可能能够对于后续的蒸馏学习有一个比较大的影响</em></p><h2 id=with-self-supervised-learning>With Self-Supervised Learning<a hidden class=anchor aria-hidden=true href=#with-self-supervised-learning>#</a></h2><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219174256.png><img alt=contrastive loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219174256.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219174256.png style="display:block;margin:0 auto" alt=contrastive></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>自监督学习最重要的就是下游任务的设计，一般分成两种：</p><ol><li>生成式模型：Encode-Decode架构，让输入输出尽可能的相似，或者是后续进化的MIM架构，挖空并还原空中的内容，并在Transformer架构中取代判别式模型方法称为主流。</li><li>判别式模型：通过Encoder编码，通过对比学习分析相似性来建立对比损失，自从MoCo出来后判别式模型在一定时间内成为主流。</li></ol><h3 id=避免退化解形成>避免退化解形成<a hidden class=anchor aria-hidden=true href=#避免退化解形成>#</a></h3><p>InfoNCE的两部分在理论上是缺一不可的，如果没有Alignment，就无法聚类，如果没有Uniformly，容易使得所有的输入输出又相同的表示，也就是形成退化解。</p><p>参考 <a href="https://mp.weixin.qq.com/s?__biz=Mzg4MjQ1NzI0NA==&amp;mid=2247494486&amp;idx=1&amp;sn=dd8700c12d394bcc4eb032ed09b508b7&amp;chksm=cf54c4a5f8234db3df5d82cc7839a6d8dc38991e495bfbda0f3b75a643c1686f1fe5c93502a3&amp;token=1062986518&amp;lang=zh_CN#rd" target=_blank rel=noopener>Article</a>
对几种自监督的方法解决退化解的方式进行了简要的分析。</p><h3 id=实验中的设置问题>实验中的设置问题<a hidden class=anchor aria-hidden=true href=#实验中的设置问题>#</a></h3><p><a href=https://zhuanlan.zhihu.com/p/378340148 target=_blank rel=noopener>zhihu</a>
<strong>对比学习中一般选择一个batch中的其他样本作为负例，如果负例中又很相似的样本怎么办？</strong></p><p>在无监督无标注的情况下，这样的伪负例，其实是不可避免的，首先可以想到的方式是去扩大语料库，去加大batch size，以降低batch训练中采样到伪负例的概率，减少它的影响。</p><p>另外，神经网络是有一定容错能力的，像伪标签方法就是一个很好的印证，但前提是错误标签数据或伪负例占较小的比例。</p><p>也可以考虑使用监督的对比学习方法</p><p><strong>对比学习的infoNCE loss 中的温度系数t的作用是什么？</strong><sub>[1]</sub></p><blockquote><p>温度系数的作用是调节对困难样本的关注程度：越小的温度系数越关注于将本样本和最相似的困难样本分开，去得到更均匀的表示。然而困难样本往往是与本样本相似程度较高的，很多困难负样本其实是潜在的正样本，过分强迫与困难样本分开会破坏学到的潜在语义结构，因此，温度系数不能过小
考虑两个极端情况，温度系数趋向于0时，对比损失退化为只关注最困难的负样本的损失函数；当温度系数趋向于无穷大时，对比损失对所有负样本都一视同仁，失去了困难样本关注的特性。</p></blockquote><p>也可以用另一个角度理解：</p><blockquote><p>可以把不同的负样本想像成同极点电荷在不同距离处的受力情况，距离越近的点电荷受到的库伦斥力更大，而距离越远的点电荷受到的斥力越小。
对比损失中，越近的负例受到的斥力越大，具体的表现就是对应的负梯度值越大[4]。这种性质更有利于形成在超球面均匀分布的特征。</p></blockquote><p>对照公式去理解：</p><div>$$
L_{i}=-\log \left(e^{S\left(z_{i}, z_{i}^{+}\right) / \tau} / \sum_{j=0}^{K} e^{S\left(z_{i}, _{j}\right) / \tau}\right)
$$</div><p>当温度系数很小时，越相似也即越困难的负例，对应的坟墓就会越大，在分母叠加项中所占的比重就会越大，对整体loss的影响就会越大，具体的表现就是对应的负梯度值越大</p><p>当然，这仅仅是提供了一种定性的认识，定量的认识和推导可以参见博客<a href=https://zhuanlan.zhihu.com/p/357071960 target=_blank rel=noopener>zhihu</a></p><h2 id=with-supervised-learning>with supervised learning<a hidden class=anchor aria-hidden=true href=#with-supervised-learning>#</a></h2><p><a href=https://zhuanlan.zhihu.com/p/143443691 target=_blank rel=noopener>ZHIHU</a></p><p>借鉴了contrastive的设计在监督信息的基础上对其进行改造，设计一个用于监督学习的对比损失。这一点也可以解决我们问题设置中的第一个问题，但是为此也只能在监督的情况下使用。</p><div>$$
\mathcal{L}_{i}^{s u p}=\frac{-1}{2 N_{\tilde{y}_{i}}-1} \sum_{j=1}^{2 N} 1_{i \neq j} \cdot 1_{\bar{y}_{i}=\bar{y}_{j}} \cdot \log \frac{\exp \left(z_{i} \cdot z_{j} / \tau\right)}{\sum_{k=1}^{2 N} 1_{i \neq k} \cdot \exp \left(z_{i} \cdot z_{k} / \tau\right)}
$$</div><p>其实也就是当标签相同的时候都当作正例，其他时候都是负例，也就是修改了原本状态下positive的情况。</p><p>在训练的过程中，该方法和two-stage会使用同样的策略，也就是在第一阶段使用SCL训练Backbone，在第二阶段固定representation的参数，并只对clf的参数进行训练。</p><h4 id=code-part>Code Part<a hidden class=anchor aria-hidden=true href=#code-part>#</a></h4><p><a href=https://www.cnblogs.com/panchuangai/p/13764774.html target=_blank rel=noopener>understand the code</a>
；<a href=https://github.com/HobbitLong/SupContrast/blob/a8a275b3a8b9b9bdc9c527f199d5b9be58148543/main_supcon.py#L131 target=_blank rel=noopener>Offical Code</a>
；</p><ul><li>如果我们需要理解这串代码如何使用，我们需要阅读官方源码中的数据使用模式，我们需要使用图像的两组不同增强，计算对应的特征，然后整合到n_views维度，再将其传入该损失。</li><li>后续我们可以基于NXTent Loss函数来简化和改写该损失，目前我们只需要对其加入Normalization就可以暂时进行使用了，第一步我们使用大的batchsize来代替2Augs，如果效果不好的话可以测试2Augs是否会有更好的增益</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SupConLoss</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.
</span></span></span><span class=line><span class=cl><span class=s2>    It also supports the unsupervised contrastive loss in SimCLR&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>temperature</span><span class=o>=</span><span class=mf>0.07</span><span class=p>,</span> <span class=n>contrast_mode</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>base_temperature</span><span class=o>=</span><span class=mf>0.07</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>SupConLoss</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>temperature</span> <span class=o>=</span> <span class=n>temperature</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>contrast_mode</span> <span class=o>=</span> <span class=n>contrast_mode</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>base_temperature</span> <span class=o>=</span> <span class=n>base_temperature</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Compute loss for model. If both `labels` and `mask` are None,
</span></span></span><span class=line><span class=cl><span class=s2>        it degenerates to SimCLR unsupervised loss:
</span></span></span><span class=line><span class=cl><span class=s2>        https://arxiv.org/pdf/2002.05709.pdf
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            features: hidden vector of shape [bsz, n_views, ...].
</span></span></span><span class=line><span class=cl><span class=s2>            labels: ground truth of shape [bsz].
</span></span></span><span class=line><span class=cl><span class=s2>            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j
</span></span></span><span class=line><span class=cl><span class=s2>                has the same class as sample i. Can be asymmetric.
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            A loss scalar.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                  <span class=k>if</span> <span class=n>features</span><span class=o>.</span><span class=n>is_cuda</span>
</span></span><span class=line><span class=cl>                  <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cpu&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>features</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mi>3</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;`features` needs to be [bsz, n_views, ...],&#39;</span>
</span></span><span class=line><span class=cl>                             <span class=s1>&#39;at least 3 dimensions are required&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>features</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>3</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>features</span> <span class=o>=</span> <span class=n>features</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>features</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>features</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span> <span class=o>=</span> <span class=n>features</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>labels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;Cannot define both `labels` and `mask`&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>labels</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>mask</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>labels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>labels</span> <span class=o>=</span> <span class=n>labels</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>labels</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>!=</span> <span class=n>batch_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;Num of labels does not match num of features&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>eq</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>labels</span><span class=o>.</span><span class=n>T</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>contrast_count</span> <span class=o>=</span> <span class=n>features</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>contrast_feature</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>unbind</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>contrast_mode</span> <span class=o>==</span> <span class=s1>&#39;one&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>anchor_feature</span> <span class=o>=</span> <span class=n>features</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>anchor_count</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>contrast_mode</span> <span class=o>==</span> <span class=s1>&#39;all&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>anchor_feature</span> <span class=o>=</span> <span class=n>contrast_feature</span>
</span></span><span class=line><span class=cl>            <span class=n>anchor_count</span> <span class=o>=</span> <span class=n>contrast_count</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;Unknown mode: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>contrast_mode</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># compute logits</span>
</span></span><span class=line><span class=cl>        <span class=n>anchor_dot_contrast</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>div</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>anchor_feature</span><span class=p>,</span> <span class=n>contrast_feature</span><span class=o>.</span><span class=n>T</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>temperature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># for numerical stability</span>
</span></span><span class=line><span class=cl>        <span class=n>logits_max</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>anchor_dot_contrast</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logits</span> <span class=o>=</span> <span class=n>anchor_dot_contrast</span> <span class=o>-</span> <span class=n>logits_max</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># tile mask</span>
</span></span><span class=line><span class=cl>        <span class=n>mask</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=n>anchor_count</span><span class=p>,</span> <span class=n>contrast_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># mask-out self-contrast cases</span>
</span></span><span class=line><span class=cl>        <span class=n>logits_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>mask</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>batch_size</span> <span class=o>*</span> <span class=n>anchor_count</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mask</span> <span class=o>=</span> <span class=n>mask</span> <span class=o>*</span> <span class=n>logits_mask</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># compute log_prob</span>
</span></span><span class=line><span class=cl>        <span class=n>exp_logits</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>logits</span><span class=p>)</span> <span class=o>*</span> <span class=n>logits_mask</span>
</span></span><span class=line><span class=cl>        <span class=n>log_prob</span> <span class=o>=</span> <span class=n>logits</span> <span class=o>-</span> <span class=n>torch</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>exp_logits</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># compute mean of log-likelihood over positive</span>
</span></span><span class=line><span class=cl>        <span class=n>mean_log_prob_pos</span> <span class=o>=</span> <span class=p>(</span><span class=n>mask</span> <span class=o>*</span> <span class=n>log_prob</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>mask</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># loss</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=o>-</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>temperature</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>base_temperature</span><span class=p>)</span> <span class=o>*</span> <span class=n>mean_log_prob_pos</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>anchor_count</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>loss</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=with-arcface>with ArcFace<a hidden class=anchor aria-hidden=true href=#with-arcface>#</a></h2><p>对比学习损失我们知道其目的是为了，拉近相似样本之间的距离，并尽量的将不同的类别之间的样本区分，而这和进行人脸识别中的 $ArcFace Loss$ 系列的Softmax Loss有着相同的目的。</p><p>那么这两种方法之间是否能够相互借鉴，或者说是否NCE本身在自监督学习任务上就更优于ArcFace?（是否会过度关注细节，无法关注到相应的整体架构）<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211220154555.png><img alt=arcface loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211220154555.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211220154555.png style="display:block;margin:0 auto" alt=arcface></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>或者说在后续的分类器训练过程中，这样是否能够帮助我们使用聚类的方式进行分类？（结合epoch-control的那种方法）进行fine-tuning等等</p><h2 id=reference>reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ol><li>“Understanding the Behaviour of Contrastive Loss” CVPR2021</li><li><a href=https://zhuanlan.zhihu.com/p/357071960 target=_blank rel=noopener>Analysis The InfoNCE-Loss</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://aikenh.cn/hugotest/tags/machine-learning/>Machine Learning</a></li><li><a href=https://aikenh.cn/hugotest/tags/loss/>Loss</a></li></ul><nav class=paginav><a class=prev href=https://aikenh.cn/hugotest/posts/lt-collection/><span class=title>« Prev</span><br><span>LT Collection</span>
</a><a class=next href=https://aikenh.cn/hugotest/posts/loss-smoothsharpen/><span class=title>Next »</span><br><span>Loss-Smooth(Sharpen)</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://aikenh.cn/hugotest/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>