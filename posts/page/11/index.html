<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | aiken's blog</title>
<meta name=keywords content><meta name=description content="Posts - aiken's blog"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.2f85ca17c12c62fa86b1e474b8a51aca4856f0d645debfe4922a4d5ddc6aa978.css integrity="sha256-L4XKF8EsYvqGseR0uKUaykhW8NZF3r/kkipNXdxqqXg=" rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://hugotest-phi.vercel.app/posts/index.xml><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Posts"><meta property="og:description" content="Let's learn and innovate together!"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Let's learn and innovate together!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"}]}</script></head><body class=list id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li class=active style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/sakana-widget@2.7.0/lib/sakana.min.css><div id=sakana-widget></div><script>function initSakanaWidget(){const e=SakanaWidget.getCharacter("chisato");e.initialState={...e.initialState,controls:!1,t:.8,i:.002,s:1,d:.999,t:.5,w:.05},e.image="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/%E5%B7%B2%E7%A7%BB%E9%99%A4%E8%83%8C%E6%99%AF%E7%9A%84Xnip2024-11-30_00-47-03.png",SakanaWidget.registerCharacter("ronSang",e),new SakanaWidget({character:"ronSang"}).mount("#sakana-widget");const t=SakanaWidget.getCharacter("chisato");t.initialState={...t.initialState,controls:!1,t:.8,i:.002,s:1,d:.999,t:.5,w:.05},t.image="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/%E5%B7%B2%E7%A7%BB%E9%99%A4%E8%83%8C%E6%99%AF%E7%9A%84Xnip2024-11-30_00-36-37.png",SakanaWidget.registerCharacter("xinxin",t),new SakanaWidget({character:"xinxin"}).mount("#sakana-widget")}</script><script async onload=initSakanaWidget() src=https://cdn.jsdmirror.com/npm/sakana-widget@2.7.0/lib/sakana.min.js></script><main class=main><header class=page-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover8.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Loss-NCE</h2></header><section class=entry-content><p>@AikenHong 2021
Noise Contrastive Estimation Loss = NCE Loss 噪声对比估计损失，这里的Noise实际上就是Negative Samples. 该损失被广泛的用于对比学习的任务，而对比学习广泛的作为自监督学习的无监督子任务用来训练一个良好的特征提取器，于是对于对比学习的目标和效用的理解十分关键。
What’s NCE Loss 在介绍NCE之前我们可以将其和CE进行一个简单的对比，虽然名称上不是同一个CE，但是在数学表达上却有很相近的地方（softmax-kind of loss）
首先softmax，他保证所有的值加起来为一，结合onehot的ce，实际上j==gt的情况下外层+log也就是ceLoss，也就是 $logSoftmax$
$$ S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}
$$
然后看infoNCE，基础的对比学习损失可以写成：
$$ L_{contrast} = \mathbb{E}[-\log\frac{e^{f_x^T f_y/T}}{e^{f_x^T f_y/T} + \sum_i e^{f_x^T f_{y_-^i}/T}}]
$$
其中 $f_x^T f_y^T$ 为 $sim(x,y)$ 时即转化为带 $T$ 的NCE，即InforNCE.
分子是正例对的相似度，分母是正例对+所有负例对的相似度，最小化infoNCE loss，就是去最大化分子的同时最小化分母，也就是最大化正例对的相似度，最小化负例对的相似度。
从该形式上看，和soft的CE形式上是统一的，当我们把分母看作概率和自身以及和其他的相似性，这样和NCE在形式上和简化后的CE实现了统一。
但是我不认为这和label smooth 后的CE有相关性，而是和原始的CE经由One-hot简化后结构上有相似性。
How it Works NCE的思想是拉近相似的样本，推开不相近的样本，从而学习到一个好的语义表示空间，这一点上实际上和度量学习的思想是一样的，只是对比学习通常作用在无监督或者自监督的语境中，度量学习这是有监督的。
考虑之前人脸匹配的研究，使用 “Alignment and Uniformity on the Hypersphere"中的Alignment and Uniformity，就是一个更好理解他的角度
$$ \begin{gathered}
L_{\text {contrast }}=\mathbb{E}\left[-\log \frac{e^{f_{x}^{T} f_{y} / \tau}}{e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{T_{x}^{T} f_{y_{i}}^{-} / \tau}}\right] \\
=\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]+\mathbb{E}\left[\log \left(e^{f_{x}^{T} f_{y} / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}^{-} / \tau}}\right)\right] \\
\mathbb{P}\left[\left(f_{x}=f_{y}\right)\right]=1 \underbrace{\mathbb{E}\left[-f_{x}^{T} f_{y} / \tau\right]}_{\text {positive alignment }}+\underbrace{\mathbb{E}\left[\log \left(e^{1 / \tau}+\sum_{i} e^{f_{x}^{T} f_{y_{i}}-/ \tau}\right)\right]}_{\text {uniformity }}
\end{gathered}
$$
公式经过上面的推导就可以看成下的两个部分，其中alignment只与positive pair有关，相反Uniformity只与negative pair相关，希望所有的点都能尽可能的分布在uni hypersphere上。
...</p></section><footer class=entry-footer><span title='2021-12-22 13:39:55 +0000 UTC'>December 22, 2021</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;655 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/loss> Loss</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/loss style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Loss</a></div></div></div><a class=entry-link aria-label="post link to Loss-NCE" href=https://hugotest-phi.vercel.app/posts/loss-nce/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover10.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Loss-Smooth(Sharpen)</h2></header><section class=entry-content><p>@AikenHong 2021 @topic
smooth label (inception v2) when does label smoothing help (nips 2019) sharpen in semi-supervised in the future offical code github 不是一个通用的方法，在很多的任务上反而会导致掉点的现象，可以简单分析一下，汲取一下思想和Sharpen做对比，在这篇文章中，我们可以结合之前的人脸对比损失来进行分析。
What’s the smooth label 首先介绍在图像分类任务中对logits和Hard label做ce得到我们的损失，可以表现为如下的形式：
$$ Loss = -\sum^{K}_{i=1}p_i \log(q_i)
$$
由于我们的标签是一个hard label，实际上可以转化成一个one-hot，即
$$ \begin{equation}
p_i = \left\{
\begin{array}{c1}
1 & i==gt \\
0 & i!=gt \\
\end{array} \right.
\end{equation}
$$
而soft label实际上做的是将 1的位置变为 $1-\alpha$ ，其他位置设置为 $\alpha/(K-1)$ ，然后再去求CE，
Hinton论文中给出该损失对特征分布的作用测试图： ...</p></section><footer class=entry-footer><span title='2021-12-17 03:35:27 +0000 UTC'>December 17, 2021</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;144 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/loss> Loss</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/loss style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Loss</a></div></div></div><a class=entry-link aria-label="post link to Loss-Smooth(Sharpen)" href=https://hugotest-phi.vercel.app/posts/loss-smoothsharpen/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover10.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Training Strategy</h2></header><section class=entry-content><p>@Aiken 2020，
主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。
参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。
优化器 Some Material 实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：
Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。
但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。
学习率 $\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，
==Basic==
学习率大 学习率小 学习速度 快 慢 使用情景 刚开始训练时 一定的次数过后 副作用 1. Loss爆炸 2.振荡 1.过拟合 2.收敛速度慢 学习率的基本设置 在训练过程中，一般根据训练轮数设置动态变化的学习率。
刚开始训练时：学习率以 0.01 ~ 0.001 为宜。 一定轮数过后：逐渐减缓。 接近训练结束：学习速率的衰减应该在100倍以上。 Note： 如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 微调 。
学习率变化方法 ==warm up==
warm up为什么有用 warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：
这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。
而这样的跑偏对于大模型而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。 ...</p></section><footer class=entry-footer><span title='2021-12-16 08:34:44 +0000 UTC'>December 16, 2021</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1045 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/pytorch> Pytorch</a>&nbsp;·&nbsp;<a href=/tags/acceleration> Acceleration</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/pytorch style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Pytorch
</a><a href=/tags/acceleration style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Acceleration</a></div></div></div><a class=entry-link aria-label="post link to Training Strategy" href=https://hugotest-phi.vercel.app/posts/nerualnetworktraining/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover4.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>PyTorch Handbook 00 （Archive）</h2></header><section class=entry-content><p>Basic Part基础设定部分 @AikenH 2020 + 2021
this part is about pytorch basic unit, help me to code deep learning better.
Tensor张量计算 两个tensor的数乘 计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数
1 2 3 4 5 6 7 8 9 10 11 12 # 简单的分析一下算法的逻辑 # 这是割裂出来batch的矩阵相乘形式 batch1 = torch.randn(10,3,4) batch2 = torch.randn(10,4,5) out = torch.bmm(batch1, batch2) out.size() '''output ans is torch.size([10,3,5])''' # 按位相乘 res = torch.mul(batch1,batch2) view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。
张量命名 1 2 3 4 NCHW = [‘N’, ‘C’, ‘H’, ‘W’] images = torch.randn(32, 3, 56, 56, names=NCHW) images.sum('C') images.select('C', index=0) 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 # tensor 与 nd.array进行互换 ndarray = tensor.cpu().numpy() tensor = torch.from_numpy(ndarray).float() # tensor与PIL.IMAGE进行互换 image = torchvision.transforms.functional.to_pil_image(tensor) path = r'./figure.jpg' tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) # np.ndarray 与 PIL.Image的互换 image = PIL.Image.fromarray(nd.array.astype(np.uint8)) ndarray = np.asarray(PIL.Image.open(path)) 维度堆叠 Stack，普通的维度堆叠的测试代码如下
...</p></section><footer class=entry-footer><span title='2021-12-15 08:00:57 +0000 UTC'>December 15, 2021</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2434 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/python> Python</a>&nbsp;·&nbsp;<a href=/tags/pytorch> Pytorch</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/python style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Python
</a><a href=/tags/pytorch style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Pytorch</a></div></div></div><a class=entry-link aria-label="post link to PyTorch Handbook 00 （Archive）" href=https://hugotest-phi.vercel.app/posts/pytorch/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover0.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Loss-WhyZero</h2></header><section class=entry-content><p>Loss :Why Zero Loss？ @Comments: ICML2020 《Do We Need Zero Training Loss After Achieving Zero Training Error》
@Noteby：AikenHong2021
如何解决训练损失下降，但是验证损失上升的问题（过拟合like）的问题，该文章实际上可以作为我们损失设计中的一个trick，只需要简单的一行代码，来提升代码的泛化能力；
这张图体现了本文的灵魂（思路），主要体现在我们在算法趋于稳定后继续训练可能验证损失会反而上升；
所以本文提出了一种flooding方法，当我们training loss 大于阈值的时候我们使其正常下降，当低于阈值的时候，flooding的设计会反过来使得梯度上升，让训练损失保持在flooding附近，让模型持续进行random walk，希望模型最终能优化到一个平坦的损失区域，这样发现test loss进一步的进行下降。
理解：
当我们的训练损失低到一定的程度，然后随着lr的下降，模型会很难跳出当前的极小值，这种情况下我们的泛化能力也会被限制住，采用这种方法在牺牲测试精度的同时能提升算法的泛化能力。
损失公式表示如下
$$ \widetilde{J}(\theta) = |J(\theta) - b| +b
$$
...</p></section><footer class=entry-footer><span title='2021-12-10 08:24:46 +0000 UTC'>December 10, 2021</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;66 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/loss> Loss</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/loss style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Loss</a></div></div></div><a class=entry-link aria-label="post link to Loss-WhyZero" href=https://hugotest-phi.vercel.app/posts/loss-whyzero/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover0.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Algorithm Sort</h2></header><section class=entry-content><p>记录各种排序操作，暂时不补充最基础的排序方式和理论，只记录排序算法的拓展应用。
在理论分析的部分主要使用cpp进行撰写，而在具体使用的时候，目前会主要按照python来进行编写，这主要是面向的场景不同决定的。
基础的排序理论，包括快排等等算法的分析在另一篇文章中记录（当初实习准备的时候有整理过，后续重新整理出来）
排序算法和理论 placeholder
排序算法应用 placeholder
同步排序 常用于Machine Learning中，将数据集中的数据和标签进行同步排序，避免打乱其中的对应关系。
使用numpy的 argsort功能来进行排序：
1 2 3 idx = np.argsort(labels) labels = labels[idx] datas = datas[idx,...] 使用sort中的args: key来进行同步排序，选出一个作为依据, 但是这种方式不支持存在np的情况，因为np无法建立hash，除非我们转化成tuple再转回来。
1 2 3 4 5 # 默认按照第0维度进行排序 lables, datas = [list(x) for x in zip(*sorted(zip(labels, datas)))] # 若要指定特定维度 from operator import itemgetter datas, labels = [list(x) for x in zip(*sorted(zip(datas, labels), key=itemgetter(1)))] 额外介绍我的愚蠢实现思路：
用 $index/length$ 作为小数位添加到 $labelList$ 上 $SORT$ 排序列表，分离并复原Index 基于Index对列表进行排序赋值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def sort_dataset(dataset): # the num_new_class can be calculate by some formula, but in this part make it HARD # sort those data and label which make it easier to del class. num_data = len(dataset) up_limit = pow(10, len(str(num_data))) index = [index /up_limit for index in num_data] # using this mark to sort the data for i, _ in enumerate(dataset.targets): dataset.targets[i] += index[i] dataset.targets.sort() # get the new order new_order = [target - int(target) for target in dataset.targets] * up_limit dataset.targets = [int(target) for target in dataset.targets] # it's necessary for us to swith to list or not? dataset.data = list(np.array(dataset.data)[new_order]) return None</p></section><footer class=entry-footer><span title='2021-12-06 17:05:03 +0000 UTC'>December 6, 2021</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;189 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/algorithm> Algorithm</a>&nbsp;·&nbsp;<a href=/tags/sort> Sort</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/algorithm style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Algorithm
</a><a href=/tags/sort style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Sort</a></div></div></div><a class=entry-link aria-label="post link to Algorithm Sort" href=https://hugotest-phi.vercel.app/posts/sorttrick/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover16.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>UniFramework 01</h2></header><section class=entry-content><p>文章的部分内容被密码保护：
--- DON'T MODIFY THIS LINE ---
@aiken 2021 Framework
Abstract Try To make structure universal，编写一个自己的通用的架构，框架化，满足通过不同的model文件和特殊配置文件就能实现不同的模型的一个架构。
只是一个初步的框架集成，还有很多没有完善的地方，目前测试了ResNet18 跑Cifar10，没有什么问题，如果有什么可以改进的地方，或者你实现了一些Feature，*欢迎进行交流*！（私下联系我最好啦！）
感谢帮助
还有一些可以参数化或者可视化的地方，由于时间关系目前还没有修改，有兴趣的可以自己先添加一下
暂时只集成了分类的模块，后续可能会随缘扩展
本框架主要希望实现的是：易读性，可拓展性，以及简洁；
希望将重要的，可变的参数都尽量的分离出来，通过配置文件和命令行参数去定义和运行我们的网络，在这种情况下实现一个较好的工作流程。
Final Project Design PURPOSE：新类发现和模型自主更新；同时希望能够解决长尾分布的数据情景；
**ANALYSIS：**为了实现这种模型的自主更新过程，将整体的流程分成两个部分
启动（start）： self supervissed 等方法无监督的学习特征提取网络（这种方式是否会对Unbalance产生增益）
初始化预测模型： 基于Unbalance的数据训练一个基础的分类模型，在输出分类结果的同时需要输出对应的预测置信度，这两个其实都是一些简单的Trick，而最重要的是Backbone的分类效果需要得到保证，同时Backbone需要支撑后续的模型蒸馏更新。 模型的自主更新和迭代： Online：在线运行推断模型，通过置信度输出筛选出新类样本，将样本在样本池中收集 Offline：基于样本池的规模和评估触发离线更新：伪标签生成模型；模型蒸馏和更新 创新点：自主新类发现和学习
...</p></section><footer class=entry-footer><span title='2021-12-04 01:43:30 +0000 UTC'>December 4, 2021</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;526 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/cv> CV</a>&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/cv style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#CV
</a><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning</a></div></div></div><a class=entry-link aria-label="post link to UniFramework 01" href=https://hugotest-phi.vercel.app/posts/uniframework/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover6.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Hungarian</h2></header><section class=entry-content><p>@AikenHong 2021 @Code: Scipy（repo） @Reference: 匈牙利算法&amp;KM算法 该篇笔记用来介绍匈牙利算法和KM算法(Kuhn-Munkres Algorithm)，这两个算法通常用来做目标之间的匹配问题。 常用于：多目标跟踪，和深度聚类中的标签匹配问题。
Method 这两种方法实际上解决的问题都是： 二分图的最大匹配问题； 首先需要对二分图有个基本的了解：
实际上就是将数据分为两组，各组的每一个点都去另一个组找对应的匹配，我们希望将两组中，相关的数据尽可能的准确的匹配起来。
可以想象成，是同一个数据在不同的映射下的不同表征需要做这样的匹配关系。
解决这种问题的方式就是使用匈牙利算法或者KM算法
匈牙利算法 匈牙利算法是一种在多项式时间内求解任务分配问题的组合优化算法
匈牙利算法可以将二分图中的连线，看成是我们认为可能是相同的目标（不带权值），实际上就是从上到下假想成立，然后进行唯一匹配的搜索，有点像BackTrack的过程。
整体算法的成功率或者准确率实际上十分依赖与连线的准确率，对算法输出预测的准确度要求更高。
KM KM解决的是带权的二分图的最优匹配的问题。
相当于我们给每条线都给出一个置信度预测值，基于这样的权值图去计算对应的匹配关系
Step1: 将左边节点标上与他所关联的最大权值的边的数值 Step2: 寻找匹配，原则如下
只有权重和左边分数相同的边才进行匹配； 如果找不到边，此条路径的所有左边顶点-d，右侧+d，这里我们将d取值为0.1 对于考虑换边的另一个节点，如果无法换边，也需要对应的进行-d 具体的例子可以这么看（最好还是看blog）： ...</p></section><footer class=entry-footer><span title='2021-12-03 00:29:37 +0000 UTC'>December 3, 2021</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;46 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/algorithm> Algorithm</a>&nbsp;·&nbsp;<a href=/tags/matching> Matching</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/algorithm style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Algorithm
</a><a href=/tags/matching style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Matching</a></div></div></div><a class=entry-link aria-label="post link to Hungarian" href=https://hugotest-phi.vercel.app/posts/hungarian/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover17.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Cherno的cpp教程笔记</h2></header><section class=entry-content><p>this notebook is based on Cherno‘s Video Class in YouTube ；if there is sth get confused，I can recheck the video which talk about it, or just google it.
this is not totally for newbie, so some basic information we should search it And this is a important websize to tell us basic info about C++. ToDo:
using c++ and Python to finish the leetcode. review data structure when we code. eorganize the notebook by onenote** and leetcode 后续可能会添加 Effetive C++中的相关内容 C++ Switch语句 Attention：
...</p></section><footer class=entry-footer><span title='2021-11-29 13:12:17 +0000 UTC'>November 29, 2021</span>&nbsp;·&nbsp;21 min&nbsp;·&nbsp;4304 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/cpp> Cpp</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/cpp style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Cpp</a></div></div></div><a class=entry-link aria-label="post link to Cherno的cpp教程笔记" href=https://hugotest-phi.vercel.app/posts/cpp/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover11.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>FSL前期调研</h2></header><section class=entry-content><p>文章的部分内容被密码保护：
--- DON'T MODIFY THIS LINE ---
主要是limited labels & Few Samples & Data programing Weakly supervised learning
semi-supervised in video field
if we can recoding this work?
多指标下降（LOSS的耦合或者循环的选择）、相关的CV最新论文等等会在后续关注
元学习、浅层神经网络的概念等等 semi-supervised
PART1 Limited Labels （base on LiFeiFei‘s reference） in this part we may list the paper which is useful for my recoding.
还有一些其他重要的可能在对论文进行重新精读的时候要记得注意reference：就比如说在loss变换和决策树生成那一块。
distant supervision(it’s kind of early) can be another baseline for our method, we need to understand how this method work for that situation
distant supervisor到底是什么机制可以去CSDN什么的看一下
...</p></section><footer class=entry-footer><span title='2021-11-29 13:12:05 +0000 UTC'>November 29, 2021</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;549 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;·&nbsp;<a href=/tags/fsl> FSL</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/machine-learning style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Machine Learning
</a><a href=/tags/survey style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Survey
</a><a href=/tags/fsl style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#FSL</a></div></div></div><a class=entry-link aria-label="post link to FSL前期调研" href=https://hugotest-phi.vercel.app/posts/fsl%E5%89%8D%E6%9C%9F%E8%B0%83%E7%A0%94/></a></article><footer class=page-footer><nav class=pagination><a class=last-icon href=https://hugotest-phi.vercel.app/posts/><span>&lt;&lt;</span>
</a><a class=prev href=https://hugotest-phi.vercel.app/posts/page/10/>«&nbsp;Prev&nbsp;10/17
</a><a class=next href=https://hugotest-phi.vercel.app/posts/page/12/>Next&nbsp;12/17&nbsp;»
</a><a class=last-icon href=https://hugotest-phi.vercel.app/posts/page/17/><span>>></span></a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>