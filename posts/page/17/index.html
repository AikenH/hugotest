<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | aiken's blog</title>
<meta name=keywords content><meta name=description content="Posts - aiken's blog"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.2f85ca17c12c62fa86b1e474b8a51aca4856f0d645debfe4922a4d5ddc6aa978.css integrity="sha256-L4XKF8EsYvqGseR0uKUaykhW8NZF3r/kkipNXdxqqXg=" rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://hugotest-phi.vercel.app/posts/index.xml><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Posts"><meta property="og:description" content="Let's learn and innovate together!"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Let's learn and innovate together!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"}]}</script></head><body class=list id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li class=active style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/sakana-widget@2.7.0/lib/sakana.min.css><div id=sakana-widget></div><script>function initSakanaWidget(){const e=SakanaWidget.getCharacter("chisato");e.initialState={...e.initialState,controls:!1,t:.8,i:.002,s:1,d:.999,t:.5,w:.05},e.image="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/%E5%B7%B2%E7%A7%BB%E9%99%A4%E8%83%8C%E6%99%AF%E7%9A%84Xnip2024-11-30_00-47-03.png",SakanaWidget.registerCharacter("ronSang",e),new SakanaWidget({character:"ronSang"}).mount("#sakana-widget");const t=SakanaWidget.getCharacter("chisato");t.initialState={...t.initialState,controls:!1,t:.8,i:.002,s:1,d:.999,t:.5,w:.05},t.image="https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/mac/%E5%B7%B2%E7%A7%BB%E9%99%A4%E8%83%8C%E6%99%AF%E7%9A%84Xnip2024-11-30_00-36-37.png",SakanaWidget.registerCharacter("xinxin",t),new SakanaWidget({character:"xinxin"}).mount("#sakana-widget")}</script><script async onload=initSakanaWidget() src=https://cdn.jsdmirror.com/npm/sakana-widget@2.7.0/lib/sakana.min.js></script><main class=main><header class=page-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover5.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Hyper-Resolution</h2></header><section class=entry-content><p>说明：重点针对超分辨率技术
备注： 超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波
超分辨率在表情识别中的应用 KEY WORDs ：
1. ("super resolution" OR "image restore") AND ("facial expression recognition" OR "emotion recognition") 2. ("super resolution") AND ("expression recognition") &lt; Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach > 针对于低带宽传输的分辨率不足和比率低的应用场景 基于facial expression recognition 的 emotion recognition 在解码器进行视频下采样的时候，联合SR和识别 &lt; Effective image super resolution via hierarchical convolutional neural network > 通过层次卷积神经网络(HCNN)来实现有校的SR 在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能 &lt; Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images > ...</p></section><footer class=entry-footer><span title='2020-03-06 14:55:02 +0000 UTC'>March 6, 2020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;210 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;·&nbsp;<a href=/tags/hyperresolution> HyperResolution</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/survey style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Survey
</a><a href=/tags/hyperresolution style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#HyperResolution</a></div></div></div><a class=entry-link aria-label="post link to Hyper-Resolution" href=https://hugotest-phi.vercel.app/posts/hyper_resolution/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover6.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>Image Caption Dataset</h2></header><section class=entry-content><p>Goals： 1.数据量要求
2.标注的标准
3.标注的手段
Microsoft COCO Captions: 使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。
“Each of our captions are also generated using human subjects on AMT.”
一些其他信息：(Caption Evaluation Server): 好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。
文中（section 3）包含了几种不同评价方法的介绍：
BLEU
ROUGE
METEOR
CIDEr
在进行Evaluation之前的 Tokenization and preprocessing中：
使用了工具来添加caption标记：
Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1) 这个工具是模仿的是peen treebank3. 其参考文献和相关链接如下：
“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link ...</p></section><footer class=entry-footer><span title='2020-01-14 02:13:25 +0000 UTC'>January 14, 2020</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;281 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/dataset> Dataset</a>&nbsp;·&nbsp;<a href=/tags/image-caption> Image Caption</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/dataset style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Dataset
</a><a href=/tags/image-caption style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Image Caption</a></div></div></div><a class=entry-link aria-label="post link to Image Caption Dataset" href=https://hugotest-phi.vercel.app/posts/imagecaptionrequirement/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://hugotest-phi.vercel.app/cover/cover20.jpeg alt></figure><div class=post-info><header class=entry-header><h2 class=entry-hint-parent>表情数据集</h2></header><section class=entry-content><p>根据这次需要搜集的表情的数据集，整理一下搜索数据集的网站和思路等
##PART1 “表情数据集” 下列是对数据搜集的要求：
是否开源 图片的大小和数量 图片的采集方式 eg：ck+
==数据来源及对应的搜索结果如下：==
谷歌数据集搜索导航 60个人脸识别的数据集汇总 cv方面的好几百个数据集汇总 另一个cv方向的数据集汇总 github-CV汇总帖 EmotioNet 好像是一个什么挑战赛的数据集要博士后或者相应教员才能申请使用申请页面 没有具体的用于表情识别的数据子集的信息（好像数据很多，但是不知道在哪下，除了那个博士后申请的）
RAF real-world Affective Face
数据量29672个图像，7种基本情绪，12种复合情绪，（包含种族年龄范围性别属性，5个准确定位和37个自动生成的定位）
**数据收集方式：**来源网络，大小应该很杂 （由40个人独立标定）
email
onenote中标记的和google 数据集搜索
FaceTracer Database basic info：（有图片的原始url）（wild）(网上收集的)姿势、环境、照明、质量 等等参差不齐，大小不固定 (针对非商业用途开放) (表情只有笑容) 故而不在详细收集，其他的标注信息，文中有详细讲解。 Tencent ML-Images 可能会有表情吧，是一个很大规模的多标签数据集。。。 ND-2006 Dataset 06年貌似 13450张图片 6种基本情感 888个对象 Google facial expression comparison dataset 没有对数据集的基本信息介绍 百度/CSDN搜索
https://blog.csdn.net/mathlxj/article/details/87920084 https://blog.csdn.net/computerme/article/details/49469767 JAFFE 只有219张，标签为分散离散值。 划分六种情感指标 256*256 中科大的NVIE 其中正面光照103人，左侧光照99人，右侧光照103人。每种光照下，每人有六种表情（喜悦、愤怒、哀 伤、恐惧、厌恶、惊奇）中的三种以上 平静帧、最大帧都已挑出 下载协议然后发给他们，才能下载 AFEW database 数据来源：电影片段的剪辑。情绪类型：“六类基本表情”+中性 SFEW database 数据来源：从AFEW中抽取出来的表情的静态帧。标注都在xml中 LIRIS-ACCEDE database 同样也是基于电影抽取的，有三种数据集，包含离散的情感数据和基于维度的情感数据 BU-3DFE database 3D的人脸表情数据集 **数据来源：**找人来做实验采集，按照要求的情绪做出表情 **数据量：**2500个3d面部模型（来自100个人） 还有同类的一些包含序列的等等的数据集，估计差别不大。 同样需要email获取 Oulu-CASIA database 数据来源：让80个受试者做出相应的表情并用不同相机采集（红外可见光正常光和弱光） 情绪类型：快乐、悲伤、惊讶、愤怒、恐惧、厌恶 email RAFD 数据来源：让67个受试者做出相应的表情在不同注视点和不同角度采集 情绪类型：8种情感类型 email KDEF database 数据来源：柔和、均匀的光线，多角度拍摄表情，使用统一的T恤颜色，在拍摄过程中使用网格将参与者面部居中，以及在扫描过程中将眼睛和嘴巴定位在固定的图像坐标中。 数据量：4900张 (70个人，一个7个情感) 页面底端超链接（没进去成功。。） ExpW 9w张左右，图片差不多8G AffectNet 百万量级数据（Emotion Net好像也是） 获取方式：从互联网获取 7类情感，首页有各种情感的数据量，最少的也有4k张 填写申请表email下载 Multi-PIE Face Database 收钱给数据集 获取方式：记录会话 数据量：75w图片 一些视频数据集(具体的在CSDN站上)（这些我就没有去详细看了）
...</p></section><footer class=entry-footer><span title='2019-10-14 21:34:54 +0000 UTC'>October 14, 2019</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;124 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/dataset> Dataset</a>&nbsp;·&nbsp;<a href=/tags/emotion> Emotion</a></footer><div class=tags style=padding:2px><div style=display:flex;flex-wrap:wrap;justify-content:flex-end;margin-top:5px><a href=/tags/dataset style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Dataset
</a><a href=/tags/emotion style="margin-right:5px;color:#fff;background-color:rgba(53,174,128,.7);border-radius:6px;padding:1px 10px;font-size:13px">#Emotion</a></div></div></div><a class=entry-link aria-label="post link to 表情数据集" href=https://hugotest-phi.vercel.app/posts/emotion_dataset/></a></article><footer class=page-footer><nav class=pagination><a class=last-icon href=https://hugotest-phi.vercel.app/posts/><span>&lt;&lt;</span>
</a><a class=prev href=https://hugotest-phi.vercel.app/posts/page/16/>«&nbsp;Prev&nbsp;16/17</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>