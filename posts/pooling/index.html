<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Pooling | aiken's blog</title>
<meta name=keywords content="Pooling,Survey,Machine Learning"><meta name=description content="DownSampling：Pooling的全面调研
@Aiken 2021 笔记摘录：
深度神经网络中的池化方法：全面调研（1989-2020） - 知乎
 ；相同论文的简单中文Version

16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…
来自 https://zhuanlan.zhihu.com/p/341820742

原文：《Pooling Methods in Deep Neural Networks, a Review》
整合2

池化的根本目的（Motivation）
卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。
池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层极大地减小了输入的空间尺寸。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。

池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。
增大感受野；
降低优化难度和参数数目，

理想的池化方法应仅提取有用的信息，并丢弃无关的细节。
特征不变性、特征降维、在一定程度上防止过拟合，更方便优化

主流的池化方法
Average Pooling 平均池化
没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征
Max Pooling 最大值池化
更关注重要的局部特征


  
    
  




"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/pooling/><link crossorigin=anonymous href=/assets/css/stylesheet.2f85ca17c12c62fa86b1e474b8a51aca4856f0d645debfe4922a4d5ddc6aa978.css integrity="sha256-L4XKF8EsYvqGseR0uKUaykhW8NZF3r/kkipNXdxqqXg=" rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/pooling/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/pooling/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Pooling"><meta property="og:description" content="DownSampling：Pooling的全面调研 @Aiken 2021 笔记摘录：
深度神经网络中的池化方法：全面调研（1989-2020） - 知乎 ；相同论文的简单中文Version 16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…
来自 https://zhuanlan.zhihu.com/p/341820742 原文：《Pooling Methods in Deep Neural Networks, a Review》
整合2 池化的根本目的（Motivation） 卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。
池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层极大地减小了输入的空间尺寸。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。
池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。 增大感受野； 降低优化难度和参数数目， 理想的池化方法应仅提取有用的信息，并丢弃无关的细节。
特征不变性、特征降维、在一定程度上防止过拟合，更方便优化
主流的池化方法 Average Pooling 平均池化 没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征
Max Pooling 最大值池化 更关注重要的局部特征"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-06-23T13:48:56+00:00"><meta property="article:modified_time" content="2021-06-23T13:48:56+00:00"><meta property="article:tag" content="Pooling"><meta property="article:tag" content="Survey"><meta property="article:tag" content="Machine Learning"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover14.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover14.jpeg"><meta name=twitter:title content="Pooling"><meta name=twitter:description content="DownSampling：Pooling的全面调研
@Aiken 2021 笔记摘录：
深度神经网络中的池化方法：全面调研（1989-2020） - 知乎
 ；相同论文的简单中文Version

16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…
来自 https://zhuanlan.zhihu.com/p/341820742

原文：《Pooling Methods in Deep Neural Networks, a Review》
整合2

池化的根本目的（Motivation）
卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。
池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层极大地减小了输入的空间尺寸。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。

池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。
增大感受野；
降低优化难度和参数数目，

理想的池化方法应仅提取有用的信息，并丢弃无关的细节。
特征不变性、特征降维、在一定程度上防止过拟合，更方便优化

主流的池化方法
Average Pooling 平均池化
没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征
Max Pooling 最大值池化
更关注重要的局部特征


  
    
  




"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"Pooling","item":"https://hugotest-phi.vercel.app/posts/pooling/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Pooling","name":"Pooling","description":"DownSampling：Pooling的全面调研 @Aiken 2021 笔记摘录：\n深度神经网络中的池化方法：全面调研（1989-2020） - 知乎 ；相同论文的简单中文Version 16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…\n来自 https://zhuanlan.zhihu.com/p/341820742 原文：《Pooling Methods in Deep Neural Networks, a Review》\n整合2 池化的根本目的（Motivation） 卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。\n池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层极大地减小了输入的空间尺寸。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。\n池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。 增大感受野； 降低优化难度和参数数目， 理想的池化方法应仅提取有用的信息，并丢弃无关的细节。\n特征不变性、特征降维、在一定程度上防止过拟合，更方便优化\n主流的池化方法 Average Pooling 平均池化 没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征\nMax Pooling 最大值池化 更关注重要的局部特征\n","keywords":["Pooling","Survey","Machine Learning"],"articleBody":"DownSampling：Pooling的全面调研 @Aiken 2021 笔记摘录：\n深度神经网络中的池化方法：全面调研（1989-2020） - 知乎 ；相同论文的简单中文Version 16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…\n来自 https://zhuanlan.zhihu.com/p/341820742 原文：《Pooling Methods in Deep Neural Networks, a Review》\n整合2 池化的根本目的（Motivation） 卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。\n池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层极大地减小了输入的空间尺寸。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。\n池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。 增大感受野； 降低优化难度和参数数目， 理想的池化方法应仅提取有用的信息，并丢弃无关的细节。\n特征不变性、特征降维、在一定程度上防止过拟合，更方便优化\n主流的池化方法 Average Pooling 平均池化 没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征\nMax Pooling 最大值池化 更关注重要的局部特征\nimage-20210219153154458\nMixed pooling 在max、average pooling中进行随机选择，来组合pooling\nL_p pooling 作者声称这个泛化能力比Max Pooling要好，输入的平均值权重（也就是和分之一）来进行，算是推广的公式。\n$$ s_j = (\\\\frac{1}{|R_j|}\\\\sum_{i \\\\in R_j}{a_i^p})^{1/p}\r$$\rStochastic Pooling feature_map中的元素按照其概率值大小随机选择，元素被选中的概率与数值大小正相关，这就是正则化操作了。\nimage-20210219160011182\nSpatial Pyramid Pooling （SPP） SPPNet在RCNN之后提出的，用于解决重复卷积计算和固定输出的问题，具体的方法是：在Feature_Map中通过Selective Search获得窗口然后输入CNN中。\n这个池化方法实际上就是多个空间池化的组合，对不同的输出尺度采用不同的划窗大小和步长来确保输出的尺度相同，同时能够融合多种尺度特征，提供更丰富的语意信息，常用于：\n多尺度训练 目标检测中的RPN 实际上也就是（全图pooling一次，全图分成22块Pooling，全图分成44块以后 做Pooling，然后就是固定尺寸的了，前面的输出是256-d 然后就是（4+16+1）* 256 最后的特征\nimage-20210219160238878\nYOLO v3 变体 在YOLO v3中，有一个网络结构中的yolo-v3-spp比原本的准确率更高，具体的cfg如下：\n### SPP ###\r[maxpool]\rstride=1\rsize=5\r[route]\rlayers=-2\r[maxpool]\rstride=1\rsize=9\r[route]\rlayers=-4\r[maxpool]\rstride=1\rsize=13\r[route]\rlayers=-1,-3,-5,-6\r### End SPP ### 这里的SPP是原本的SPPNet的变体，通过多个Kernel Size的maxpool 将最终得到的feature map进行concate，得到新的特征组合：\nSPP有效的原因分析 从感受野角度来讲，之前计算感受野的时候可以明显发现，maxpool的操作对感受野的影响非常大，其中主要取决于kernel size大小。在SPP中，使用了kernel size非常大的maxpool会极大提高模型的感受野，笔者没有详细计算过darknet53这个backbone的感受野，在COCO上有效很可能是因为backbone的感受野还不够大。\n第二个角度是从Attention的角度考虑，这一点启发自CSDN@小楞（链接在参考文献中），他在文章中这样讲：\n出现检测效果提升的原因：通过spp模块实现局部特征和全局特征（所以空间金字塔池化结构的最大的池化核要尽可能的接近等于需要池化的featherMap的大小）的featherMap级别的融合，丰富最终特征图的表达能力，从而提高MAP。\nAttention机制很多都是为了解决远距离依赖问题，通过使用kernel size接近特征图的size可以以比较小的计算代价解决这个问题。另外就是如果使用了SPP模块，就没有必要在SPP后继续使用其他空间注意力模块比如SK block，因为他们作用相似，可能会有一定冗余。\nRegion of Interest Pooling （ROI Pooling） 参考链接：原理以及代码实现 ；Some Detail 以及Align的改进 ；Best One 对于ROI pooling 的讲解首先要从目标检测的框架出发，帮助理解，\n目标检测分为两步：\nregion proposal：输入image，找到所有可能的object的位置（bounding box），也就是ROI，在这过程中可能用到滑窗和selective search。 final classification：确定上阶段的每个region proposal是否是目标类别，或者背景 这样的框架存在问题：\n大量的ROI要进行计算，就很难实时监测，也无法做到E2E 使用ROI Pooling进行简化，输入和作用如下：\n从多个具有卷积核池化的深度网络中获得固定大小的Feature-Map； 对不同尺寸的ROI进行处理，能得到统一的尺寸。 一个表示所有ROI的N*5的尺寸，N是数目，5维度分别是Index，左上角坐标，右下角坐标 具体实现的操作：\n根据输入image，将ROI映射到feature map对应位置； 将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）； 对每个sections进行max pooling操作； 这样我们就可以从不同大小的方框得到固定大小的相应 的feature maps。值得一提的是，输出的feature maps的大小不取决于ROI和卷积feature maps大小。ROI pooling 最大的好处就在于极大地提高了处理速度。\n下图大黑框是对应的ROI，输出最后的要求是2*2，基于下面的划分再进行maxpooling即可。\nROI Align的改进 ROI pooling在映射的时候出现小数，这是第一次量化，在每个roi中选取多少个采样点进行max pooling也会出现小数。这样的处理可能会丢失数据，降低了模型的精度\nROI Align并不需要对两步量化中产生的浮点数坐标的像素值都进行计算，而是设计了一套优雅的流程。如图2，其中虚线代表的是一个feature map，实线代表的是一个roi(在这个例子中，一个roi是分成了2*2个bins)，实心点代表的是采样点，每个bin中有4个采样点。我们通过双线性插值的方法根据采样点周围的四个点计算每一个采样点的值，然后对着四个采样点执行最大池化操作得到当前bin的像素值。\n**RoI Align做法：**假定采样点数为4，即表示，对于每个2.97 x 2.97的bin，平分四份小矩形，每一份取其中心点位置，而中心点位置的像素，采用双线性插值法进行计算，这样就会得到四个小数坐标点的像素值。\n实际上就是用双线性插值来取代了ROI Pooling的量化过程。\n新颖特殊的池化方法 这一部分的池化方法存在着一些特殊的特性，在实际需要的时候再进行仔细的研究，但是可以将大体的特征简单的描述一下，方便后续寻找。\n中值池化 与中值滤波特别类似，但是用的特别少，中值池化也具有学习边缘和纹理结构的特性，抗噪声能力比较强。\n组合池化 就是将max 和 average concate或者add起来。\nMulti-scale order-less Pooling MOP池化 基于多尺度的池化方式，提升了卷积网络的不变性同时没有破坏卷积网络的可鉴别性，分布从全局与局部池化中提取特征，图示与说明如下：\nNetVLAD Pooling NetVLAD是论文《NetVLAD: CNN Architecture for Weakly Supervised Place Recognition》提出的一个局部特征聚合的方法。\n双线性池化 Bilinear Pooling是在《Bilinear CNN Models for Fine-grained Visual Recognition》被提出的，主要用在细粒度分类网络中。双线性池化主要用于特征融合，对于同一个样本提取得到的特征x和特征y, 通过双线性池化来融合两个特征(外积)，进而提高模型分类的能力。\nUnPooling上采样操作 1.在Pooling（一般是Max Pooling）时，保存最大值的位置。\n2.中间经历若干网络层的运算。\n3.上采样阶段，利用第1步保存的Max Location，重建下一层的feature map。\nUnPooling不完全是Pooling的逆运算，Pooling之后的feature map，要经过若干运算，才会进行UnPooling操作；对于非Max Location的地方以零填充。然而这样并不能完全还原信息。\n光谱池化 图像池化不光发生在空间域，还可以通过DFT变换，在频域空间实现池化，一个使用光谱池化最大池化的例子如下：\n基于排名的均值池化 Rank-based Average Pooling\n这种池化方式的好处事可以克服最大池化与均值池化方式的不足\n$$ S_j = \\\\frac{1}{t}\\\\sum_{i\\\\in R_{j,r_i","wordCount":"232","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover14.jpeg","datePublished":"2021-06-23T13:48:56Z","dateModified":"2021-06-23T13:48:56Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/pooling/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Pooling</h1><div class=post-meta><span title='2021-06-23 13:48:56 +0000 UTC'>June 23, 2021</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;232 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/pooling> Pooling</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/Pooling.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover14.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#downsamplingpooling%e7%9a%84%e5%85%a8%e9%9d%a2%e8%b0%83%e7%a0%94 aria-label=DownSampling：Pooling的全面调研>DownSampling：Pooling的全面调研</a><ul class=header-level-1><li><a href=#%e6%b1%a0%e5%8c%96%e7%9a%84%e6%a0%b9%e6%9c%ac%e7%9b%ae%e7%9a%84motivation aria-label=池化的根本目的（Motivation）>池化的根本目的（Motivation）</a></li><li><a href=#%e4%b8%bb%e6%b5%81%e7%9a%84%e6%b1%a0%e5%8c%96%e6%96%b9%e6%b3%95 aria-label=主流的池化方法>主流的池化方法</a><ul class=header-level-2><li><a href=#average-pooling-%e5%b9%b3%e5%9d%87%e6%b1%a0%e5%8c%96 aria-label="Average Pooling 平均池化">Average Pooling 平均池化</a></li><li><a href=#max-pooling-%e6%9c%80%e5%a4%a7%e5%80%bc%e6%b1%a0%e5%8c%96 aria-label="Max Pooling 最大值池化">Max Pooling 最大值池化</a></li><li><a href=#mixed-pooling aria-label="Mixed pooling">Mixed pooling</a></li><li><a href=#l_p-pooling aria-label="L_p pooling">L_p pooling</a></li><li><a href=#stochastic-pooling aria-label="Stochastic Pooling">Stochastic Pooling</a></li><li><a href=#spatial-pyramid-pooling-spp aria-label="Spatial Pyramid Pooling （SPP）">Spatial Pyramid Pooling （SPP）</a></li><li><a href=#yolo-v3-%e5%8f%98%e4%bd%93 aria-label="YOLO v3 变体">YOLO v3 变体</a></li><li><a href=#spp%e6%9c%89%e6%95%88%e7%9a%84%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90 aria-label=SPP有效的原因分析>SPP有效的原因分析</a></li><li><a href=#region-of-interest-pooling-roi-pooling aria-label="Region of Interest Pooling （ROI Pooling）">Region of Interest Pooling （ROI Pooling）</a></li><li><a href=#roi-align%e7%9a%84%e6%94%b9%e8%bf%9b aria-label="ROI Align的改进">ROI Align的改进</a></li></ul></li><li><a href=#%e6%96%b0%e9%a2%96%e7%89%b9%e6%ae%8a%e7%9a%84%e6%b1%a0%e5%8c%96%e6%96%b9%e6%b3%95 aria-label=新颖特殊的池化方法>新颖特殊的池化方法</a><ul class=header-level-2><li><a href=#%e4%b8%ad%e5%80%bc%e6%b1%a0%e5%8c%96 aria-label=中值池化>中值池化</a></li><li><a href=#%e7%bb%84%e5%90%88%e6%b1%a0%e5%8c%96 aria-label=组合池化>组合池化</a></li><li><a href=#multi-scale-order-less-pooling-mop%e6%b1%a0%e5%8c%96 aria-label="Multi-scale order-less Pooling MOP池化">Multi-scale order-less Pooling MOP池化</a></li><li><a href=#netvlad-pooling aria-label="NetVLAD Pooling">NetVLAD Pooling</a></li><li><a href=#%e5%8f%8c%e7%ba%bf%e6%80%a7%e6%b1%a0%e5%8c%96 aria-label=双线性池化>双线性池化</a></li><li><a href=#unpooling%e4%b8%8a%e9%87%87%e6%a0%b7%e6%93%8d%e4%bd%9c aria-label=UnPooling上采样操作>UnPooling上采样操作</a></li><li><a href=#%e5%85%89%e8%b0%b1%e6%b1%a0%e5%8c%96 aria-label=光谱池化>光谱池化</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e6%8e%92%e5%90%8d%e7%9a%84%e5%9d%87%e5%80%bc%e6%b1%a0%e5%8c%96 aria-label=基于排名的均值池化>基于排名的均值池化</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e6%9d%83%e9%87%8d%e7%9a%84%e6%b1%a0%e5%8c%96 aria-label=基于权重的池化>基于权重的池化</a></li><li><a href=#edge-aware-pyramid-pooling aria-label="Edge-aware Pyramid Pooling">Edge-aware Pyramid Pooling</a></li></ul></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=downsamplingpooling的全面调研>DownSampling：Pooling的全面调研<a hidden class=anchor aria-hidden=true href=#downsamplingpooling的全面调研>#</a></h1><p>@Aiken 2021 笔记摘录：</p><p><a href=https://zhuanlan.zhihu.com/p/341820742 target=_blank rel=noopener>深度神经网络中的池化方法：全面调研（1989-2020） - 知乎</a>
；<a href=https://www.sohu.com/a/442710521_823210 target=_blank rel=noopener>相同论文的简单中文Version</a></p><p>16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视…</p><p>来自 <a href=https://zhuanlan.zhihu.com/p/341820742 target=_blank rel=noopener>https://zhuanlan.zhihu.com/p/341820742</a></p><p>原文：《Pooling Methods in Deep Neural Networks, a Review》</p><p><a href=https://zhuanlan.zhihu.com/p/112216409 target=_blank rel=noopener>整合2</a></p><h2 id=池化的根本目的motivation>池化的根本目的（Motivation）<a hidden class=anchor aria-hidden=true href=#池化的根本目的motivation>#</a></h2><p>卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。</p><p>池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层<strong>极大地减小了输入的空间尺寸</strong>。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。</p><ul><li>池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。</li><li>增大感受野；</li><li>降低优化难度和参数数目，</li></ul><p>理想的池化方法应仅提取有用的信息，并丢弃无关的细节。</p><p><strong>特征不变性、特征降维、在一定程度上防止过拟合，更方便优化</strong></p><h2 id=主流的池化方法>主流的池化方法<a hidden class=anchor aria-hidden=true href=#主流的池化方法>#</a></h2><h3 id=average-pooling-平均池化>Average Pooling 平均池化<a hidden class=anchor aria-hidden=true href=#average-pooling-平均池化>#</a></h3><p>没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征</p><h3 id=max-pooling-最大值池化>Max Pooling 最大值池化<a hidden class=anchor aria-hidden=true href=#max-pooling-最大值池化>#</a></h3><p>更关注重要的局部特征</p><p><div class=post-img-view><a data-fancybox=gallery href=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219153154458.png><img alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219153154458.png loading=lazy src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219153154458.png class=responsive-image src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219153154458.png style="display:block;margin:0 auto" alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219153154458.png></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>image-20210219153154458</p><h3 id=mixed-pooling>Mixed pooling<a hidden class=anchor aria-hidden=true href=#mixed-pooling>#</a></h3><p>在max、average pooling中进行随机选择，来组合pooling</p><h3 id=l_p-pooling>L_p pooling<a hidden class=anchor aria-hidden=true href=#l_p-pooling>#</a></h3><p>作者声称这个泛化能力比Max Pooling要好，输入的平均值权重（也就是和分之一）来进行，算是推广的公式。</p><div>$$
s_j = (\\frac{1}{|R_j|}\\sum_{i \\in R_j}{a_i^p})^{1/p}
$$</div><h3 id=stochastic-pooling>Stochastic Pooling<a hidden class=anchor aria-hidden=true href=#stochastic-pooling>#</a></h3><p>feature_map中的元素按照其概率值大小随机选择，元素被选中的概率与数值大小正相关，这就是正则化操作了。</p><p><div class=post-img-view><a data-fancybox=gallery href=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160011182.png><img alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160011182.png loading=lazy src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160011182.png class=responsive-image src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160011182.png style="display:block;margin:0 auto" alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160011182.png></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>image-20210219160011182</p><h3 id=spatial-pyramid-pooling-spp>Spatial Pyramid Pooling （SPP）<a hidden class=anchor aria-hidden=true href=#spatial-pyramid-pooling-spp>#</a></h3><p>SPPNet在RCNN之后提出的，用于解决重复卷积计算和固定输出的问题，具体的方法是：在Feature_Map中通过Selective Search获得窗口然后输入CNN中。</p><p>这个池化方法实际上就是多个空间池化的组合，对不同的输出尺度采用不同的划窗大小和步长<strong>来确保输出的尺度相同</strong>，同时能够融合多种尺度特征，提供更丰富的语意信息，常用于：</p><ul><li>多尺度训练</li><li>目标检测中的RPN</li></ul><p>实际上也就是（全图pooling一次，全图分成2<em>2块Pooling，全图分成4</em>4块以后 做Pooling，然后就是固定尺寸的了，前面的输出是256-d 然后就是（4+16+1）* 256 最后的特征</p><p><div class=post-img-view><a data-fancybox=gallery href=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160238878.png><img alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160238878.png loading=lazy src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160238878.png class=responsive-image src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160238878.png style="display:block;margin:0 auto" alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210219160238878.png></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>image-20210219160238878</p><h3 id=yolo-v3-变体>YOLO v3 变体<a hidden class=anchor aria-hidden=true href=#yolo-v3-变体>#</a></h3><p>在YOLO v3中，有一个网络结构中的yolo-v3-spp比原本的准确率更高，具体的cfg如下：</p><pre tabindex=0><code>### SPP ###
[maxpool]
stride=1
size=5

[route]
layers=-2

[maxpool]
stride=1
size=9

[route]
layers=-4

[maxpool]
stride=1
size=13

[route]
layers=-1,-3,-5,-6

### End SPP ###
</code></pre><p>这里的SPP是原本的SPPNet的变体，通过多个Kernel Size的maxpool 将最终得到的feature map进行concate，得到新的特征组合：</p><h3 id=spp有效的原因分析>SPP有效的原因分析<a hidden class=anchor aria-hidden=true href=#spp有效的原因分析>#</a></h3><ol><li><p>从感受野角度来讲，之前计算感受野的时候可以明显发现，maxpool的操作对感受野的影响非常大，其中主要取决于kernel size大小。在SPP中，使用了kernel size非常大的maxpool会极大提高模型的感受野，笔者没有详细计算过darknet53这个backbone的感受野，在COCO上有效很可能是因为backbone的感受野还不够大。</p></li><li><p>第二个角度是从Attention的角度考虑，这一点启发自CSDN@小楞（链接在参考文献中），他在文章中这样讲：</p><blockquote><p>出现检测效果提升的原因：通过spp模块实现局部特征和全局特征（所以空间金字塔池化结构的最大的池化核要尽可能的接近等于需要池化的featherMap的大小）的featherMap级别的融合，丰富最终特征图的表达能力，从而提高MAP。</p></blockquote></li><li><p>Attention机制很多都是为了解决远距离依赖问题，通过使用kernel size接近特征图的size可以以比较小的计算代价解决这个问题。另外就是如果使用了SPP模块，就没有必要在SPP后继续使用其他空间注意力模块比如SK block，因为他们作用相似，可能会有一定冗余。</p></li></ol><h3 id=region-of-interest-pooling-roi-pooling>Region of Interest Pooling （ROI Pooling）<a hidden class=anchor aria-hidden=true href=#region-of-interest-pooling-roi-pooling>#</a></h3><p>参考链接：<a href=https://blog.csdn.net/u011436429/article/details/80279536 target=_blank rel=noopener>原理以及代码实现</a>
；<a href=https://zhuanlan.zhihu.com/p/59692298 target=_blank rel=noopener>Some Detail 以及Align的改进</a>
；<a href=https://www.sohu.com/a/414474326_823210 target=_blank rel=noopener>Best One</a></p><p>对于ROI pooling 的讲解首先要从目标检测的框架出发，帮助理解，</p><p>目标检测分为两步：</p><ol><li>region proposal：输入image，找到所有可能的object的位置（bounding box），也就是ROI，在这过程中可能用到滑窗和selective search。</li><li>final classification：确定上阶段的每个region proposal是否是目标类别，或者背景</li></ol><p>这样的框架<strong>存在问题：</strong></p><ul><li>大量的ROI要进行计算，就很难实时监测，也无法做到E2E</li></ul><p>使用ROI Pooling进行简化，<strong>输入和作用</strong>如下：</p><ul><li>从多个具有卷积核池化的深度网络中获得固定大小的Feature-Map；
对不同尺寸的ROI进行处理，能得到统一的尺寸。</li><li>一个表示所有ROI的N*5的尺寸，N是数目，5维度分别是Index，左上角坐标，右下角坐标</li></ul><p>具体实现的操作：</p><ol><li>根据输入image，将ROI映射到feature map对应位置；</li><li>将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）；</li><li>对每个sections进行max pooling操作；</li></ol><p>这样我们就可以从不同大小的方框得到固定大小的相应 的feature maps。值得一提的是，输出的feature maps的大小不取决于ROI和卷积feature maps大小。ROI pooling 最大的好处就在于极大地提高了处理速度。</p><p>下图大黑框是对应的ROI，输出最后的要求是2*2，基于下面的划分再进行maxpooling即可。</p><h3 id=roi-align的改进>ROI Align的改进<a hidden class=anchor aria-hidden=true href=#roi-align的改进>#</a></h3><p>ROI pooling在映射的时候出现小数，这是第一次量化，在每个roi中选取多少个采样点进行max pooling也会出现小数。这样的处理可能会丢失数据，降低了模型的精度</p><p>ROI Align并不需要对两步量化中产生的浮点数坐标的像素值都进行计算，而是设计了一套优雅的流程。如图2，其中虚线代表的是一个feature map，实线代表的是一个roi(在这个例子中，一个roi是分成了2*2个bins)，实心点代表的是采样点，每个bin中有4个采样点。我们通过双线性插值的方法根据采样点周围的四个点计算每一个采样点的值，然后对着四个采样点执行最大池化操作得到当前bin的像素值。</p><p>**RoI Align做法：**假定采样点数为4，即表示，对于每个2.97 x 2.97的bin，<strong>平分四份小矩形，每一份取其中心点位置，而中心点位置的像素，采用双线性插值法进行计算</strong>，这样就会得到四个小数坐标点的像素值。</p><p>实际上就是用双线性插值来取代了ROI Pooling的量化过程。</p><h2 id=新颖特殊的池化方法>新颖特殊的池化方法<a hidden class=anchor aria-hidden=true href=#新颖特殊的池化方法>#</a></h2><p>这一部分的池化方法存在着一些特殊的特性，在实际需要的时候再进行仔细的研究，但是可以将大体的特征简单的描述一下，方便后续寻找。</p><h3 id=中值池化>中值池化<a hidden class=anchor aria-hidden=true href=#中值池化>#</a></h3><p>与中值滤波特别类似，但是用的特别少，中值池化也具有学习边缘和纹理结构的特性，抗噪声能力比较强。</p><h3 id=组合池化>组合池化<a hidden class=anchor aria-hidden=true href=#组合池化>#</a></h3><p>就是将max 和 average concate或者add起来。</p><h3 id=multi-scale-order-less-pooling-mop池化>Multi-scale order-less Pooling MOP池化<a hidden class=anchor aria-hidden=true href=#multi-scale-order-less-pooling-mop池化>#</a></h3><p>基于多尺度的池化方式，提升了卷积网络的不变性同时没有破坏卷积网络的可鉴别性，分布从全局与局部池化中提取特征，图示与说明如下：</p><h3 id=netvlad-pooling>NetVLAD Pooling<a hidden class=anchor aria-hidden=true href=#netvlad-pooling>#</a></h3><p>NetVLAD是论文《NetVLAD: CNN Architecture for Weakly Supervised Place Recognition》提出的一个局部特征聚合的方法。</p><h3 id=双线性池化>双线性池化<a hidden class=anchor aria-hidden=true href=#双线性池化>#</a></h3><p>Bilinear Pooling是在《Bilinear CNN Models for Fine-grained Visual Recognition》被提出的，主要用在细粒度分类网络中。双线性池化主要用于特征融合，对于同一个样本提取得到的特征x和特征y, 通过双线性池化来融合两个特征(外积)，进而提高模型分类的能力。</p><h3 id=unpooling上采样操作>UnPooling上采样操作<a hidden class=anchor aria-hidden=true href=#unpooling上采样操作>#</a></h3><p>1.在Pooling（一般是Max Pooling）时，保存最大值的位置。</p><p>2.中间经历若干网络层的运算。</p><p>3.上采样阶段，利用第1步保存的Max Location，重建下一层的feature map。</p><blockquote><p><strong>UnPooling不完全是Pooling的逆运算</strong>，Pooling之后的feature map，要经过若干运算，才会进行UnPooling操作；对于非Max Location的地方以零填充。然而这样并不能完全还原信息。</p></blockquote><h3 id=光谱池化>光谱池化<a hidden class=anchor aria-hidden=true href=#光谱池化>#</a></h3><p>图像池化不光发生在空间域，<strong>还可以通过DFT变换，在频域空间实现池化</strong>，一个使用光谱池化最大池化的例子如下：</p><h3 id=基于排名的均值池化>基于排名的均值池化<a hidden class=anchor aria-hidden=true href=#基于排名的均值池化>#</a></h3><p><strong>Rank-based Average Pooling</strong></p><p>这种池化方式的好处事可以克服最大池化与均值池化方式的不足</p><div>$$
S_j = \\frac{1}{t}\\sum_{i\\in R_{j,r_i<t}} a_i $$ </div><h3 id=基于权重的池化>基于权重的池化<a hidden class=anchor aria-hidden=true href=#基于权重的池化>#</a></h3><h3 id=edge-aware-pyramid-pooling>Edge-aware Pyramid Pooling<a hidden class=anchor aria-hidden=true href=#edge-aware-pyramid-pooling>#</a></h3><p><a href=Pooling%20b5b6c37730b54ff89114750889d54aec/Survey_NIPS%20%E4%B8%AD%E5%9B%BD%E9%A2%84%E8%AE%B2%E4%BC%9A%20md%20a89f987a08854a2c9c2fb44213136246.md>Survey_NIPS 中国预讲会.md</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/pooling/>Pooling</a></li><li><a href=https://hugotest-phi.vercel.app/tags/survey/>Survey</a></li><li><a href=https://hugotest-phi.vercel.app/tags/machine-learning/>Machine Learning</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/intview_%E7%AC%94%E8%AF%95%E9%A2%98%E5%9E%8B%E5%92%8C%E6%A1%86%E6%9E%B6%E6%80%BB%E7%BB%93/><span class=title>« Prev</span><br><span>Leetcode 题型和框架代码总结</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/ow-openmix/><span class=title>Next »</span><br><span>OW-openmix</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>