<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Fine Tuning | aiken's blog</title>
<meta name=keywords content="Pytorch,Fine-Tune,Machine Learning"><meta name=description content="@Langs: python, torch
@reference: d2l-pytorch，transfer_torch

This Note focus on the code part.
模型微调和模型预训练，在Pytorch中的使用方式对比汇总。
How to Design the Fine Tune
这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。


  
    
  





基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。
在Transfer任务中，有几种不同的调整方式：

固定Bakcbone，只训练Classifier
同步微调网络
区分学习率，微调Backbone，训练Classifirer

为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。
Code Part
不同lr设置
微调Backbone，训练Classifier作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。

相关的文档可以参考：torch.optim



 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26


# get dataset
train_img = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))

# get new model
pretrained_new = model.expand_dim(dim=out_dim,re_init=True)

# pre train it 定义一个用于微调的函数
# pytorch可以通过字典的形式来区分对设置lr
def train_fine_tuning(net, learning_rate, batch_size=128, num_epoch=5, diff_lr=True):
	# set dataloader
	train_iter = torch.utils.Dataloader(train_img, batch_size=batch_size, shuffle=True)
	test_iter = ...
	
	# set loss
	loss = nn.CrossEntropyLoss(reduction='none')
	
	# set diff lr for diff part of it 
	if diff_lr:
		params_1x = [param for name, param in net.name_parameters() if name not in [&#34;fc.weight&#34;, &#34;fc.bias&#34;]]
		trainer = torch.optim.SGD([{'params': params_1x},
								  {'params': net.fc.parameters(),
								  'lr': learning_rate *10}],
								  lr=learning_rate, weight_decay=0.001
								 )
	else:
		trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)


同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/finetune/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/finetune/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/finetune/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Fine Tuning"><meta property="og:description" content="@Langs: python, torch @reference: d2l-pytorch，transfer_torch This Note focus on the code part. 模型微调和模型预训练，在Pytorch中的使用方式对比汇总。
How to Design the Fine Tune 这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。
基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。
在Transfer任务中，有几种不同的调整方式：
固定Bakcbone，只训练Classifier 同步微调网络 区分学习率，微调Backbone，训练Classifirer 为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。
Code Part 不同lr设置 微调Backbone，训练Classifier作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。
相关的文档可以参考：torch.optim 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # get dataset train_img = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train')) # get new model pretrained_new = model.expand_dim(dim=out_dim,re_init=True) # pre train it 定义一个用于微调的函数 # pytorch可以通过字典的形式来区分对设置lr def train_fine_tuning(net, learning_rate, batch_size=128, num_epoch=5, diff_lr=True): # set dataloader train_iter = torch.utils.Dataloader(train_img, batch_size=batch_size, shuffle=True) test_iter = ... # set loss loss = nn.CrossEntropyLoss(reduction='none') # set diff lr for diff part of it if diff_lr: params_1x = [param for name, param in net.name_parameters() if name not in [&#34;fc.weight&#34;, &#34;fc.bias&#34;]] trainer = torch.optim.SGD([{'params': params_1x}, {'params': net.fc.parameters(), 'lr': learning_rate *10}], lr=learning_rate, weight_decay=0.001 ) else: trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001) 同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-02-08T14:31:37+00:00"><meta property="article:modified_time" content="2022-02-08T14:31:37+00:00"><meta property="article:tag" content="Pytorch"><meta property="article:tag" content="Fine-Tune"><meta property="article:tag" content="Machine Learning"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover10.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover10.jpeg"><meta name=twitter:title content="Fine Tuning"><meta name=twitter:description content="@Langs: python, torch
@reference: d2l-pytorch，transfer_torch

This Note focus on the code part.
模型微调和模型预训练，在Pytorch中的使用方式对比汇总。
How to Design the Fine Tune
这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。


  
    
  





基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。
在Transfer任务中，有几种不同的调整方式：

固定Bakcbone，只训练Classifier
同步微调网络
区分学习率，微调Backbone，训练Classifirer

为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。
Code Part
不同lr设置
微调Backbone，训练Classifier作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。

相关的文档可以参考：torch.optim



 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26


# get dataset
train_img = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))

# get new model
pretrained_new = model.expand_dim(dim=out_dim,re_init=True)

# pre train it 定义一个用于微调的函数
# pytorch可以通过字典的形式来区分对设置lr
def train_fine_tuning(net, learning_rate, batch_size=128, num_epoch=5, diff_lr=True):
	# set dataloader
	train_iter = torch.utils.Dataloader(train_img, batch_size=batch_size, shuffle=True)
	test_iter = ...
	
	# set loss
	loss = nn.CrossEntropyLoss(reduction='none')
	
	# set diff lr for diff part of it 
	if diff_lr:
		params_1x = [param for name, param in net.name_parameters() if name not in [&#34;fc.weight&#34;, &#34;fc.bias&#34;]]
		trainer = torch.optim.SGD([{'params': params_1x},
								  {'params': net.fc.parameters(),
								  'lr': learning_rate *10}],
								  lr=learning_rate, weight_decay=0.001
								 )
	else:
		trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)


同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"Fine Tuning","item":"https://hugotest-phi.vercel.app/posts/finetune/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Fine Tuning","name":"Fine Tuning","description":"@Langs: python, torch @reference: d2l-pytorch，transfer_torch This Note focus on the code part. 模型微调和模型预训练，在Pytorch中的使用方式对比汇总。\nHow to Design the Fine Tune 这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。\n基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。\n在Transfer任务中，有几种不同的调整方式：\n固定Bakcbone，只训练Classifier 同步微调网络 区分学习率，微调Backbone，训练Classifirer 为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。\nCode Part 不同lr设置 微调Backbone，训练Classifier作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。\n相关的文档可以参考：torch.optim 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # get dataset train_img = torchvision.datasets.ImageFolder(os.path.join(data_dir, \u0026#39;train\u0026#39;)) # get new model pretrained_new = model.expand_dim(dim=out_dim,re_init=True) # pre train it 定义一个用于微调的函数 # pytorch可以通过字典的形式来区分对设置lr def train_fine_tuning(net, learning_rate, batch_size=128, num_epoch=5, diff_lr=True): # set dataloader train_iter = torch.utils.Dataloader(train_img, batch_size=batch_size, shuffle=True) test_iter = ... # set loss loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) # set diff lr for diff part of it if diff_lr: params_1x = [param for name, param in net.name_parameters() if name not in [\u0026#34;fc.weight\u0026#34;, \u0026#34;fc.bias\u0026#34;]] trainer = torch.optim.SGD([{\u0026#39;params\u0026#39;: params_1x}, {\u0026#39;params\u0026#39;: net.fc.parameters(), \u0026#39;lr\u0026#39;: learning_rate *10}], lr=learning_rate, weight_decay=0.001 ) else: trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001) 同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试\n","keywords":["Pytorch","Fine-Tune","Machine Learning"],"articleBody":"@Langs: python, torch @reference: d2l-pytorch，transfer_torch This Note focus on the code part. 模型微调和模型预训练，在Pytorch中的使用方式对比汇总。\nHow to Design the Fine Tune 这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。\n基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。\n在Transfer任务中，有几种不同的调整方式：\n固定Bakcbone，只训练Classifier 同步微调网络 区分学习率，微调Backbone，训练Classifirer 为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。\nCode Part 不同lr设置 微调Backbone，训练Classifier作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。\n相关的文档可以参考：torch.optim 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # get dataset train_img = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train')) # get new model pretrained_new = model.expand_dim(dim=out_dim,re_init=True) # pre train it 定义一个用于微调的函数 # pytorch可以通过字典的形式来区分对设置lr def train_fine_tuning(net, learning_rate, batch_size=128, num_epoch=5, diff_lr=True): # set dataloader train_iter = torch.utils.Dataloader(train_img, batch_size=batch_size, shuffle=True) test_iter = ... # set loss loss = nn.CrossEntropyLoss(reduction='none') # set diff lr for diff part of it if diff_lr: params_1x = [param for name, param in net.name_parameters() if name not in [\"fc.weight\", \"fc.bias\"]] trainer = torch.optim.SGD([{'params': params_1x}, {'params': net.fc.parameters(), 'lr': learning_rate *10}], lr=learning_rate, weight_decay=0.001 ) else: trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001) 同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试\n1 2 3 4 5 6 7 8 9 optimizer = torch.optim.SGD([{'params': [torch.rand((2,2), requires_grad=True)]}, {'params': [torch.rand((2,2), requires_grad=True)],'lr': 0.01}], lr=0.1, momentum=0.9) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1, verbose=False) for epoch in range(1,10): scheduler.step() print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr'])) print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[1]['lr'])) 梯度截断 PyTorch Docs 保留Backbone，训练Classifier，截断网络向Backbone的回传，设置学习率仅训练分类器。\n表面上写的梯度截断，实际上我们需要做的就是不让优化器优化模型即可，不需要截断梯度的运算，也就是在optim的参数种不添加其他部分的网络即可,\n也就是反向一下上面的params_1x即可，然后添加对应的参数。\n还有另一种方式，也是官方的实现，也就是使用require_grad来对不需要进行梯度计算的单元进行覆盖设置。 具体的代码可以参考如下：\n1 2 3 4 5 6 for name, params in model.name_parameters(): if name not in['fc.weight', 'fc.bias']: params.require_grad = False parameters = [p for p in model.parameters() if p.require_grad] assert len(parameters) == 2 加载部分模型 在自监督学习中，只加载Backbone或者只加载Classifier的情况是非常常见的，这就需要我们仅仅加载部分的参数，为了实现该目标，我们可以按照如下的方式进行操作\n1 2 3 4 5 6 7 8 9 # 读取训练好的模型参数，获取当前模型的字典 ckpt = torch.load(pretrain_opt['pth'])['model'] model_dict = model.state_dict() # 获取特定的‘key’将该字典用来更新模型的参数 pretrain_dict = {k:v for k,v in ckpt.items() if 'backbone' in k and 'fc' not in k} # 更新模型的dict后进行载入 model_dict.update(pretrain_dict) model.load_state_dict(model_dict) 函数中的update需要参数的key和模型中的字典完全匹配，结构相同也不行，因此，在这里还会遇到一个另外的问题就是，模型名称失配问题。\n而为了解决这个问题，最简单直接的方法就是，修改对应的key，最内层基本都是一致的，名称上的区别只在于，我们外层的结构不同。\n1 pre_projector_dict = {k.replace('classifier.', ''):v for k,v in ckpt.items() if 'classifier' in k} 由此便可以完成对部分模型的加载和匹配。\n","wordCount":"281","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover10.jpeg","datePublished":"2022-02-08T14:31:37Z","dateModified":"2022-02-08T14:31:37Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/finetune/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Fine Tuning</h1><div class=post-meta><span title='2022-02-08 14:31:37 +0000 UTC'>February 8, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;281 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/pytorch> Pytorch</a>&nbsp;·&nbsp;<a href=/tags/fine-tune> Fine-Tune</a>&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/FineTune.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover10.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#how-to-design-the-fine-tune aria-label="How to Design the Fine Tune">How to Design the Fine Tune</a></li><li><a href=#code-part aria-label="Code Part">Code Part</a><ul class=header-level-2><li><a href=#%e4%b8%8d%e5%90%8clr%e8%ae%be%e7%bd%ae aria-label=不同lr设置>不同lr设置</a></li><li><a href=#%e6%a2%af%e5%ba%a6%e6%88%aa%e6%96%ad aria-label=梯度截断>梯度截断</a></li><li><a href=#%e5%8a%a0%e8%bd%bd%e9%83%a8%e5%88%86%e6%a8%a1%e5%9e%8b aria-label=加载部分模型>加载部分模型</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>@Langs: python, torch
@reference: d2l-pytorch，<a href=https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html target=_blank rel=noopener>transfer_torch</a></p><p>This Note focus on the code part.
模型微调和模型预训练，在Pytorch中的使用方式对比汇总。</p><h2 id=how-to-design-the-fine-tune>How to Design the Fine Tune<a hidden class=anchor aria-hidden=true href=#how-to-design-the-fine-tune>#</a></h2><p>这一部分主要集中于我们对于微调任务的拆解，有几种不同的预训练和微调的方式，在不同的情景下，对应的参数应该怎么设置和调整是问题的重点。</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211205143153.png><img alt=WorkFlow loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211205143153.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211205143153.png style="display:block;margin:0 auto" alt=WorkFlow></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>基于这种Transfer的策略，我们能够学习到一个更通用，泛化能力更强，有助于识别边缘，色彩，等等有助于下游任务的通用特征提取。</p><p>在Transfer任务中，有几种不同的调整方式：</p><ul><li>固定Bakcbone，只训练Classifier</li><li>同步微调网络</li><li>区分学习率，微调Backbone，训练Classifirer</li></ul><p>为了实现这几种不同的Transfer方式，需要用到以下的几种方式：梯度截断，lr区分设置等。</p><h2 id=code-part>Code Part<a hidden class=anchor aria-hidden=true href=#code-part>#</a></h2><h3 id=不同lr设置>不同lr设置<a hidden class=anchor aria-hidden=true href=#不同lr设置>#</a></h3><p><strong>微调Backbone，训练Classifier</strong>作为最经典的Transfer设定，在Code上也较为复杂，所以我们首先举个这种例子。</p><p>相关的文档可以参考：<a href=https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-optim/ target=_blank rel=noopener>torch.optim</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># get dataset</span>
</span></span><span class=line><span class=cl><span class=n>train_img</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>ImageFolder</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_dir</span><span class=p>,</span> <span class=s1>&#39;train&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># get new model</span>
</span></span><span class=line><span class=cl><span class=n>pretrained_new</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>expand_dim</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=n>out_dim</span><span class=p>,</span><span class=n>re_init</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># pre train it 定义一个用于微调的函数</span>
</span></span><span class=line><span class=cl><span class=c1># pytorch可以通过字典的形式来区分对设置lr</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_fine_tuning</span><span class=p>(</span><span class=n>net</span><span class=p>,</span> <span class=n>learning_rate</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>num_epoch</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>diff_lr</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=c1># set dataloader</span>
</span></span><span class=line><span class=cl>	<span class=n>train_iter</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>Dataloader</span><span class=p>(</span><span class=n>train_img</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>test_iter</span> <span class=o>=</span> <span class=o>...</span>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	<span class=c1># set loss</span>
</span></span><span class=line><span class=cl>	<span class=n>loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>(</span><span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	<span class=c1># set diff lr for diff part of it </span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=n>diff_lr</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>params_1x</span> <span class=o>=</span> <span class=p>[</span><span class=n>param</span> <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>net</span><span class=o>.</span><span class=n>name_parameters</span><span class=p>()</span> <span class=k>if</span> <span class=n>name</span> <span class=ow>not</span> <span class=ow>in</span> <span class=p>[</span><span class=s2>&#34;fc.weight&#34;</span><span class=p>,</span> <span class=s2>&#34;fc.bias&#34;</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>		<span class=n>trainer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>([{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>params_1x</span><span class=p>},</span>
</span></span><span class=line><span class=cl>								  <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>net</span><span class=o>.</span><span class=n>fc</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>								  <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>learning_rate</span> <span class=o>*</span><span class=mi>10</span><span class=p>}],</span>
</span></span><span class=line><span class=cl>								  <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.001</span>
</span></span><span class=line><span class=cl>								 <span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>trainer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>net</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>同时不用担心，scheduler可以将我们的两组lr同时进行更新，可以基于下面的代码进行测试</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>([{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>),</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)]},</span>
</span></span><span class=line><span class=cl>                            <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>),</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)],</span><span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=mf>0.01</span><span class=p>}],</span> 
</span></span><span class=line><span class=cl>                            <span class=n>lr</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>step_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Epoch-</span><span class=si>{0}</span><span class=s1> lr: </span><span class=si>{1}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>epoch</span><span class=p>,</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;lr&#39;</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Epoch-</span><span class=si>{0}</span><span class=s1> lr: </span><span class=si>{1}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>epoch</span><span class=p>,</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>1</span><span class=p>][</span><span class=s1>&#39;lr&#39;</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=梯度截断>梯度截断<a hidden class=anchor aria-hidden=true href=#梯度截断>#</a></h3><p><a href=https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html target=_blank rel=noopener>PyTorch Docs</a></p><p><strong>保留Backbone，训练Classifier</strong>，截断网络向Backbone的回传，设置学习率仅训练分类器。</p><p>表面上写的梯度截断，实际上我们需要做的就是不让优化器优化模型即可，不需要截断梯度的运算，也就是在optim的参数种不添加其他部分的网络即可,</p><p>也就是反向一下上面的params_1x即可，然后添加对应的参数。</p><p>还有另一种方式，也是官方的实现，也就是使用require_grad来对不需要进行梯度计算的单元进行覆盖设置。
具体的代码可以参考如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>params</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>name_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=n>name</span> <span class=ow>not</span> <span class=ow>in</span><span class=p>[</span><span class=s1>&#39;fc.weight&#39;</span><span class=p>,</span> <span class=s1>&#39;fc.bias&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>		<span class=n>params</span><span class=o>.</span><span class=n>require_grad</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>parameters</span> <span class=o>=</span> <span class=p>[</span><span class=n>p</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()</span> <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>require_grad</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>parameters</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=加载部分模型>加载部分模型<a hidden class=anchor aria-hidden=true href=#加载部分模型>#</a></h3><p>在自监督学习中，只加载Backbone或者只加载Classifier的情况是非常常见的，这就需要我们仅仅加载部分的参数，为了实现该目标，我们可以按照如下的方式进行操作</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 读取训练好的模型参数，获取当前模型的字典</span>
</span></span><span class=line><span class=cl><span class=n>ckpt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>pretrain_opt</span><span class=p>[</span><span class=s1>&#39;pth&#39;</span><span class=p>])[</span><span class=s1>&#39;model&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>model_dict</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 获取特定的‘key’将该字典用来更新模型的参数</span>
</span></span><span class=line><span class=cl><span class=n>pretrain_dict</span> <span class=o>=</span> <span class=p>{</span><span class=n>k</span><span class=p>:</span><span class=n>v</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span><span class=n>v</span> <span class=ow>in</span> <span class=n>ckpt</span><span class=o>.</span><span class=n>items</span><span class=p>()</span> <span class=k>if</span> <span class=s1>&#39;backbone&#39;</span> <span class=ow>in</span> <span class=n>k</span> <span class=ow>and</span> <span class=s1>&#39;fc&#39;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>k</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 更新模型的dict后进行载入</span>
</span></span><span class=line><span class=cl><span class=n>model_dict</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>pretrain_dict</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>model_dict</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>函数中的<code>update</code>需要参数的<code>key</code>和模型中的字典完全匹配，结构相同也不行，因此，在这里还会遇到一个另外的问题就是，<strong>模型名称失配问题</strong>。</p><p>而为了解决这个问题，最简单直接的方法就是，修改对应的key，最内层基本都是一致的，名称上的区别只在于，我们外层的结构不同。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>pre_projector_dict</span> <span class=o>=</span> <span class=p>{</span><span class=n>k</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;classifier.&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>):</span><span class=n>v</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span><span class=n>v</span> <span class=ow>in</span> <span class=n>ckpt</span><span class=o>.</span><span class=n>items</span><span class=p>()</span> <span class=k>if</span> <span class=s1>&#39;classifier&#39;</span> <span class=ow>in</span> <span class=n>k</span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>由此便可以完成对部分模型的加载和匹配。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/pytorch/>Pytorch</a></li><li><a href=https://hugotest-phi.vercel.app/tags/fine-tune/>Fine-Tune</a></li><li><a href=https://hugotest-phi.vercel.app/tags/machine-learning/>Machine Learning</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/picbed/><span class=title>« Prev</span><br><span>PicBed Setting for note and blog</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/git_manual1/><span class=title>Next »</span><br><span>Git 01 入门与常用操作</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>