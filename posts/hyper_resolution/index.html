<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Hyper-Resolution | aiken's blog</title>
<meta name=keywords content="Survey,HyperResolution"><meta name=description content='说明：重点针对超分辨率技术
备注：
超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波
超分辨率在表情识别中的应用
KEY WORDs ：

1. ("super resolution" OR "image restore") AND ("facial expression recognition" OR "emotion recognition")   
2. ("super resolution") AND  ("expression recognition")   


< Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach >



针对于低带宽传输的分辨率不足和比率低的应用场景
基于facial expression recognition 的 emotion recognition
在解码器进行视频下采样的时候，联合SR和识别




< Effective image super resolution via hierarchical convolutional neural network >



通过层次卷积神经网络(HCNN)来实现有校的SR
在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能




< Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images >
'><meta name=author content="aikenhong"><link rel=canonical href=https://aikenh.cn/hugotest/posts/hyper_resolution/><link crossorigin=anonymous href=/hugotest/assets/css/stylesheet.2f85ca17c12c62fa86b1e474b8a51aca4856f0d645debfe4922a4d5ddc6aa978.css integrity="sha256-L4XKF8EsYvqGseR0uKUaykhW8NZF3r/kkipNXdxqqXg=" rel="preload stylesheet" as=style><link rel=icon href=https://aikenh.cn/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://aikenh.cn/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://aikenh.cn/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://aikenh.cn/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://aikenh.cn/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://aikenh.cn/hugotest/posts/hyper_resolution/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://aikenh.cn/hugotest/posts/hyper_resolution/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Hyper-Resolution"><meta property="og:description" content='说明：重点针对超分辨率技术
备注： 超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波
超分辨率在表情识别中的应用 KEY WORDs ：1. ("super resolution" OR "image restore") AND ("facial expression recognition" OR "emotion recognition") 2. ("super resolution") AND ("expression recognition") < Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach > 针对于低带宽传输的分辨率不足和比率低的应用场景 基于facial expression recognition 的 emotion recognition 在解码器进行视频下采样的时候，联合SR和识别 < Effective image super resolution via hierarchical convolutional neural network > 通过层次卷积神经网络(HCNN)来实现有校的SR 在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能 < Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images > '><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-03-06T14:55:02+00:00"><meta property="article:modified_time" content="2020-03-06T14:55:02+00:00"><meta property="article:tag" content="Survey"><meta property="article:tag" content="HyperResolution"><meta property="og:image" content="https://aikenh.cn/cover/cover5.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://aikenh.cn/cover/cover5.jpeg"><meta name=twitter:title content="Hyper-Resolution"><meta name=twitter:description content='说明：重点针对超分辨率技术
备注：
超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波
超分辨率在表情识别中的应用
KEY WORDs ：

1. ("super resolution" OR "image restore") AND ("facial expression recognition" OR "emotion recognition")   
2. ("super resolution") AND  ("expression recognition")   


< Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach >



针对于低带宽传输的分辨率不足和比率低的应用场景
基于facial expression recognition 的 emotion recognition
在解码器进行视频下采样的时候，联合SR和识别




< Effective image super resolution via hierarchical convolutional neural network >



通过层次卷积神经网络(HCNN)来实现有校的SR
在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能




< Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images >
'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://aikenh.cn/hugotest/posts/"},{"@type":"ListItem","position":2,"name":"Hyper-Resolution","item":"https://aikenh.cn/hugotest/posts/hyper_resolution/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hyper-Resolution","name":"Hyper-Resolution","description":"说明：重点针对超分辨率技术\n备注： 超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波\n超分辨率在表情识别中的应用 KEY WORDs ：\r1. (\u0026#34;super resolution\u0026#34; OR \u0026#34;image restore\u0026#34;) AND (\u0026#34;facial expression recognition\u0026#34; OR \u0026#34;emotion recognition\u0026#34;) 2. (\u0026#34;super resolution\u0026#34;) AND (\u0026#34;expression recognition\u0026#34;) \u0026lt; Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach \u0026gt; 针对于低带宽传输的分辨率不足和比率低的应用场景 基于facial expression recognition 的 emotion recognition 在解码器进行视频下采样的时候，联合SR和识别 \u0026lt; Effective image super resolution via hierarchical convolutional neural network \u0026gt; 通过层次卷积神经网络(HCNN)来实现有校的SR 在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能 \u0026lt; Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images \u0026gt; ","keywords":["Survey","HyperResolution"],"articleBody":"说明：重点针对超分辨率技术\n备注： 超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波\n超分辨率在表情识别中的应用 KEY WORDs ：\r1. (\"super resolution\" OR \"image restore\") AND (\"facial expression recognition\" OR \"emotion recognition\") 2. (\"super resolution\") AND (\"expression recognition\") \u003c Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach \u003e 针对于低带宽传输的分辨率不足和比率低的应用场景 基于facial expression recognition 的 emotion recognition 在解码器进行视频下采样的时候，联合SR和识别 \u003c Effective image super resolution via hierarchical convolutional neural network \u003e 通过层次卷积神经网络(HCNN)来实现有校的SR 在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能 \u003c Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images \u003e 有点擦边吧，就是基于超分辨率算法的多分辨率图像，对面部进行识别从而判断疼痛程度 也可能妹啥用，你可以考虑一下 \u003c Low-resolution facial expression recognition: A filter learning perspective \u003e 摘要中没有明确的提到Super-Resolution， 但是感觉低分辨率这个问题前缀，可能和SR有关系来着 \u003c PKU_ICST at TRECVID 2019: Instance Search Task \u003e 好像是什么比赛，过程中有一部分是面部表情检测 在识别之前采取了超分辨率的查询增强 \u003c Facial Expression Restoration Based on Improved Graph Convolutional Networks \u003e 针对分辨率低和部分遮挡的面部表情识别 GAN IGCN RRMB 修复和超分辨率面部表情 图像恢复技术、图像增强技术、人脸增强技术在表情识别中的应用 KEY WORDs：\r1. (\"super resolution\" OR \"image restore\") AND (\"facial expression recognition\" OR \"emotion recognition\") 2. (\"image restore\") AND (\"expression recognition\") ——NONE\r3. (\"Image enhancement\") AND (\"facial expression recognition\")\r4. (\"face enhancement\") AND (\"facial expression recognition\")\r5. (\"Image restoration\") AND (\"facial expression recognition\") \u003c Efficient facial expression recognition via convolution neural network and infrared imaging technology \u003e 离散小波变换正则化和快速盲恢复模型来重建红外光谱。。。。来帮助面部表情识别 针对光，姿势变化，噪声和遮挡的人脸识别？AND 其他 \u003c Facial appearance and texture feature-based robust facial expression recognition framework for sentiment knowledge discovery \u003e 没有提到超分辨率或是图像重建 但是有提到标题那几个，结合局部和全局特征… \u003c Improving Facial Emotion Recognition Systems with Crucial Feature Extractors \u003e 是对表情识别的增强但是好像不是图像增强….. 基于特征提取的增强把 ","wordCount":"210","inLanguage":"en","image":"https://aikenh.cn/cover/cover5.jpeg","datePublished":"2020-03-06T14:55:02Z","dateModified":"2020-03-06T14:55:02Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://aikenh.cn/hugotest/posts/hyper_resolution/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://aikenh.cn/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://aikenh.cn/hugotest/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://aikenh.cn/hugotest/ title=home><span>home</span></a></li><li><a href=https://aikenh.cn/hugotest/posts/ title=posts><span>posts</span></a></li><li><a href=https://aikenh.cn/hugotest/tags/ title=tags><span>tags</span></a></li><li><a href=https://aikenh.cn/hugotest/categories/ title=categories><span>categories</span></a></li><li><a href=https://aikenh.cn/hugotest/archives/ title=archives><span>archives</span></a></li><li><a href=https://aikenh.cn/hugotest/about/ title=about><span>about</span></a></li><li><a href=https://aikenh.cn/hugotest/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://aikenh.cn/hugotest/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://aikenh.cn/hugotest/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://aikenh.cn/hugotest/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://aikenh.cn/hugotest/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://aikenh.cn/hugotest/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://aikenh.cn/hugotest/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://aikenh.cn/hugotest/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://aikenh.cn/hugotest/>Home</a>&nbsp;»&nbsp;<a href=https://aikenh.cn/hugotest/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Hyper-Resolution</h1><div class=post-meta><span title='2020-03-06 14:55:02 +0000 UTC'>March 6, 2020</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;210 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;·&nbsp;<a href=/tags/hyperresolution> HyperResolution</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/Hyper_Resolution.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://aikenh.cn/cover/cover5.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e8%b6%85%e5%88%86%e8%be%a8%e7%8e%87%e5%9c%a8%e8%a1%a8%e6%83%85%e8%af%86%e5%88%ab%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8 aria-label=超分辨率在表情识别中的应用>超分辨率在表情识别中的应用</a></li><li><a href=#%e5%9b%be%e5%83%8f%e6%81%a2%e5%a4%8d%e6%8a%80%e6%9c%af%e5%9b%be%e5%83%8f%e5%a2%9e%e5%bc%ba%e6%8a%80%e6%9c%af%e4%ba%ba%e8%84%b8%e5%a2%9e%e5%bc%ba%e6%8a%80%e6%9c%af%e5%9c%a8%e8%a1%a8%e6%83%85%e8%af%86%e5%88%ab%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8 aria-label=图像恢复技术、图像增强技术、人脸增强技术在表情识别中的应用>图像恢复技术、图像增强技术、人脸增强技术在表情识别中的应用</a></li><li><a href=#%e9%92%88%e5%af%b9%e5%85%89%e5%a7%bf%e5%8a%bf%e5%8f%98%e5%8c%96%e5%99%aa%e5%a3%b0%e5%92%8c%e9%81%ae%e6%8c%a1%e7%9a%84%e4%ba%ba%e8%84%b8%e8%af%86%e5%88%aband-%e5%85%b6%e4%bb%96 aria-label="针对光，姿势变化，噪声和遮挡的人脸识别？AND 其他">针对光，姿势变化，噪声和遮挡的人脸识别？AND 其他</a></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>说明：重点针对<strong>超分辨率</strong>技术</p><p>备注：
超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波<br></p><h2 id=超分辨率在表情识别中的应用>超分辨率在表情识别中的应用<a hidden class=anchor aria-hidden=true href=#超分辨率在表情识别中的应用>#</a></h2><pre tabindex=0><code>KEY WORDs ：

1. (&#34;super resolution&#34; OR &#34;image restore&#34;) AND (&#34;facial expression recognition&#34; OR &#34;emotion recognition&#34;)   
2. (&#34;super resolution&#34;) AND  (&#34;expression recognition&#34;)   
</code></pre><ol><li><p><a href=https://arxiv.org/pdf/1709.03126.pdf target=_blank rel=noopener>&lt; Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach ></a></p><blockquote><ul><li>针对于低带宽传输的分辨率不足和比率低的应用场景</li><li>基于facial expression recognition 的 emotion recognition</li><li>在解码器进行视频下采样的时候，<strong>联合SR和识别</strong></li></ul></blockquote></li><li><p><a href=https://www.sciencedirect.com/science/article/abs/pii/S0925231219312974 target=_blank rel=noopener>&lt; Effective image super resolution via hierarchical convolutional neural network ></a></p><blockquote><ul><li>通过层次卷积神经网络(HCNN)来实现有校的SR</li><li>在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能</li></ul></blockquote></li><li><p><a href=https://link.springer.com/chapter/10.1007/978-3-319-56687-0_13 target=_blank rel=noopener>&lt; Spatio-temporal Pain Recognition in CNN-Based Super-Resolved Facial Images ></a></p><blockquote><ul><li>有点擦边吧，就是基于超分辨率算法的多分辨率图像，对面部进行识别从而判断疼痛程度</li><li>也可能妹啥用，你可以考虑一下</li></ul></blockquote></li><li><p><a href=https://www.sciencedirect.com/science/article/abs/pii/S0165168419304232 target=_blank rel=noopener>&lt; Low-resolution facial expression recognition: A filter learning perspective ></a></p><blockquote><ul><li>摘要中没有明确的提到Super-Resolution，</li><li>但是感觉低分辨率这个问题前缀，可能和SR有关系来着</li></ul></blockquote></li><li><p><a href=https://www-nlpir.nist.gov/projects/tvpubs/tv19.papers/pku-icst.pdf target=_blank rel=noopener>&lt; PKU_ICST at TRECVID 2019: Instance Search Task ></a></p><blockquote><ul><li>好像是什么比赛，过程中有一部分是面部表情检测</li><li>在识别之前采取了超分辨率的查询增强</li></ul></blockquote></li><li><p><a href=https://link.springer.com/chapter/10.1007/978-3-030-37734-2_43 target=_blank rel=noopener>&lt; Facial Expression Restoration Based on Improved Graph Convolutional Networks ></a></p><blockquote><ul><li>针对分辨率低和部分遮挡的面部表情识别</li><li>GAN IGCN RRMB 修复和超分辨率面部表情</li></ul></blockquote></li></ol><h2 id=图像恢复技术图像增强技术人脸增强技术在表情识别中的应用>图像恢复技术、图像增强技术、人脸增强技术在表情识别中的应用<a hidden class=anchor aria-hidden=true href=#图像恢复技术图像增强技术人脸增强技术在表情识别中的应用>#</a></h2><pre tabindex=0><code>KEY WORDs：

1. (&#34;super resolution&#34; OR &#34;image restore&#34;) AND (&#34;facial expression recognition&#34; OR &#34;emotion recognition&#34;)  
2. (&#34;image restore&#34;)  AND  (&#34;expression recognition&#34;)  ——NONE
3. (&#34;Image enhancement&#34;) AND (&#34;facial expression recognition&#34;)
4. (&#34;face enhancement&#34;) AND (&#34;facial expression recognition&#34;)
5. (&#34;Image restoration&#34;) AND (&#34;facial expression recognition&#34;)
</code></pre><ol><li><a href=https://www.sciencedirect.com/science/article/abs/pii/S1350449519306620 target=_blank rel=noopener>&lt; Efficient facial expression recognition via convolution neural network and infrared imaging technology ></a><blockquote><ul><li>离散小波变换正则化和快速盲恢复模型来重建红外光谱。。。。来帮助面部表情识别</li></ul></blockquote></li></ol><h2 id=针对光姿势变化噪声和遮挡的人脸识别and-其他>针对光，姿势变化，噪声和遮挡的人脸识别？AND 其他<a hidden class=anchor aria-hidden=true href=#针对光姿势变化噪声和遮挡的人脸识别and-其他>#</a></h2><ol><li><p><a href=https://link.springer.com/article/10.1007/s10586-017-0935-z target=_blank rel=noopener>&lt; Facial appearance and texture feature-based robust facial expression recognition framework for sentiment knowledge discovery ></a></p><blockquote><ul><li>没有提到超分辨率或是图像重建</li><li>但是有提到标题那几个，结合局部和全局特征&mldr;</li></ul></blockquote></li><li><p><a href=https://link.springer.com/chapter/10.1007/978-3-030-30642-7_24 target=_blank rel=noopener>&lt; Improving Facial Emotion Recognition Systems with Crucial Feature Extractors ></a></p><blockquote><ul><li>是对表情识别的增强但是好像不是图像增强&mldr;..</li><li>基于特征提取的增强把</li></ul></blockquote></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://aikenh.cn/hugotest/tags/survey/>Survey</a></li><li><a href=https://aikenh.cn/hugotest/tags/hyperresolution/>HyperResolution</a></li></ul><nav class=paginav><a class=prev href=https://aikenh.cn/hugotest/posts/markdown/><span class=title>« Prev</span><br><span>Markdown Handbook</span>
</a><a class=next href=https://aikenh.cn/hugotest/posts/imagecaptionrequirement/><span class=title>Next »</span><br><span>Image Caption Dataset</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://aikenh.cn/hugotest/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>