<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>YOLOv4 阅读笔记 | aiken's blog</title>
<meta name=keywords content="CV,Object Detection"><meta name=description content="@AikenHong 20200726
基于YOLO v4 掌握一些CV方面训练的Trick，同时针对Typora的使用进行一个熟悉掌握。GITHUB CODE

一些相关的参考资料
⚡️https://zhuanlan.zhihu.com/p/150127712
⚡ 机器之心YOLOv4

⚡️https://www.zhihu.com/question/390191723/answer/1177584901
本文中一些其他的收获
•  其他可替代的Object Detection的SOTA算法有哪些
•  BoS，BoF方法
•  简直是一个Tricks的综述
Abstract
本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些通用的Trick的组合尝试，包括
•  加权残差连接（WRC）
•  Cross-Stage-Partial-connection，CSP
•  Cross mini-Batch Normalization，CmBN

•  自对抗训练（Self-adversarial-training，SAT）
•  Mish 激活（Mish-activation）
•  Mosaic 数据增强
•  DropBlock 正则化
•  CIoU 损失
基于该文章我们可以了解一下这些方法的主要思路和后续的应用价值。YOLOv4 更快，更准确，只需要比较小的计算需求即可


  
    
  




"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/cv-yolov4/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/cv-yolov4/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/cv-yolov4/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="YOLOv4 阅读笔记"><meta property="og:description" content="@AikenHong 20200726
基于YOLO v4 掌握一些CV方面训练的Trick，同时针对Typora的使用进行一个熟悉掌握。GITHUB CODE 一些相关的参考资料
⚡️https://zhuanlan.zhihu.com/p/150127712
⚡ 机器之心YOLOv4 ⚡️https://www.zhihu.com/question/390191723/answer/1177584901
本文中一些其他的收获
• 其他可替代的Object Detection的SOTA算法有哪些
• BoS，BoF方法
• 简直是一个Tricks的综述
Abstract 本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些通用的Trick的组合尝试，包括
• 加权残差连接（WRC）
• Cross-Stage-Partial-connection，CSP
• Cross mini-Batch Normalization，CmBN
• 自对抗训练（Self-adversarial-training，SAT）
• Mish 激活（Mish-activation）
• Mosaic 数据增强
• DropBlock 正则化
• CIoU 损失
基于该文章我们可以了解一下这些方法的主要思路和后续的应用价值。YOLOv4 更快，更准确，只需要比较小的计算需求即可"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-07-26T13:16:40+00:00"><meta property="article:modified_time" content="2020-07-26T13:16:40+00:00"><meta property="article:tag" content="CV"><meta property="article:tag" content="Object Detection"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover6.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover6.jpeg"><meta name=twitter:title content="YOLOv4 阅读笔记"><meta name=twitter:description content="@AikenHong 20200726
基于YOLO v4 掌握一些CV方面训练的Trick，同时针对Typora的使用进行一个熟悉掌握。GITHUB CODE

一些相关的参考资料
⚡️https://zhuanlan.zhihu.com/p/150127712
⚡ 机器之心YOLOv4

⚡️https://www.zhihu.com/question/390191723/answer/1177584901
本文中一些其他的收获
•  其他可替代的Object Detection的SOTA算法有哪些
•  BoS，BoF方法
•  简直是一个Tricks的综述
Abstract
本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些通用的Trick的组合尝试，包括
•  加权残差连接（WRC）
•  Cross-Stage-Partial-connection，CSP
•  Cross mini-Batch Normalization，CmBN

•  自对抗训练（Self-adversarial-training，SAT）
•  Mish 激活（Mish-activation）
•  Mosaic 数据增强
•  DropBlock 正则化
•  CIoU 损失
基于该文章我们可以了解一下这些方法的主要思路和后续的应用价值。YOLOv4 更快，更准确，只需要比较小的计算需求即可


  
    
  




"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"YOLOv4 阅读笔记","item":"https://hugotest-phi.vercel.app/posts/cv-yolov4/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"YOLOv4 阅读笔记","name":"YOLOv4 阅读笔记","description":"@AikenHong 20200726\n基于YOLO v4 掌握一些CV方面训练的Trick，同时针对Typora的使用进行一个熟悉掌握。GITHUB CODE 一些相关的参考资料\n⚡️https://zhuanlan.zhihu.com/p/150127712\n⚡ 机器之心YOLOv4 ⚡️https://www.zhihu.com/question/390191723/answer/1177584901\n本文中一些其他的收获\n• 其他可替代的Object Detection的SOTA算法有哪些\n• BoS，BoF方法\n• 简直是一个Tricks的综述\nAbstract 本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些通用的Trick的组合尝试，包括\n• 加权残差连接（WRC）\n• Cross-Stage-Partial-connection，CSP\n• Cross mini-Batch Normalization，CmBN\n• 自对抗训练（Self-adversarial-training，SAT）\n• Mish 激活（Mish-activation）\n• Mosaic 数据增强\n• DropBlock 正则化\n• CIoU 损失\n基于该文章我们可以了解一下这些方法的主要思路和后续的应用价值。YOLOv4 更快，更准确，只需要比较小的计算需求即可\n","keywords":["CV","Object Detection"],"articleBody":"@AikenHong 20200726\n基于YOLO v4 掌握一些CV方面训练的Trick，同时针对Typora的使用进行一个熟悉掌握。GITHUB CODE 一些相关的参考资料\n⚡️https://zhuanlan.zhihu.com/p/150127712\n⚡ 机器之心YOLOv4 ⚡️https://www.zhihu.com/question/390191723/answer/1177584901\n本文中一些其他的收获\n• 其他可替代的Object Detection的SOTA算法有哪些\n• BoS，BoF方法\n• 简直是一个Tricks的综述\nAbstract 本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些通用的Trick的组合尝试，包括\n• 加权残差连接（WRC）\n• Cross-Stage-Partial-connection，CSP\n• Cross mini-Batch Normalization，CmBN\n• 自对抗训练（Self-adversarial-training，SAT）\n• Mish 激活（Mish-activation）\n• Mosaic 数据增强\n• DropBlock 正则化\n• CIoU 损失\n基于该文章我们可以了解一下这些方法的主要思路和后续的应用价值。YOLOv4 更快，更准确，只需要比较小的计算需求即可\nINTRODUCTION • 更快更强，从速度和准确率，以及训练需求上提升实际运用价值\n​\t这里有一些其他的SOTA可以列一下：EfficientDet、ATSS，ASFT，CenterMask\n• AP：平均准确率 FPS：每秒传输帧率嘛？\n主要贡献可总结如下\n建立了一个高效强大的目标检测模型。它使得每个人都可以使用 1080Ti 或 2080Ti 的 GPU 来训练一个快速准确的目标检测器。\n验证了当前最优 Bag-of-Freebies 和 Bag-of-Specials 目标检测方法在检测器训练过程中的影响。\nBag-of-freebies: 仅仅只增加training cost或者只改变training strategy的方法。典型例子：数据增强 bag-of-specials: 增加少量推理成本，但能提高准确率的**插件模块（****plugin modules）和后处理方法（post-processing method）**被称为BoS。\n修改了 SOTA 方法，使之更加高效，更适合单 GPU 训练。这些方法包括 CBN、PAN、SAM 等。\nPAN: Path aggregation network for instance segmentation\nSAM: CBAM: Convolutional block attention module\nRELATED WORK 基本架构\nobject detector 通常由backbone和head两部分构成，其中backbone是再imagenet上预训练的骨架\nGPU: VGG [68], ResNet [26], ResNeXt [86],or DenseNet [30] CPU: SqueezeNet [31], MobileNet[28, 66, 27, 74], or ShuffleNet [97, 53] head则是用来预测物体类别和边界框的网络架构\nOne-Stage: YOLO [61, 62, 63], SSD [50],and RetinaNet [45] Anchor-free：CenterNet [13], CornerNet [37, 38], FCOS [78], etc. Two-Stage: R-CNN [19] series: fast R-CNN [18], faster R-CNN [64], R-FCN [9],and Libra R-CNN [58] anchor-free: Rep-Points[87] 近年来在backbone和head之间插入neck用以收集不同stage的feature-maps FPN、PAN、BiFPN、NAS-FPN、etc.\nTo sum up, an ordinary object detector is composed of several parts:\nBag-of-freebies:\n仅仅只增加training cost或者只改变training strategy的方法。典型例子：数据增强\n目标检测中的多种数据增强：包括对图像遮挡的处理，随机擦除和基本的数据增强，也有feature map中类似的操作 解决数据存在偏差的问题：例如数据不平衡 BoundingBox回归方法：MSE-》IoU，也就是一些边界回归上的损失函数，CIoU、GIoU、DIoU、MSE等 Bag of specials\n增加少量推理成本，但能提高准确率的**插件模块（plugin modules）和后处理方法（post-processing method）**被称为BoS。\nPlugin modules：例如扩大接受域，引入注意力机制，增强特征集成能力等等，\npost-processing method：筛选预测结果的方法\n扩大接受域：SPP（将SPM集成到CNN中）、ASPP、RFB。\nAttention module：\nChannel-Wise：SE\nPoint-Wise：SAM\nfeature integration：\n将低层的物理特征集成到高层语义特征\nskip connection、hyper-column FPN出现后：SFAM、ASFF、BiFPN activation function： 解决softmax和sigmoid中出现的梯度消失问题：ReLU、LReLU、PReLU、ReLU6、SELU、Swish、hard-Swish、Mish post-process：\n– NMS用于处理预测同一对象的一些BBox，并保留响应速度更快的BBox\n– 还有一些相关变体\n– anchor-free的方法不需要这部分\nArchitecture 找到最优的input network resolution，conv layer number， the parameter number(filter size2 * filters * channel / groups) 以及 **the number of layer outputs(filters)**之间的最有平衡\n挑选能够增加感受域的额外单元（additional block），以及最佳参数聚合方法\nYoloV4 的基本目标是提高生产系统中神经网络的运行速度，同时为并行计算做出优化，而不是针对低计算量理论指标（BFLOP）进行优化。YoloV4 的作者提出了两种实时神经网络：\n（Backbone）\n• 对于 GPU，研究者在卷积层中使用少量组（1-8 组）：CSPResNeXt50 / CSPDarknet53；\n• 对于 VPU，研究者使用了分组卷积（grouped-convolution），但避免使用 Squeeze-and-excitement（SE）块。具体而言，它包括以下模型：EfficientNet-lite / MixNet / GhostNet / MobileNetV3。\n分类器和检测器需求上的区别：\n架构选择part1\nCSPDarknet53\u003c-最终选择的一个较好的模型（backbone）\n在cspdarknet52上添加了spp block，用PANet取代v3中的FPN，yolov3作为head\n架构选择part2：selection of BoF or BoS\nCNN的优化通常有这几个方面：\nActivations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, or Mish Bounding box regression loss: MSE, IoU, GIoU,CIoU, DIoU Data augmentation: CutOut, MixUp, CutMix Regularization method: DropOut, DropPath [36], Spatial DropOut [79], or DropBlock Normalization of the network activations by their mean and variance: Batch Normalization (BN) [32], Cross-GPU Batch Normalization (CGBN or SyncBN) [93], Filter Response Normalization (FRN) [70], or Cross-Iteration Batch Normalization (CBN) [89]\nSkip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, or Cross stage partial connections (CSP) 架构选择Part3 ：额外的改进\n使得架构能够更适合在单个GPU上进行运算，设计了一些改进\n• 新的数据增强方法：mosaic \u0026SAT（self-Adversarial Training）\n• 在遗传算法中使用了最佳的超参数\n• 修改SAM，PAN和CmBN使得设计适合更有效的训练和检测\nMosaic（马赛克）数据增强，把四张图拼成一张图来训练，变相的等价于增大了mini-batch。这是从CutMix混合两张图的基础上改进；\nMosaic数据增强\nSelf-Adversarial Training(自对抗训练)，这是在一张图上，让神经网络反向更新图像，对图像做改变扰动，然后在这个图像上训练。这个方法，是图像风格化的主要方法，让网络反向更新图像来风格化图像（对风格化感兴趣，可以看看我写的一篇介绍谷歌的一个实时任意风格化的文章 ）；对自身实行对抗攻击\n跨最小批的归一化（Cross mini-batch Normal），在CBN的基础上改进；\nBN, CBN，CmBN的对比\n修改的SAM，从SAM的逐空间的attention，到逐点的attention； [image: https://pic4.zhimg.com/50/v2-440bfacec2a426272ef06e94a16837bb_hd.jpg?source=1940ef5c]\nSAM和修改的SAM对比图\n修改的PAN，把通道从相加（add）改变为concat，改变很小； [image: https://pic4.zhimg.com/50/v2-a1f0ccf10cea594c1aebcc98111c6dd5_hd.jpg?source=1940ef5c][image: https://pic4.zhimg.com/80/v2-a1f0ccf10cea594c1aebcc98111c6dd5_720w.jpg?source=1940ef5c]\nPAN和修改的PAN\n最终整体架构表示：\nExperiments 实验中的一些参数设置和具体的表达就从文章中看吧，还有各种trick的表达效果,其实很重要，可以省下很多的研究时间。\n• Influence of different features on Classifier training\n• Influence of different features on Detector training\n• Influence of different backbones and pretrained weightings on Detector training\n• Influence of different minibatch size on Detector training\nFAQ\n• reception field 的理解，以及作用\n","wordCount":"417","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover6.jpeg","datePublished":"2020-07-26T13:16:40Z","dateModified":"2020-07-26T13:16:40Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/cv-yolov4/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">YOLOv4 阅读笔记</h1><div class=post-meta><span title='2020-07-26 13:16:40 +0000 UTC'>July 26, 2020</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;417 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/cv> CV</a>&nbsp;·&nbsp;<a href=/tags/object-detection> Object Detection</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/CV-YOLOv4.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover6.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#abstract aria-label=Abstract>Abstract</a></li><li><a href=#introduction aria-label=INTRODUCTION>INTRODUCTION</a></li><li><a href=#related-work aria-label="RELATED WORK">RELATED WORK</a></li><li><a href=#architecture aria-label=Architecture>Architecture</a></li><li><a href=#experiments aria-label=Experiments>Experiments</a></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>@AikenHong 20200726</p><p>基于YOLO v4 掌握一些CV方面训练的<strong>Trick</strong>，同时针对Typora的使用进行一个熟悉掌握。<a href=https://github.com/AlexeyAB/darknet target=_blank rel=noopener>GITHUB CODE</a></p><p>一些相关的参考资料</p><p>⚡️https://zhuanlan.zhihu.com/p/150127712</p><p>⚡ <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650785604&amp;idx=1&amp;sn=46bd186e5291deded9f6ec1ae6a22649&amp;chksm=871a033ab06d8a2cff370a06e9e88f578a6c16a70231778ae2f997a8b30e347c6e746db10759&amp;mpshare=1&amp;scene=1&amp;srcid=0429kHitmMCPeF2JGN1XCzik&amp;sharer_sharetime=1588144165276&amp;sharer_shareid=484a4a951d2ad320314b6b56ee9a0ba8&amp;key=c53866ae67b2b8c4b46c89671357025dcdb6b895d1ebde603135230e484682a3552d924bf6126ecf72cb98361e1171f0f0381bee5bd456520dd201034c33ec48272d62ae73345cc914c2db9c6e943a10&amp;ascene=1&amp;uin=NTkyNDg4NjQw&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=ASfZUAGjes1A%2BJpXS1yNmT0%3D&amp;pass_ticket=GB56ClnZIrs5ENfLSAh4yF9tj54n041FM39bTg38LQuW%2FKDyBPyfqKLD8SDIZgE%2F" target=_blank rel=noopener>机器之心YOLOv4</a></p><p>⚡️https://www.zhihu.com/question/390191723/answer/1177584901</p><p><strong>本文中一些其他的收获</strong></p><p>• 其他可替代的Object Detection的SOTA算法有哪些</p><p>• BoS，BoF方法</p><p>• 简直是一个Tricks的综述</p><h2 id=abstract>Abstract<a hidden class=anchor aria-hidden=true href=#abstract>#</a></h2><p>本文对近期再CNN上的一些Feature方法进行了尝试组合，并实现了新的SOTA，其实就是一些<strong>通用的<strong><strong>Trick</strong></strong>的组合</strong>尝试，包括</p><p>• 加权残差连接（WRC）</p><p>• Cross-Stage-Partial-connection，CSP</p><p>• Cross mini-Batch Normalization，CmBN</p><p>• 自对抗训练（Self-adversarial-training，SAT）</p><p>• Mish 激活（Mish-activation）</p><p>• Mosaic 数据增强</p><p>• DropBlock 正则化</p><p>• CIoU 损失</p><p>基于该文章我们可以了解一下这些方法的主要思路和后续的应用价值。YOLOv4 更快，更准确，只需要比较小的计算需求即可</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165042.png><img alt=image-20210930165040810 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165042.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165042.png style="display:block;margin:0 auto" alt=image-20210930165040810></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h2 id=introduction>INTRODUCTION<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>• 更快更强，从速度和准确率，以及训练需求上提升实际运用价值</p><p>​ 这里有一些其他的SOTA可以列一下：EfficientDet、ATSS，ASFT，CenterMask</p><p>• AP：平均准确率 FPS：每秒传输帧率嘛？</p><p>主要贡献可总结如下</p><ol><li><p>建立了一个高效强大的目标检测模型。它使得每个人都可以使用 1080Ti 或 2080Ti 的 GPU 来训练一个快速准确的目标检测器。</p></li><li><p>验证了当前最优 Bag-of-Freebies 和 Bag-of-Specials 目标检测方法在检测器训练过程中的影响。</p><p>Bag-of-freebies: 仅仅只增加training cost或者只改变training strategy的方法。典型例子：数据增强
bag-of-specials: 增加少量推理成本，但能提高准确率的**插件模块（****plugin modules）和后处理方法（post-processing method）**被称为BoS。</p></li><li><p>修改了 SOTA 方法，使之更加高效，更适合单 GPU 训练。这些方法包括 CBN、PAN、SAM 等。</p><p>PAN: Path aggregation network for instance segmentation</p><p>SAM: CBAM: Convolutional block attention module</p></li></ol><h2 id=related-work>RELATED WORK<a hidden class=anchor aria-hidden=true href=#related-work>#</a></h2><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165008.png><img alt=image-20210930165005309 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165008.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165008.png style="display:block;margin:0 auto" alt=image-20210930165005309></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p><strong>基本架构</strong></p><ul><li><p>object detector 通常由backbone和head两部分构成，其中backbone是再imagenet上预训练的骨架</p><ul><li>GPU: VGG [68], ResNet [26], ResNeXt [86],or DenseNet [30]</li><li>CPU: SqueezeNet [31], MobileNet[28, 66, 27, 74], or ShuffleNet [97, 53]</li></ul></li><li><p>head则是用来预测物体类别和边界框的网络架构</p><ul><li>One-Stage: YOLO [61, 62, 63], SSD [50],and RetinaNet [45]</li><li>Anchor-free：CenterNet [13], CornerNet [37, 38], FCOS [78], etc.</li><li>Two-Stage: R-CNN [19] series: fast R-CNN [18], faster R-CNN [64], R-FCN [9],and Libra R-CNN [58] anchor-free: Rep-Points[87]</li></ul></li><li><p>近年来在backbone和head之间插入neck用以收集不同stage的feature-maps FPN、PAN、BiFPN、NAS-FPN、etc.</p></li></ul><p>To sum up, an ordinary object detector is composed of several parts:</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165142.png><img alt=image-20210930165140911 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165142.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165142.png style="display:block;margin:0 auto" alt=image-20210930165140911></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p><strong>Bag-of-freebies:</strong></p><p>仅仅只增加training cost或者只改变training strategy的方法。典型例子：数据增强</p><ul><li>目标检测中的多种数据增强：包括对图像遮挡的处理，随机擦除和基本的数据增强，也有feature map中类似的操作</li><li>解决数据存在偏差的问题：例如数据不平衡</li><li>BoundingBox回归方法：MSE-》IoU，也就是一些边界回归上的损失函数，CIoU、GIoU、DIoU、MSE等</li></ul><p><strong>Bag of specials</strong></p><p>增加少量推理成本，但能提高准确率的**插件模块（plugin modules）和后处理方法（post-processing method）**被称为BoS。</p><p><strong>Plugin modules</strong>：例如扩大接受域，引入注意力机制，增强特征集成能力等等，</p><p><strong>post-processing method</strong>：筛选预测结果的方法</p><ul><li><p>扩大接受域：SPP（将SPM集成到CNN中）、ASPP、RFB。</p></li><li><p>Attention module：</p></li><li><p>Channel-Wise：SE</p></li><li><p>Point-Wise：SAM</p></li><li><p>feature integration：</p></li></ul><p><strong>将低层的物理特征集成到高层语义特征</strong></p><ul><li>skip connection、hyper-column</li><li>FPN出现后：SFAM、ASFF、BiFPN</li><li>activation function：</li><li>解决softmax和sigmoid中出现的梯度消失问题：ReLU、LReLU、PReLU、ReLU6、SELU、Swish、hard-Swish、Mish</li></ul><p><strong>post-process：</strong></p><p>– NMS用于处理预测同一对象的一些BBox，并保留响应速度更快的BBox</p><p>– 还有一些相关变体</p><p>– anchor-free的方法不需要这部分</p><h2 id=architecture>Architecture<a hidden class=anchor aria-hidden=true href=#architecture>#</a></h2><ol><li><p>找到最优的<strong>input network resolution</strong>，<strong>conv layer number</strong>， <strong>the parameter number(filter size2 * filters * channel / groups)</strong> <strong>以及</strong> **the number of layer outputs(filters)**之间的最有平衡</p></li><li><p>挑选能够增加感受域的额外单元（additional block），以及最佳参数聚合方法</p><p>YoloV4 的基本目标是提高生产系统中神经网络的运行速度，同时为并行计算做出优化，而不是针对低计算量理论指标（BFLOP）进行优化。YoloV4 的作者提出了两种实时神经网络：</p></li></ol><p>（Backbone）</p><p>• 对于 GPU，研究者在卷积层中使用少量组（1-8 组）：CSPResNeXt50 / CSPDarknet53；</p><p>• 对于 VPU，研究者使用了分组卷积（grouped-convolution），但避免使用 Squeeze-and-excitement（SE）块。具体而言，它包括以下模型：EfficientNet-lite / MixNet / GhostNet / MobileNetV3。</p><p>分类器和检测器需求上的区别：</p><p><strong>架构选择part1</strong></p><ol><li><p>CSPDarknet53&lt;-最终选择的一个较好的模型（backbone）</p></li><li><p>在cspdarknet52上添加了spp block，用PANet取代v3中的FPN，yolov3作为head</p></li></ol><p><strong>架构选择part2：selection of BoF or BoS</strong></p><p>CNN的优化通常有这几个方面：</p><ul><li>Activations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, or Mish</li><li>Bounding box regression loss: MSE, IoU, GIoU,CIoU, DIoU</li><li>Data augmentation: CutOut, MixUp, CutMix</li><li>Regularization method: DropOut, DropPath [36], Spatial DropOut [79], or <strong>DropBlock</strong></li><li>Normalization of the network activations by their mean and variance:</li></ul><p>Batch Normalization (BN) [32], Cross-GPU Batch Normalization (CGBN or SyncBN) [93], Filter Response Normalization (FRN) [70], or Cross-Iteration Batch Normalization (CBN) [89]</p><ul><li>Skip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, or Cross stage partial connections (CSP)</li></ul><p><strong>架构选择Part3</strong> ：额外的改进</p><p>使得架构能够更适合在单个GPU上进行运算，设计了一些改进</p><p>• 新的数据增强方法：mosaic &amp;SAT（self-Adversarial Training）</p><p>• 在遗传算法中使用了最佳的超参数</p><p>• 修改SAM，PAN和CmBN使得设计适合更有效的训练和检测</p><p>Mosaic（马赛克）数据增强，把四张图拼成一张图来训练，变相的等价于增大了mini-batch。这是从CutMix混合两张图的基础上改进；</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165156.png><img alt=image-20210930165154939 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165156.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210930165156.png style="display:block;margin:0 auto" alt=image-20210930165154939></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><hr><p><strong>Mosaic数据增强</strong></p><ol><li><p>Self-Adversarial Training(自对抗训练)，这是在一张图上，让神经网络反向更新图像，对图像做改变扰动，然后在这个图像上训练。这个方法，是图像风格化的主要方法，让网络反向更新图像来风格化图像（对风格化感兴趣，可以看看我写的一篇介绍<a href=https://zhuanlan.zhihu.com/p/105550915 target=_blank rel=noopener>谷歌的一个实时任意风格化的文章</a>
）；对自身实行对抗攻击</p></li><li><p>跨最小批的归一化（Cross mini-batch Normal），在CBN的基础上改进；</p></li></ol><p><strong>BN, CBN，CmBN的对比</strong></p><ol><li>修改的SAM，从SAM的逐空间的attention，到逐点的attention；</li></ol><p>[image: https://pic4.zhimg.com/50/v2-440bfacec2a426272ef06e94a16837bb_hd.jpg?source=1940ef5c]</p><p><strong>SAM和修改的SAM对比图</strong></p><ol><li>修改的PAN，把通道从相加（add）改变为concat，改变很小；</li></ol><p>[image: https://pic4.zhimg.com/50/v2-a1f0ccf10cea594c1aebcc98111c6dd5_hd.jpg?source=1940ef5c][image: https://pic4.zhimg.com/80/v2-a1f0ccf10cea594c1aebcc98111c6dd5_720w.jpg?source=1940ef5c]</p><p>PAN和修改的PAN</p><p>最终整体架构表示：</p><h2 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h2><p>实验中的一些参数设置和具体的表达就从文章中看吧，还有各种trick的表达效果,其实很重要，可以省下很多的研究时间。</p><p>• Influence of different features on Classifier training</p><p>• Influence of different features on Detector training</p><p>• Influence of different backbones and pretrained weightings on Detector training</p><p>• Influence of different minibatch size on Detector training</p><p><strong>FAQ</strong></p><p>• reception field 的理解，以及作用</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/cv/>CV</a></li><li><a href=https://hugotest-phi.vercel.app/tags/object-detection/>Object Detection</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/gans/><span class=title>« Prev</span><br><span>GANs 01</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/markdown/><span class=title>Next »</span><br><span>Markdown Handbook</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>