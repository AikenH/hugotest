<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LT Collection | aiken's blog</title>
<meta name=keywords content="Machine Learning,Survey,Long-Tailed Learning"><meta name=description content="LT-Collections
@AikenHong 2021
Code of must of those methods

We will analysis those tricks on LT situation, and Analysis why it works.
在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。
其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps
Introduction


  
    
  





通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合
首先介绍 bag of tricks
 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick
经过该文实验总结，Trick组合应该是[1]`：

在前几个epoch应用input mixup数据增强，然后后面fine-tuning;
(基于CAM的)重采样来重新训练分类器;

实际上就是MixUp + Two-Stage的策略，后续对Mix-up这个策略带来的作用要进行补充了解一下
Rebalance

对于ReBalance的方法，实际上就是从 data和 update两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/lt-collection/><link crossorigin=anonymous href=/assets/css/stylesheet.2f85ca17c12c62fa86b1e474b8a51aca4856f0d645debfe4922a4d5ddc6aa978.css integrity="sha256-L4XKF8EsYvqGseR0uKUaykhW8NZF3r/kkipNXdxqqXg=" rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/lt-collection/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/lt-collection/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="LT Collection"><meta property="og:description" content="LT-Collections @AikenHong 2021
Code of must of those methods We will analysis those tricks on LT situation, and Analysis why it works. 在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。
其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps
Introduction 通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合
首先介绍 bag of tricks 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick
经过该文实验总结，Trick组合应该是[1]`：
在前几个epoch应用input mixup数据增强，然后后面fine-tuning; (基于CAM的)重采样来重新训练分类器; 实际上就是MixUp + Two-Stage的策略，后续对Mix-up这个策略带来的作用要进行补充了解一下
Rebalance 对于ReBalance的方法，实际上就是从 data和 update两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-22T14:36:16+00:00"><meta property="article:modified_time" content="2021-12-22T14:36:16+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Survey"><meta property="article:tag" content="Long-Tailed Learning"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover0.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover0.jpeg"><meta name=twitter:title content="LT Collection"><meta name=twitter:description content="LT-Collections
@AikenHong 2021
Code of must of those methods

We will analysis those tricks on LT situation, and Analysis why it works.
在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。
其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps
Introduction


  
    
  





通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合
首先介绍 bag of tricks
 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick
经过该文实验总结，Trick组合应该是[1]`：

在前几个epoch应用input mixup数据增强，然后后面fine-tuning;
(基于CAM的)重采样来重新训练分类器;

实际上就是MixUp + Two-Stage的策略，后续对Mix-up这个策略带来的作用要进行补充了解一下
Rebalance

对于ReBalance的方法，实际上就是从 data和 update两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"LT Collection","item":"https://hugotest-phi.vercel.app/posts/lt-collection/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LT Collection","name":"LT Collection","description":"LT-Collections @AikenHong 2021\nCode of must of those methods We will analysis those tricks on LT situation, and Analysis why it works. 在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。\n其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps\nIntroduction 通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合\n首先介绍 bag of tricks 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick\n经过该文实验总结，Trick组合应该是[1]`：\n在前几个epoch应用input mixup数据增强，然后后面fine-tuning; (基于CAM的)重采样来重新训练分类器; 实际上就是MixUp + Two-Stage的策略，后续对Mix-up这个策略带来的作用要进行补充了解一下\nRebalance 对于ReBalance的方法，实际上就是从 data和 update两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。\n","keywords":["Machine Learning","Survey","Long-Tailed Learning"],"articleBody":"LT-Collections @AikenHong 2021\nCode of must of those methods We will analysis those tricks on LT situation, and Analysis why it works. 在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。\n其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps\nIntroduction 通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合\n首先介绍 bag of tricks 这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick\n经过该文实验总结，Trick组合应该是[1]`：\n在前几个epoch应用input mixup数据增强，然后后面fine-tuning; (基于CAM的)重采样来重新训练分类器; 实际上就是MixUp + Two-Stage的策略，后续对Mix-up这个策略带来的作用要进行补充了解一下\nRebalance 对于ReBalance的方法，实际上就是从 data和 update两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。\n前者称为rebalance，后者则为reweight.\nreweighting 这一部分在实际设计上的体现主要是通过对Loss的重新构造而成，通过对Loss的构造来实现区分的BP权重.\n代价敏感softmax交叉熵损失CS_CE: 在ce前乘最小训练图像数目与每个类别图像数目的比值，相当于更注重少类样本 $$ \\mathcal{L}_{CS\\_CE}(\\mathbf{z}, c)=-\\frac{n_{\\min }}{n_{c}} \\log \\left(\\frac{\\exp \\left(z_{c}\\right)}{\\sum_{i=1}^{C} \\exp \\left(z_{i}\\right)}\\right)\r$$\rFocal Loss：设置 $\\alpha$ 和 $\\beta$ 来控制少数类和难分类别对损失的贡献： $$ \\mathcal{L}_{\\text {Focal }}(\\mathbf{z}, c)=-\\sum_{i=1}^{C}\\left(1-p_{i}^{t}\\right)^{\\gamma} \\log \\left(p_{i}^{t}\\right) $$\r类别平衡损失：就是在基本的损失（CE，FOCAL）前加入一个衡量权重，其中 $\\beta$ 是一个超参数，来衡量有效的信息 $$ \\mathcal{L}_{CB\\_Focal}(\\mathbf{z}, c)=-\\frac{1-\\beta}{1-\\beta^{n_{c}}} \\sum_{i=1}^{C}\\left(1-p_{i}^{t}\\right)^{\\gamma} \\log \\left(p_{i}^{t}\\right) $$\rLogit Abjustment[3]: $$ \\ell(y, f(x))=\\alpha_{y} \\cdot \\log \\left[1+\\sum_{y^{\\prime} \\neq y} e^{\\Delta_{y y^{\\prime}}} \\cdot e^{\\left(f_{y^{\\prime}}(x)-f_{y}(x)\\right)}\\right] $$\rrebalance 实际上就是对少类或者多类的数据重新做均衡，方法的本质差别一般都不是特别大\n随机过采样：随即重复少数类别的样本来使得样本均衡 随机降采样：随机删除多数类别的样本使得样本均衡 样本平衡采样：应该值得就是1-2 IB-Sampling 类别平均采样: 对类别进行统一采样，每个类别被采样的概率都一样(Q=0)，然后从每个类别中有放回的随机采样实例，从而构建平衡的数据集 $$ p_j = \\frac{n_j^q}{\\sum_{i=1}^C n_i^q} $$\r平方根采样(Q=0.5) 逐步平衡采样：先对多个epoch进行实例平衡采样（上式q=1，也就是没有任何平衡操作的采样），然后再剩下的epoches中进行类别平衡采样。这种采样方式需要设置一个超参数来调整从哪一个epoch开始变换采样方式。也可以使用更软的阈值，即随着epoch的增加来逐渐调整实例平衡采样（IB）和类别平衡采样所占的比例，如下面公式所示。 $$ P_j^{PB} (t) = (1-\\frac{t}{T})P_j^{IB} + \\frac{t}{T}P_j^{CB}\r$$\rtwo-stage 在Unbalanced的Data上Pretrain一个特征提取器，然后再rebalance（IB，CB）的数据集上对Classifier进行重新训练（调整），（and | or）对齐，校准（disalign，causal）来提升LT的性能的方法\nmotivation 但是这些rebalance的方法通常会带来以下两个问题[2]：\nrebalance之后分类器会倾向于分类正确的尾部样本，导致对于头部有一定的bad influence（欠拟合），对尾部过拟合 rebalance方法会显著的促进分类器的学习，但是会损害深度特征的表示能力，如上图所示，分类器学到的分界面更好，但是特征的表示却更加的松散了 我认为rebalance的策略确实会使得Clf学的更好的分界面，减少偏向性，但是不至于在尾部过拟合，这一部分分析最重要的应该是rebalance对于特征空间的Bad Influence，这可能就是Two Stage的来源。\n于是作者为其设计了一些消融实验：CE指的是长尾，RW，RS指的是使用的rebalance的数据。\n可以发现在Backbone上使用Unbalance的数据而在Clf上使用Resampler的数据效果是最好的，这种two-stage的解耦两阶段的训练策略展现了一个有希望的结果。\n这种两阶段的方式，我认为在第二阶段的时候也要对特征进行微调来适应当前的分布，不过很多的方法都是直接只对分类器进行调整，我们可以对两种方式进行测试\n下图显示了fix-two-stage和baseline对比[5] 下图展示了理想的two-stage结果与显示方法之间的距离[5] cls-bound是再fix特征后，用完全均衡的数据集训练分类器得到的结果，由此带入第二张图的绿色的线，可以知道，现有长尾方法的性能瓶颈（未使用two-stage），仍然在特征空间中的有偏差的决策边界。 基于这些分析,我们认为，在得到一个强有力的特征表示后，我们可以将问题归化到分类器上，基于这点假设，我们可以结合我们的自监督模块来对该方法进行归化。\nBBN structure Share Weight of Backbone，Using diff dataset to get diff feature. Then we using $\\alpha$ to Combine the logits and calculate the loss.\n$$ z = \\alpha * W_c^T * f_c + (1-\\alpha) * W_\\gamma^T * f_\\gamma\r$$\r$$ L = \\alpha * l(softmax(z),y_c) + (1-\\alpha) *l(softmax(z),y_\\gamma)\r$$\r在上述的流程图中W代表的是两个不一样的数据优化器，基于这样的设置最终就能区分两部分的优化。\n但是这个方法为我们带来的最大的启发还是在于区分两阶段中学习的重点，backbone需要在一个unblance的条件下学习一个更为通用的表征，而Cls需要矫正偏差。不平衡的情况下可能能学到一个很好的通用表征，这一点就是我们使用自监督的一个重要原因。\nDecoupling ==Train BB and Fixed then Train CLF== 此外坐着发现全连接的weight和norm和对应类别的样本数正相关，所以在第二部最后将分类器改为归一化的分类器，文中的两种设计是：\n$\\overline{W_i}=\\frac{w_i}{\\lVert W_i \\rVert^T}$ $\\overline{W_i}=\\frac{w_i}{f_i}$ 其中2利用fixed第一步分类权重 $w_i$ ,对每个类学习了一个加权参数 $f_i$\nbetter-calibration 但是这种两阶段的方式也不是没有代价的，他会带来比较严重的校准错误(Calibration)，也就是我们预测的概率和实际的相似度之间的一致性。\n（BTW评估校准错误的指标 $ECE=\\sum_{b=1}^B\\frac{|S_b|}{N} |acc(S_b) - conf(S_b)|$ ，将数据分为b组，S_b是落入b区间的样本集合)\n本文主要测试了MixUP在两阶段训练中的作用，以及提出了：\n标签感知平滑损失，实际上就是cb_ce的半泛化形式： $$ \\begin{gathered}\rl(\\boldsymbol{q}, \\boldsymbol{p})=-\\sum_{i=1}^{K} \\boldsymbol{q}_{i} \\log \\boldsymbol{p}_{i} \\\\\r\\boldsymbol{q}_{i}= \\begin{cases}1-\\epsilon_{y}=1-f\\left(N_{y}\\right), \u0026 i=y \\\\\r\\frac{\\epsilon_{y}}{K-1}=\\frac{f\\left(N_{y}\\right)}{K-1}, \u0026 \\text { Otherwise }\\end{cases}\r\\end{gathered} $$\r$\\epsilon_y$ 是y(gt)的一个小平滑因子,数目与类别的样本数有关，并提出了几种函数形式，来优化这个损失 2. BN的移位学习，由于两阶段的数据集不一致，所以normalize的参数是需要学习变化的（均值和方差）\n具体的数学分析和推导，后续根据论文理解了再来补充\nDisAlign 基于上述对于方法的分析，该文章着重于对于分类器进行校准，具体的思路是基于利于平衡预测的类别分布来对分类器的输出进行匹配，矫正；简单的说利用类别先验和输入数据学习类别的决策边界。 具体由两部分构成(重构预测的概率输出，建立理想分布，使用KL散度计算损失)\n自适应配准函数 $$ \\begin{gathered}\rs_{j}=\\alpha_{j} \\cdot z_{j}^{o}+\\beta_{j}, \\quad \\forall j \\in \\mathcal{C} \\\\\r\\hat{z}_{j}=\\sigma(\\mathbf{x}) \\cdot s_{j}+(1-\\sigma(\\mathbf{x})) \\cdot z_{j}^{o} \\\\\r=\\left(1+\\sigma(\\mathbf{x}) \\alpha_{j}\\right) \\cdot z_{j}^{o}+\\sigma(\\mathbf{x}) \\cdot \\beta_{j} \\\\\rp_{m}(y=j \\mid \\mathbf{x})=\\frac{\\exp \\left(\\hat{z}_{j}\\right)}{\\sum_{k=1}^{C} \\exp \\left(\\hat{z}_{k}\\right)}\r\\end{gathered} $$\r广义重加权校准 理想的分布的计算方法如下，定义说的不是很好，最好还是参考一下代码 $$ \\begin{gathered}\rp_{r}\\left(y=c \\mid \\mathbf{x}_{i}\\right)=w_{c} \\cdot \\delta_{c}\\left(y_{i}\\right), \\quad \\forall c \\in \\mathcal{C} \\\\\rw_{c}=\\frac{\\left(1 / r_{c}\\right)^{\\rho}}{\\sum_{k=1}^{K}\\left(1 / r_{k}\\right)^{\\rho}}, \\quad \\forall c \\in \\mathcal{C}\r\\end{gathered} $$\r最终的损失计算方程如下：\n$$ \\begin{aligned}\r\\mathcal{L} \u0026=\\mathbb{E}_{\\mathcal{D}_{t r}}\\left[\\mathcal{K} \\mathcal{L}\\left(p_{r}(y \\mid \\mathbf{x}) \\| p_{m}(y \\mid \\mathbf{x})\\right)\\right] \\\\\r\u0026 \\approx-\\frac{1}{N} \\sum_{i=1}^{N}\\left[\\sum_{y \\in \\mathcal{C}} p_{r}\\left(y \\mid \\mathbf{x}_{i}\\right) \\log \\left(p_{m}\\left(y \\mid \\mathbf{x}_{i}\\right)\\right)\\right]+C\r\\end{aligned}\r$$\r==训练的具体策略== 1）在第一阶段，在不平衡数据集上使用实例平衡 ( instance-balanced ) 采样策略实现特征提取器和原始分类头的联合学习。此时由于不平衡的数据分布，学习到的原始分类头是严重有偏的。\n2）在第二阶段，我们在特征提取器参数固定不变的情况下关注分类头以调整决策边界，引入了自适应配准函数 ( adaptive calibration function ) 和广义重加权 ( generalized re-weight ) 策略来配准各类概率。\nCaucal Analysis 基于two-stage的这种现象，然后分析机器和人学习的区别，认为带来偏差的元凶在于Optim优化算法，为此，该文章构建因果图，从而去除在模型更新过程中由动量带来的偏差效应。\n\"keep good and remove bad momentum\"[7]\r$v_t = \\mu · v_{t-1} + g_t$ , $\\theta = \\theta_{t-1} - lr · v_t$\n要调用这个方法的话，我们就需要\n将训练的CLF修改成Multi-Head并Normlize，参考Decouple. 训练过程中统计移动平局特征 $\\overline{x}$ ，将其单位方向看成头部倾向. 测试的过程中修正logits即可 具体公式参考对应的解析和代码实现;\n和自监督结合的话，只需要在微调的阶段进行统计和修正即可，毕竟是一个一阶段的方式。\nContrastive 这一部分考虑一些和对比学习，或者说自监督学习耦合的方法来进行分析。\n为何将这两者放到同一个章节中？ 因为这两者企图从表征的层面，为LT任务，带来增益，得到一个可分的特征空间基于良好的特征表达，进而解耦的来训练一个更好的CLF。\n如果我们假设我们能得到一个高维线性可分的特征空间，对于长尾的样本带来的训练偏差（决策面偏差）是否可以通过对于特定类别的Margin-Like的Loss设置，达到一个类似Balance的效果，这一点上实际上可能和Align和校正的思想有点相似。但是我们是为了让分类器空间中的分界面在小样本的束缚下变得更加的合理。\n从分界面的角度看LT的情况：（上面是普通CE，下面是Contrastive Learning） 在数据量出现较大的差异的情况下，由于蓝色的数目更多更杂，所以实际上分界面可能会沿着蓝色数据的边界做切分（overfit），在这种Class-Level的过拟合下，就会导致对于少数类别的分类结果很差。\n而下方的对比学习就是一样的解决方案，他试图将同一类的数据聚拢在一起，将不同类的距离尽可能的拉远，这样会使得在空间中的决策面更加的鲁棒也已于区分，虽然可能会一定程度上减少蓝色的表现，但是红色的表现会因此大大的提升。\nhybird contrastive 该文章[9]的基本架构上实际上参考的就是BBN的epoch-params在two-stage中集成 supervised contrasive Loss，具体框架可以看下面这图： 他的设计思想很容易从这张图中领会，损失函数的表达显然如下\n$$ L_{hybird} = \\alpha · L_{SCL}(B_{SC}) + (1-\\alpha) · L_{ce}(B_{CE})\r$$\r在这里要注意SC和自监督中使用的区别在于，自监督学习的过程中没有标签，所以只能将自己作为Positive，而在SC的时候，同类的样本之间应该都作为Positive\n$$ \\mathcal{L}_{S C L}\\left(\\mathbf{z}_{i}\\right)=\\frac{-1}{\\left|\\left\\{\\mathbf{z}_{i}^{+}\\right\\}\\right|} \\sum_{\\mathbf{z}_{j} \\in\\left\\{\\mathbf{z}_{i}^{+}\\right\\}} \\log \\frac{\\exp \\left(\\mathbf{z}_{i} \\cdot \\mathbf{z}_{j} / \\tau\\right)}{\\sum_{\\mathbf{z}_{k}, k \\neq i} \\exp \\left(\\mathbf{z}_{i} \\cdot \\mathbf{z}_{k} / \\tau\\right)}\r$$\r鉴于SC的计算复杂度要和整个Epoch的数据进行对比，需要大量的显存空间，在这方面作者将其改进为PSC，其实也就是将每个class计算一个prototype，然后基于原型去计算这个相似性损失\n$$ \\mathcal{L}_{P S C}\\left(\\mathbf{z}_{i}\\right)=-\\log \\frac{\\exp \\left(\\mathbf{z}_{i} \\cdot \\mathbf{p}_{y_{i}} / \\tau\\right)}{\\sum_{j=1, j \\neq y_{i}}^{C} \\exp \\left(\\mathbf{z}_{i} \\cdot \\mathbf{p}_{j} / \\tau\\right)}\r$$\r在这里这个Prototypical需要正则化到单位元中，这样能快速计算相似性损失，也不会需要大量的现存。\n可以参考的点主要就在于损失的设计和框架上的这种分epoch机制了，但是基于自监督的方式的话，可能不是很用的上这一点，但是我们可以考虑怎么结合这个loss去做对应的分类器。\nThe value of labels 这一篇文章是将自监督学习和半监督学习应用到长尾分布的问题上，文章对应的仓库中可以get预训练模型和很多对应的数据，同时验证了下面两种策略都可以大大提升模型的效果，包括和之前的各种策略进行耦合。\n半监督：利用更多的无标注数据 自监督：不利用任何其他数据，使用长尾分布的数据进行自监督训练 后续的实验过程中我可能也会遵循该设计，或者使用的是全数据的自监督预训练。\n考虑尾部标签本身的意义，想要利用尾部的标签信息，又不受偏差的影响，实际上就是使用自监督进行预训练，然后后面使用各种方法兼容的一个策略。 MixUp in LT 将MixUP应用在LT中，试图\"以使其具有更高的泛化性，以及降低模型本身的置信度\"[4], 经过实验表明，仅在Stage1使用MixUP，在Stage2的第二阶段使用几个epoch的Mixup的效果可能会更好。\n在这里可能也要考虑一下CutMix方法\nConclusion 实验结果汇总 基于BackBone对这些方法的实验结果( $Top1 Acc$ )进行汇总，作为我们后续研究的参照：在进行实验的时候，我们需要首先调整好BenchMark，基于Benchmark做的改进才能和对应的方法进行对比。\n整理原则：\n对应的论文则由该论文本身为主，后续和LT的仓库进行对比分析； 最主要需要对比的应该是ce情况下的指标，这是我们最重要的，当这个指标对齐后，我们就可以和这些方法同台竞技了。 Dataset -\u003e LT-Cifar-100 \u003c- -\u003e LT-CIfar10 \u003c- Backbone Factor(Exp) 100 50 10 100 50 10 ResNet32 RESULT - - - - - - CE 38.32 43.85 55.71 70.36 74.81 86.39 - Focal Loss 38.4 44.3 56.8 70.4 76.7 86.7 - MixUp 39.5 45.0 58.0 73.1 77.8 87.1 - CB Loss 39.6 45.2 58.0 74.6 79.3 87.1 - BAGS-After 47.83 51.69 - 73.59 79.03 - - SSL-Uniform 40.40 45.04 57.07 73.50 78.20 87.72 SSL-Balanced 43.06 47.09 58.06 76.53 80.4 87.72 LDAM 42.0 46.6 58.7 77.0 81.0 88.2 - BBN 42.56 47.07 59.12 79.82 82.18 88.32 - Causal 44.1 50.3 59.6 80.6 83.6 88.5 - Reference 阅读过程中还看到一些什么BAGS，进行数据分组的方法，这个方法肯定不会在我们的框架中使用，但是我们可以分析一下这种分组训练为什么会对长尾的场景存在差异。\n⭐“Bag of Tricks for LT Visual Recognition with Deep Convolutional Neural Network” ZHIHU ⭐“BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition” ZHIHU CVPR20 ❓“Long-Tail Learning via Logit Abjustment” ICLR 20 zhihu1 | zhihu2 “Improving Calibration for Long-Tailed Recognition” CVPR21 zhihu ⭐“Distribution Alignment: A Unified Framework for Long-tail Visual Recognition” CVPR21 zhihu | zhihu2 “Decoupling Representation and Classifier for Long-Tailed Recognition” ICLR20 “Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect” NIPS20 | zhihu “Rethinking the Value of Labels for Improving Class-Imbalanced Learning” NIPS20| zhihu “Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification” CVPR21 zhihu 总结性串讲：\nLT-Classification ","wordCount":"690","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover0.jpeg","datePublished":"2021-12-22T14:36:16Z","dateModified":"2021-12-22T14:36:16Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/lt-collection/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">LT Collection</h1><div class=post-meta><span title='2021-12-22 14:36:16 +0000 UTC'>December 22, 2021</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;690 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;·&nbsp;<a href=/tags/long-tailed-learning> Long-Tailed Learning</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/LT-Collection.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover0.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#lt-collections aria-label=LT-Collections>LT-Collections</a><ul class=header-level-1><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#rebalance aria-label=Rebalance>Rebalance</a><ul class=header-level-2><li><a href=#reweighting aria-label=reweighting>reweighting</a></li><li><a href=#rebalance-1 aria-label=rebalance>rebalance</a></li></ul></li><li><a href=#two-stage aria-label=two-stage>two-stage</a><ul class=header-level-2><li><a href=#motivation aria-label=motivation>motivation</a></li><li><a href=#bbn-structure aria-label="BBN structure">BBN structure</a></li><li><a href=#decoupling aria-label=Decoupling>Decoupling</a></li><li><a href=#better-calibration aria-label=better-calibration>better-calibration</a></li><li><a href=#disalign aria-label=DisAlign>DisAlign</a></li></ul></li><li><a href=#caucal-analysis aria-label="Caucal Analysis">Caucal Analysis</a></li><li><a href=#contrastive aria-label=Contrastive>Contrastive</a><ul class=header-level-2><li><a href=#hybird-contrastive aria-label="hybird contrastive">hybird contrastive</a></li><li><a href=#the-value-of-labels aria-label="The value of labels">The value of labels</a></li></ul></li><li><a href=#mixup-in-lt aria-label="MixUp in LT">MixUp in LT</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a><ul class=header-level-2><li><a href=#%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c%e6%b1%87%e6%80%bb aria-label=实验结果汇总>实验结果汇总</a></li></ul></li><li><a href=#reference aria-label=Reference>Reference</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=lt-collections>LT-Collections<a hidden class=anchor aria-hidden=true href=#lt-collections>#</a></h1><p>@AikenHong 2021</p><p><a href=https://github.com/mitming/OpenLT target=_blank rel=noopener>Code of must of those methods</a>
We will analysis those tricks on LT situation, and Analysis why it works.
在进行LT矫正的任务中，有几种常见的trick在各种模型中被使用，我们会对这几种不同的trick进行介绍和分析。</p><p>其实在数据量少这一方面LT和Few-Shot是有一定的OverLap的,可以参考以下那边的思路perhaps</p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png><img alt=LT loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165531.png style="display:block;margin:0 auto" alt=LT></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>通常情况下这种严重的类别不平衡问题会使得模型严重过拟合于头部，而在尾部欠拟合</p><p>首先介绍 <a href=https://zhuanlan.zhihu.com/p/416315017 target=_blank rel=noopener>bag of tricks</a>
这篇论文中总结了一些常用的Trick，并组合出了最佳的一套trick</p><p>经过该文实验总结，Trick组合应该是<sub>[1]`</sub>：</p><ul><li>在前几个epoch应用input mixup数据增强，然后后面fine-tuning;</li><li>(基于CAM的)重采样来重新训练分类器;</li></ul><p>实际上就是MixUp + Two-Stage的策略，后续对<strong>Mix-up</strong>这个策略带来的作用要进行补充了解一下</p><h2 id=rebalance>Rebalance<a hidden class=anchor aria-hidden=true href=#rebalance>#</a></h2><p>对于ReBalance的方法，实际上就是从 <code>data</code>和 <code>update</code>两个角度来缓解Unbalance本身，通过从数据量上达到重新均衡，或者基于Loss使得bp过程中赋予Tail更高的权重来达到优化过程的平衡。</p><p>前者称为rebalance，后者则为reweight.</p><h3 id=reweighting>reweighting<a hidden class=anchor aria-hidden=true href=#reweighting>#</a></h3><p>这一部分在实际设计上的体现主要是通过对Loss的重新构造而成，通过对Loss的构造来实现区分的BP权重.</p><ol><li>代价敏感softmax交叉熵损失CS_CE: 在ce前乘最小训练图像数目与每个类别图像数目的比值，相当于更注重少类样本</li></ol><div>$$
\mathcal{L}_{CS\_CE}(\mathbf{z}, c)=-\frac{n_{\min }}{n_{c}} \log \left(\frac{\exp \left(z_{c}\right)}{\sum_{i=1}^{C} \exp \left(z_{i}\right)}\right)
$$</div><ol start=2><li>Focal Loss：设置 $\alpha$ 和 $\beta$ 来控制少数类和难分类别对损失的贡献：</li></ol><div>$$ \mathcal{L}_{\text {Focal }}(\mathbf{z}, c)=-\sum_{i=1}^{C}\left(1-p_{i}^{t}\right)^{\gamma} \log \left(p_{i}^{t}\right) $$</div><ol start=3><li>类别平衡损失：就是在基本的损失（CE，FOCAL）前加入一个衡量权重，其中 $\beta$ 是一个超参数，来衡量有效的信息</li></ol><div>$$ \mathcal{L}_{CB\_Focal}(\mathbf{z}, c)=-\frac{1-\beta}{1-\beta^{n_{c}}} \sum_{i=1}^{C}\left(1-p_{i}^{t}\right)^{\gamma} \log \left(p_{i}^{t}\right) $$</div><ol start=4><li>Logit Abjustment<sub>[3]</sub>:</li></ol><div>$$ \ell(y, f(x))=\alpha_{y} \cdot \log \left[1+\sum_{y^{\prime} \neq y} e^{\Delta_{y y^{\prime}}} \cdot e^{\left(f_{y^{\prime}}(x)-f_{y}(x)\right)}\right] $$</div><h3 id=rebalance-1>rebalance<a hidden class=anchor aria-hidden=true href=#rebalance-1>#</a></h3><p>实际上就是对少类或者多类的数据重新做均衡，方法的本质差别一般都不是特别大</p><ol><li><strong>随机过采样</strong>：随即重复少数类别的样本来使得样本均衡</li><li><strong>随机降采样</strong>：随机删除多数类别的样本使得样本均衡</li><li><strong>样本平衡采样</strong>：应该值得就是1-2 IB-Sampling</li><li><strong>类别平均采样</strong>: 对类别进行统一采样，每个类别被采样的概率都一样(Q=0)，然后从每个类别中有放回的随机采样实例，从而构建平衡的数据集</li></ol><div>$$ p_j = \frac{n_j^q}{\sum_{i=1}^C n_i^q} $$</div><ol start=5><li><strong>平方根采样</strong>(Q=0.5)</li><li><strong>逐步平衡采样</strong>：先对多个epoch进行实例平衡采样（上式q=1，也就是没有任何平衡操作的采样），然后再剩下的epoches中进行类别平衡采样。这种采样方式需要设置一个超参数来调整从哪一个epoch开始变换采样方式。也可以使用更软的阈值，即随着epoch的增加来逐渐调整实例平衡采样（IB）和类别平衡采样所占的比例，如下面公式所示。</li></ol><div>$$
P_j^{PB} (t) = (1-\frac{t}{T})P_j^{IB} + \frac{t}{T}P_j^{CB}
$$</div><h2 id=two-stage>two-stage<a hidden class=anchor aria-hidden=true href=#two-stage>#</a></h2><p>在Unbalanced的Data上Pretrain一个特征提取器，然后再rebalance（IB，CB）的数据集上对Classifier进行重新训练（调整），（and | or）对齐，校准（disalign，causal）来提升LT的性能的方法</p><h3 id=motivation>motivation<a hidden class=anchor aria-hidden=true href=#motivation>#</a></h3><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165813.png><img alt=rebalance loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165813.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217165813.png style="display:block;margin:0 auto" alt=rebalance></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>但是这些rebalance的方法通常会带来以下两个问题<sub>[2]</sub>：</p><ul><li>rebalance之后分类器会倾向于分类正确的尾部样本，导致对于头部有一定的bad influence（欠拟合），对尾部过拟合</li><li>rebalance方法会显著的促进分类器的学习，但是会损害深度特征的表示能力，如上图所示，分类器学到的分界面更好，但是特征的表示却更加的松散了</li></ul><blockquote><p>我认为rebalance的策略确实会使得Clf学的更好的分界面，减少偏向性，但是不至于在尾部过拟合，这一部分分析最重要的应该是rebalance对于特征空间的Bad Influence，这可能就是Two Stage的来源。</p></blockquote><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217172128.png><img alt=Absl loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217172128.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/labimg/20211217172128.png style="display:block;margin:0 auto" alt=Absl></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>于是作者为其设计了一些消融实验：CE指的是长尾，RW，RS指的是使用的rebalance的数据。</p><p>可以发现在Backbone上使用Unbalance的数据而在Clf上使用Resampler的数据效果是最好的，这种two-stage的解耦两阶段的训练策略展现了一个有希望的结果。</p><blockquote><p>这种两阶段的方式，我认为在第二阶段的时候也要对特征进行微调来适应当前的分布，不过很多的方法都是直接只对分类器进行调整，我们可以对两种方式进行测试</p></blockquote><p><em>下图显示了fix-two-stage和baseline对比</em><sub>[5]</sub><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218155958.png><img alt=two-stage loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218155958.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218155958.png style="display:block;margin:0 auto" alt=two-stage></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p><em>下图展示了理想的two-stage结果与显示方法之间的距离</em><sub>[5]</sub>
cls-bound是再fix特征后，用完全均衡的数据集训练分类器得到的结果，由此带入第二张图的绿色的线，可以知道，现有长尾方法的性能瓶颈（未使用two-stage），仍然在特征空间中的有偏差的决策边界。<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218161858.png><img alt=ideal-real loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218161858.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218161858.png style="display:block;margin:0 auto" alt=ideal-real></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>基于这些分析,我们认为，在得到一个强有力的特征表示后，我们可以将问题归化到分类器上，基于这点假设，我们可以结合我们的自监督模块来对该方法进行归化。</p><h3 id=bbn-structure>BBN structure<a hidden class=anchor aria-hidden=true href=#bbn-structure>#</a></h3><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218124356.png><img alt=BBN loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218124356.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218124356.png style="display:block;margin:0 auto" alt=BBN></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>Share Weight of Backbone，Using diff dataset to get diff feature. Then we using $\alpha$ to Combine the logits and calculate the loss.</p><div>$$
z = \alpha * W_c^T * f_c + (1-\alpha) * W_\gamma^T * f_\gamma
$$</div><div>$$
L = \alpha * l(softmax(z),y_c) + (1-\alpha) *l(softmax(z),y_\gamma)
$$</div><p>在上述的流程图中W代表的是两个不一样的数据优化器，基于这样的设置最终就能区分两部分的优化。</p><blockquote><p>但是这个方法为我们带来的最大的启发还是在于区分两阶段中学习的重点，backbone需要在一个unblance的条件下学习一个更为通用的表征，而Cls需要矫正偏差。不平衡的情况下可能能学到一个很好的通用表征，这一点就是我们使用自监督的一个重要原因。</p></blockquote><h3 id=decoupling>Decoupling<a hidden class=anchor aria-hidden=true href=#decoupling>#</a></h3><p>==Train BB and Fixed then Train CLF==
此外坐着发现全连接的weight和norm和对应类别的样本数正相关，所以在第二部最后将分类器改为归一化的分类器，文中的两种设计是：</p><ol><li>$\overline{W_i}=\frac{w_i}{\lVert W_i \rVert^T}$</li><li>$\overline{W_i}=\frac{w_i}{f_i}$</li></ol><p>其中2利用fixed第一步分类权重 $w_i$ ,对每个类学习了一个加权参数 $f_i$</p><h3 id=better-calibration>better-calibration<a hidden class=anchor aria-hidden=true href=#better-calibration>#</a></h3><p>但是这种两阶段的方式也不是没有代价的，他会带来比较严重的<strong>校准错误</strong>(Calibration)，也就是我们预测的概率和实际的相似度之间的一致性。</p><p>（BTW评估校准错误的指标 $ECE=\sum_{b=1}^B\frac{|S_b|}{N} |acc(S_b) - conf(S_b)|$ ，将数据分为b组，S_b是落入b区间的样本集合)</p><p>本文主要测试了MixUP在两阶段训练中的作用，以及提出了：</p><ol><li>标签感知平滑损失，实际上就是cb_ce的半泛化形式：</li></ol><div>$$ \begin{gathered}
l(\boldsymbol{q}, \boldsymbol{p})=-\sum_{i=1}^{K} \boldsymbol{q}_{i} \log \boldsymbol{p}_{i} \\
\boldsymbol{q}_{i}= \begin{cases}1-\epsilon_{y}=1-f\left(N_{y}\right), & i=y \\
\frac{\epsilon_{y}}{K-1}=\frac{f\left(N_{y}\right)}{K-1}, & \text { Otherwise }\end{cases}
\end{gathered} $$</div><p>$\epsilon_y$ 是y(gt)的一个小平滑因子,数目与类别的样本数有关，并提出了几种函数形式，来优化这个损失
2. BN的移位学习，由于两阶段的数据集不一致，所以normalize的参数是需要学习变化的（均值和方差）</p><p>具体的数学分析和推导，后续根据论文理解了再来补充</p><h3 id=disalign>DisAlign<a hidden class=anchor aria-hidden=true href=#disalign>#</a></h3><p>基于上述对于方法的分析，该文章着重于对于分类器进行校准，具体的思路是基于利于平衡预测的类别分布来对分类器的输出进行匹配，矫正；简单的说利用类别先验和输入数据学习类别的决策边界。
具体由两部分构成(重构预测的概率输出，建立理想分布，使用KL散度计算损失)</p><ol><li>自适应配准函数</li></ol><div>$$ \begin{gathered}
s_{j}=\alpha_{j} \cdot z_{j}^{o}+\beta_{j}, \quad \forall j \in \mathcal{C} \\
\hat{z}_{j}=\sigma(\mathbf{x}) \cdot s_{j}+(1-\sigma(\mathbf{x})) \cdot z_{j}^{o} \\
=\left(1+\sigma(\mathbf{x}) \alpha_{j}\right) \cdot z_{j}^{o}+\sigma(\mathbf{x}) \cdot \beta_{j} \\
p_{m}(y=j \mid \mathbf{x})=\frac{\exp \left(\hat{z}_{j}\right)}{\sum_{k=1}^{C} \exp \left(\hat{z}_{k}\right)}
\end{gathered} $$</div><ol start=2><li>广义重加权校准
理想的分布的计算方法如下，定义说的不是很好，最好还是参考一下代码</li></ol><div>$$ \begin{gathered}
p_{r}\left(y=c \mid \mathbf{x}_{i}\right)=w_{c} \cdot \delta_{c}\left(y_{i}\right), \quad \forall c \in \mathcal{C} \\
w_{c}=\frac{\left(1 / r_{c}\right)^{\rho}}{\sum_{k=1}^{K}\left(1 / r_{k}\right)^{\rho}}, \quad \forall c \in \mathcal{C}
\end{gathered} $$</div><p>最终的损失计算方程如下：</p><div>$$
\begin{aligned}
\mathcal{L} &=\mathbb{E}_{\mathcal{D}_{t r}}\left[\mathcal{K} \mathcal{L}\left(p_{r}(y \mid \mathbf{x}) \| p_{m}(y \mid \mathbf{x})\right)\right] \\
& \approx-\frac{1}{N} \sum_{i=1}^{N}\left[\sum_{y \in \mathcal{C}} p_{r}\left(y \mid \mathbf{x}_{i}\right) \log \left(p_{m}\left(y \mid \mathbf{x}_{i}\right)\right)\right]+C
\end{aligned}
$$</div><p>==训练的具体策略==
1）在第一阶段，在不平衡数据集上使用实例平衡 ( instance-balanced ) 采样策略实现特征提取器和原始分类头的联合学习。此时由于不平衡的数据分布，学习到的原始分类头是严重有偏的。</p><p>2）在第二阶段，我们在特征提取器参数固定不变的情况下关注分类头以调整决策边界，引入了自适应配准函数 ( adaptive calibration function ) 和广义重加权 ( generalized re-weight ) 策略来配准各类概率。</p><h2 id=caucal-analysis>Caucal Analysis<a hidden class=anchor aria-hidden=true href=#caucal-analysis>#</a></h2><p>基于two-stage的这种现象，然后分析机器和人学习的区别，认为带来偏差的元凶在于Optim优化算法，为此，该文章构建因果图，从而去除在模型更新过程中由动量带来的偏差效应。</p><center>"keep good and remove bad momentum"<sub>[7]</sub></center><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218172020.png><img alt=causal loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218172020.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211218172020.png style="display:block;margin:0 auto" alt=causal></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>$v_t = \mu · v_{t-1} + g_t$ , $\theta = \theta_{t-1} - lr · v_t$</p><p>要调用这个方法的话，我们就需要</p><ol><li>将训练的CLF修改成Multi-Head并Normlize，参考Decouple.</li><li>训练过程中统计移动平局特征 $\overline{x}$ ，将其单位方向看成头部倾向.</li><li>测试的过程中修正logits即可</li></ol><p>具体公式参考对应的解析和代码实现;</p><p>和自监督结合的话，只需要在微调的阶段进行统计和修正即可，毕竟是一个一阶段的方式。</p><h2 id=contrastive>Contrastive<a hidden class=anchor aria-hidden=true href=#contrastive>#</a></h2><p>这一部分考虑一些和对比学习，或者说自监督学习耦合的方法来进行分析。</p><p>为何将这两者放到同一个章节中？
因为这两者企图从表征的层面，为LT任务，带来增益，得到一个可分的特征空间基于良好的特征表达，进而解耦的来训练一个更好的CLF。</p><blockquote><p>如果我们假设我们能得到一个高维线性可分的特征空间，对于长尾的样本带来的训练偏差（决策面偏差）是否可以通过对于特定类别的Margin-Like的Loss设置，达到一个类似Balance的效果，这一点上实际上可能和Align和校正的思想有点相似。但是我们是为了让分类器空间中的分界面在小样本的束缚下变得更加的合理。</p></blockquote><p>从分界面的角度看LT的情况：（上面是普通CE，下面是Contrastive Learning）<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219145815.png><img alt=CL loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219145815.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219145815.png style="display:block;margin:0 auto" alt=CL></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>在数据量出现较大的差异的情况下，由于蓝色的数目更多更杂，所以实际上分界面可能会沿着蓝色数据的边界做切分（overfit），在这种Class-Level的过拟合下，就会导致对于少数类别的分类结果很差。</p><p>而下方的对比学习就是一样的解决方案，他试图将同一类的数据聚拢在一起，将不同类的距离尽可能的拉远，这样会使得在空间中的决策面更加的鲁棒也已于区分，虽然可能会一定程度上减少蓝色的表现，但是红色的表现会因此大大的提升。</p><h3 id=hybird-contrastive>hybird contrastive<a hidden class=anchor aria-hidden=true href=#hybird-contrastive>#</a></h3><p>该文章<sub>[9]</sub>的基本架构上实际上参考的就是BBN的epoch-params在two-stage中集成 supervised contrasive Loss，具体框架可以看下面这图：<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219150447.png><img alt="hybird-contrastive learning for lt" loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219150447.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219150447.png style="display:block;margin:0 auto" alt="hybird-contrastive learning for lt"></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script>他的设计思想很容易从这张图中领会，损失函数的表达显然如下</p><div>$$
L_{hybird} = \alpha · L_{SCL}(B_{SC}) + (1-\alpha) · L_{ce}(B_{CE})
$$</div><p>在这里要注意SC和自监督中使用的区别在于，自监督学习的过程中没有标签，所以只能将自己作为Positive，而在SC的时候，同类的样本之间应该都作为Positive</p><div>$$
\mathcal{L}_{S C L}\left(\mathbf{z}_{i}\right)=\frac{-1}{\left|\left\{\mathbf{z}_{i}^{+}\right\}\right|} \sum_{\mathbf{z}_{j} \in\left\{\mathbf{z}_{i}^{+}\right\}} \log \frac{\exp \left(\mathbf{z}_{i} \cdot \mathbf{z}_{j} / \tau\right)}{\sum_{\mathbf{z}_{k}, k \neq i} \exp \left(\mathbf{z}_{i} \cdot \mathbf{z}_{k} / \tau\right)}
$$</div><p>鉴于SC的计算复杂度要和整个Epoch的数据进行对比，需要大量的显存空间，在这方面作者将其改进为PSC，其实也就是将每个class计算一个prototype，然后基于原型去计算这个相似性损失</p><div>$$
\mathcal{L}_{P S C}\left(\mathbf{z}_{i}\right)=-\log \frac{\exp \left(\mathbf{z}_{i} \cdot \mathbf{p}_{y_{i}} / \tau\right)}{\sum_{j=1, j \neq y_{i}}^{C} \exp \left(\mathbf{z}_{i} \cdot \mathbf{p}_{j} / \tau\right)}
$$</div><p>在这里这个Prototypical需要正则化到单位元中，这样能快速计算相似性损失，也不会需要大量的现存。</p><blockquote><p>可以参考的点主要就在于损失的设计和框架上的这种分epoch机制了，但是基于自监督的方式的话，可能不是很用的上这一点，但是我们可以考虑怎么结合这个loss去做对应的分类器。</p></blockquote><h3 id=the-value-of-labels>The value of labels<a hidden class=anchor aria-hidden=true href=#the-value-of-labels>#</a></h3><p>这一篇文章是将自监督学习和半监督学习应用到长尾分布的问题上，文章对应的仓库中可以get预训练模型和很多对应的数据，同时验证了下面两种策略都可以大大提升模型的效果，包括和之前的各种策略进行耦合。</p><ul><li>半监督：利用更多的无标注数据</li><li>自监督：不利用任何其他数据，使用长尾分布的数据进行自监督训练</li></ul><blockquote><p>后续的实验过程中我可能也会遵循该设计，或者使用的是全数据的自监督预训练。</p></blockquote><p>考虑尾部标签本身的意义，想要利用尾部的标签信息，又不受偏差的影响，实际上就是使用自监督进行预训练，然后后面使用各种方法兼容的一个策略。<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219155744.png><img alt=Self-Supervised loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219155744.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211219155744.png style="display:block;margin:0 auto" alt=Self-Supervised></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h2 id=mixup-in-lt>MixUp in LT<a hidden class=anchor aria-hidden=true href=#mixup-in-lt>#</a></h2><p>将MixUP应用在LT中，试图"以使其具有更高的泛化性，以及降低模型本身的置信度"<sub>[4]</sub>, 经过实验表明，仅在Stage1使用MixUP，在Stage2的第二阶段使用几个epoch的Mixup的效果可能会更好。</p><p>在这里可能也要考虑一下CutMix方法</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><h3 id=实验结果汇总>实验结果汇总<a hidden class=anchor aria-hidden=true href=#实验结果汇总>#</a></h3><p>基于BackBone对这些方法的实验结果( $Top1 Acc$ )进行汇总，作为我们后续研究的参照：在进行实验的时候，我们需要首先调整好BenchMark，基于Benchmark做的改进才能和对应的方法进行对比。</p><p><strong>整理原则</strong>：</p><ol><li>对应的论文则由该论文本身为主，后续和LT的仓库进行对比分析；</li><li>最主要需要对比的应该是ce情况下的指标，这是我们最重要的，当这个指标对齐后，我们就可以和这些方法同台竞技了。</li></ol><table><thead><tr><th>Dataset</th><th style=text-align:center>-></th><th style=text-align:center>LT-Cifar-100</th><th style=text-align:center>&lt;-</th><th style=text-align:center>-></th><th style=text-align:center>LT-CIfar10</th><th style=text-align:center>&lt;-</th><th>Backbone</th></tr></thead><tbody><tr><td>Factor(Exp)</td><td style=text-align:center>100</td><td style=text-align:center>50</td><td style=text-align:center>10</td><td style=text-align:center>100</td><td style=text-align:center>50</td><td style=text-align:center>10</td><td>ResNet32</td></tr><tr><td>RESULT</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td></td></tr><tr><td>CE</td><td style=text-align:center>38.32</td><td style=text-align:center>43.85</td><td style=text-align:center>55.71</td><td style=text-align:center>70.36</td><td style=text-align:center>74.81</td><td style=text-align:center>86.39</td><td>-</td></tr><tr><td>Focal Loss</td><td style=text-align:center>38.4</td><td style=text-align:center>44.3</td><td style=text-align:center>56.8</td><td style=text-align:center>70.4</td><td style=text-align:center>76.7</td><td style=text-align:center>86.7</td><td>-</td></tr><tr><td>MixUp</td><td style=text-align:center>39.5</td><td style=text-align:center>45.0</td><td style=text-align:center>58.0</td><td style=text-align:center>73.1</td><td style=text-align:center>77.8</td><td style=text-align:center>87.1</td><td>-</td></tr><tr><td>CB Loss</td><td style=text-align:center>39.6</td><td style=text-align:center>45.2</td><td style=text-align:center>58.0</td><td style=text-align:center>74.6</td><td style=text-align:center>79.3</td><td style=text-align:center>87.1</td><td>-</td></tr><tr><td>BAGS-After</td><td style=text-align:center>47.83</td><td style=text-align:center>51.69</td><td style=text-align:center>-</td><td style=text-align:center>73.59</td><td style=text-align:center>79.03</td><td style=text-align:center>-</td><td>-</td></tr><tr><td>SSL-Uniform</td><td style=text-align:center>40.40</td><td style=text-align:center>45.04</td><td style=text-align:center>57.07</td><td style=text-align:center>73.50</td><td style=text-align:center>78.20</td><td style=text-align:center>87.72</td><td></td></tr><tr><td>SSL-Balanced</td><td style=text-align:center>43.06</td><td style=text-align:center>47.09</td><td style=text-align:center>58.06</td><td style=text-align:center>76.53</td><td style=text-align:center>80.4</td><td style=text-align:center>87.72</td><td></td></tr><tr><td>LDAM</td><td style=text-align:center>42.0</td><td style=text-align:center>46.6</td><td style=text-align:center>58.7</td><td style=text-align:center>77.0</td><td style=text-align:center>81.0</td><td style=text-align:center>88.2</td><td>-</td></tr><tr><td>BBN</td><td style=text-align:center>42.56</td><td style=text-align:center>47.07</td><td style=text-align:center>59.12</td><td style=text-align:center>79.82</td><td style=text-align:center>82.18</td><td style=text-align:center>88.32</td><td>-</td></tr><tr><td>Causal</td><td style=text-align:center>44.1</td><td style=text-align:center>50.3</td><td style=text-align:center>59.6</td><td style=text-align:center>80.6</td><td style=text-align:center>83.6</td><td style=text-align:center>88.5</td><td>-</td></tr></tbody></table><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><p>阅读过程中还看到一些什么BAGS，进行数据分组的方法，这个方法肯定不会在我们的框架中使用，但是我们可以分析一下这种分组训练为什么会对长尾的场景存在差异。</p><ol><li>⭐&ldquo;Bag of Tricks for LT Visual Recognition with Deep Convolutional Neural Network&rdquo; <a href=https://zhuanlan.zhihu.com/p/416315017 target=_blank rel=noopener>ZHIHU</a></li><li>⭐&ldquo;BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition&rdquo; <a href=https://zhuanlan.zhihu.com/p/373053356 target=_blank rel=noopener>ZHIHU</a>
CVPR20</li><li>❓&ldquo;Long-Tail Learning via Logit Abjustment&rdquo; ICLR 20 <a href=https://zhuanlan.zhihu.com/p/267058892 target=_blank rel=noopener>zhihu1</a>
| <a href=https://zhuanlan.zhihu.com/p/403981340 target=_blank rel=noopener>zhihu2</a></li><li>&ldquo;Improving Calibration for Long-Tailed Recognition&rdquo; CVPR21 <a href=https://zhuanlan.zhihu.com/p/419911014 target=_blank rel=noopener>zhihu</a></li><li>⭐&ldquo;Distribution Alignment: A Unified Framework for Long-tail Visual Recognition&rdquo; CVPR21 <a href=https://zhuanlan.zhihu.com/p/422891404 target=_blank rel=noopener>zhihu</a>
| <a href=https://zhuanlan.zhihu.com/p/385053738 target=_blank rel=noopener>zhihu2</a></li><li>&ldquo;Decoupling Representation and Classifier for Long-Tailed Recognition&rdquo; ICLR20</li><li>&ldquo;Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect&rdquo; NIPS20 | <a href=https://zhuanlan.zhihu.com/p/259569655 target=_blank rel=noopener>zhihu</a></li><li>&ldquo;Rethinking the Value of Labels for Improving Class-Imbalanced Learning&rdquo; NIPS20| <a href=https://zhuanlan.zhihu.com/p/390106051 target=_blank rel=noopener>zhihu</a></li><li>&ldquo;Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification&rdquo; CVPR21 <a href=https://zhuanlan.zhihu.com/p/405043879 target=_blank rel=noopener>zhihu</a></li></ol><p>总结性串讲：</p><ol><li><a href=https://www.cnblogs.com/fusheng-rextimmy/p/15389065.html target=_blank rel=noopener>LT-Classification</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/machine-learning/>Machine Learning</a></li><li><a href=https://hugotest-phi.vercel.app/tags/survey/>Survey</a></li><li><a href=https://hugotest-phi.vercel.app/tags/long-tailed-learning/>Long-Tailed Learning</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/il-wyz/><span class=title>« Prev</span><br><span>WYZ-IL-Collection</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/loss-nce/><span class=title>Next »</span><br><span>Loss-NCE</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>