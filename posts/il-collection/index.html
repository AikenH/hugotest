<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>IL Collection | aiken's blog</title>
<meta name=keywords content="Incremental Learning,Machine Learning,Survey"><meta name=description content="@AikenHong 2022
[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.
In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure.
在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发

DER

SPPR 没有 get 到方法到底是怎么做的

Introduction 👿
在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。
Incremental 的基本过程可以表示如下[4]：


  
    
  




"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/il-collection/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/il-collection/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/il-collection/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="IL Collection"><meta property="og:description" content="@AikenHong 2022
[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.
In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure. 在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发
DER SPPR 没有 get 到方法到底是怎么做的 Introduction 👿 在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。
Incremental 的基本过程可以表示如下[4]： "><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-01-04T01:38:04+00:00"><meta property="article:modified_time" content="2022-01-04T01:38:04+00:00"><meta property="article:tag" content="Incremental Learning"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Survey"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover9.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover9.jpeg"><meta name=twitter:title content="IL Collection"><meta name=twitter:description content="@AikenHong 2022
[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.
In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure.
在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发

DER

SPPR 没有 get 到方法到底是怎么做的

Introduction 👿
在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。
Incremental 的基本过程可以表示如下[4]：


  
    
  




"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"IL Collection","item":"https://hugotest-phi.vercel.app/posts/il-collection/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"IL Collection","name":"IL Collection","description":"@AikenHong 2022\n[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.\nIn this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure. 在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发\nDER SPPR 没有 get 到方法到底是怎么做的 Introduction 👿 在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。\nIncremental 的基本过程可以表示如下[4]： ","keywords":["Incremental Learning","Machine Learning","Survey"],"articleBody":"@AikenHong 2022\n[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.\nIn this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure. 在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发\nDER SPPR 没有 get 到方法到底是怎么做的 Introduction 👿 在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。\nIncremental 的基本过程可以表示如下[4]： 我们将模型可以划分为以下的两个部分[1]：backbone 和 classifier 从 LWF 中我们可以知道经典的 Paradigm，主要有下面的三种来对 $\\theta _S$ 和 $\\theta_o$ 来进行更新：\n仅重新训练分类器：仅更新 $\\theta_o$ 微调特征提取器，重新训练分类器 联合训练 基于蒸馏架构的方法 这一系列的方法实际上是 IL 最经典的发展路线，实际上从初始的蒸馏架构开始，最后逐渐的发展到结合回放的策略中，我认为结合rehearsal才是该类方法最后的归宿，所以我将基于蒸馏正则化的 Pod 和 LWF 也放到了这一部分。\nMotivation 《Learning without Forgetting》LWF 主要带来的就是将 KD 损失引入 Joint Training 的范式，也就是我们印象中最原始的增量学习的途径，利用 expand_dim 训练最后输出的新的节点，但是这个范式是不需要旧数据。\n$$ Loss = L_{CE} + L_{KD}\r$$\r这里的蒸馏使用的是最终的 pred 输出，后续对于蒸馏损失的有 KDC 的变体，根据新旧样本的比例来赋予权重，考虑模型优化的权重。\n$$ Loss = \\lambda L_{CE} + (1-\\lambda) L_{KD}\r$$\r其中 $\\lambda^2 = \\frac{|C_{old}|}{|C_{old}|+ |C_{new}|}$\n这就是最经典的 Incremental Learning 的范式，我们首先继承一部分分类器的参数，然后通过这个损失对整个框架进行协同训练。\n引入旧样例 《ICaRL: Incremental Classifier and Representation Learning》在 LWF 基础上引入部分旧数据来避免灾难遗忘的问题\n基于特征提取器对新旧数据的训练集提取==平均特征向量==（Kmeans + KNN） 基于最近邻均值分类算法 NME 计算出新旧数据的预测值 计算 LWF 的经典损失，优化模型 本文的亮点主要在于引入了旧的数据进行复习（有一个比较好的数据选取策略），以及最后使用的不是全连接层而是最近邻分类器来作为预测。（Will This Get Better？）\n后续在 ==《End-to-End Incremental Learning》== 中，将最近邻分类器替换成分类层，其动机就是对 ICaRL 进行优化。\nmemory 保存旧样本 -\u003e CE+KD -\u003e reBalance + Fine-tune\n由于数据量上的有偏，导致分类器会严重有偏与 New-Classes，但是我认为这个可能是对于场景设定的不同，加入新的需求和发现少量的数据两者是一个比较大的不同。\n这里的 样本选择策略 可能在后续会比较有用。\n在 ICaRL 中选择的是最确信的样本来 rehearsal，也就是使用特征中心的 KNN 方法来选取样本。 而在==《Rainbow Memory》==[8]中则是选择最难的样本，其 motivation 是选择最接近判别界样本 RM 的最终实现的思路是通过 Data Augmentation 对样本进行变化，将不同 Augmentaion 后的预测的偏差（不确定程度）来衡量一个样本是 Hard or Simple Task，基于这种方式来选择 Hard-Task（Uncertainty）\n具体而言，标签为 c 的样本，经过 perturbed 后，被网络预测为 c 类的次数越多，则不确定性越弱。\n优化分类器 由于新类的大量数据带来的偏差，==《Large Sacale Incremental Learning》== 试图解决这个问题\n将训练集划分一个 rebalance 的 dataset 作为验证集，并用该数据集训练一个 Bias Correction Layer 得到修正的参数， 该层的输出如下，实际上就是一个线性回归层，只有两个参数\n$$ q_{k}=\\left\\{\\begin{array}{lr}\ro_{k} \u0026 1 \\leq k \\leq n \\\\\r\\alpha o_{k}+\\beta \u0026 n+1 \\leq k \\leq n+m\r\\end{array}\\right.\r$$\r训练该层的时候固定 CLF 和 BB，使用 CE 损失即可，但是模型在大数据集上的表现更佳，在 cifar100 的小数据集上表现一般。\n另外还有借助 Long-Tailed 中的策略，从 $||W||$ 的角度矫正偏差的文章 ==《Learning a Unified Classifier Incrementally via Rebalancing》==\n动机是由于：1）imbalance：new classes 的权重的大小远远高于 old classes 的权重。2）特征与 old classes 的权重关系没有保留。3）一些 new classes 的权重与 old classes 的权重相近（容易混淆的类别），导致歧义性。\n引入了 Cosine Normalization 分类器，实际上就是进分类器之前进行正则化，加入 Margin 损失（可以参考人脸比对的 Cosine Face 之类的）最终损失为：\n$$ L=\\frac{1}{|\\mathcal{N}|} \\sum_{x \\in \\mathcal{N}}\\left(L_{\\mathrm{ce}}(x)+\\lambda L_{\\mathrm{dis}}^{\\mathrm{G}}(x)\\right)+\\frac{1}{\\left|\\mathcal{N}_{\\mathrm{o}}\\right|} \\sum_{x \\in \\mathcal{N}_{\\mathrm{o}}} L_{\\mathrm{mr}}(x)\r$$\r更简单的有==《Maintaining discrimination and fairness in class incremental learning》==，通过对于分类器中的新旧模型的**weight **做 Rescale 使其再 W 上达成一致来维持一个较好的效果\n$$ \\begin{gathered}\rW = (W_{old},W_{new}) ; Norm_{old} = (||W_1||, ···, ||W_{c^b_{old}}) \\\\\r\\gamma = \\frac{Mean(Norm_{old})}{Mean(Norm_{new}} \\\\\r\\hat{W}_{new} = \\gamma · W_{new} \\\\\r\\end{gathered}\r$$\r优化特征提取器 其实Incremental现阶段的任务也倾向于使用两阶段的架构，基于这样的架构，我们首先提名最重要的就是基于SCL的这篇文章[9],这篇文章主要的思路是：\nSCL+projector（Train）+NCM（Test）\r训练的Batch就是普通的Memory+New，但是值得一提的是，这篇文章对Memory的数据选取做了消融实验，得到了这样的结果：\n随机选取Memory的效果\u003eGSS（NIPS2019）和ASER（AAAI2021），是一个令人惊讶的结果.\n而类似的，也有使用图像旋转的SSL（缓解ce带来的特征bias）+CE结合Prototype（rehearsal避免遗忘）+ KDLoss的研究[14]，证明了结合类似的自监督任务能够有效缓解特征之间的重叠。\n使用的SSL任务是常见的Rotate Loss, KD是和上一轮的模型做约束。\n$$ L_{t,total} = L_{t,ce} + \\lambda L_{t,protoAug} + \\gamma L_{t,kd}\r$$\r同样的C2OL[15] 这篇方法，就用最基本的对比学习的损失来研究该方法对于IL的实用性，也发现了基于CL学出来的特征确实更适合用在蒸馏的任务之上，验证了我们的猜想。\n优化损失设计 《PODNet Pooled Outputs Distillation for Small-Tasks Incremental Learning》基于样本回放的方法，改进 KD，定义了 Pooled Output Distillation。\nspatial-based distillation-loss，基于空间的蒸馏损失，改进蒸馏方法 representation comprising multiplt proxy vectors，代理向量改进了分类器 ==part1 Update KD Loss==\nPooling 简略图\r假设： $\\hat{y} = g(f(x))$ 为分类过程，其中 $f(x)$ 代表特征提取过程。 POD 算法则为，不仅将蒸馏应用到特征提取的最终输出，还将其用于 $f(x)$ 的中间过程的输出\n$$ f^t(x) = f^t_L .. ·f^t_l .. ·f^t_1(x)\r$$\r中的每一层（如下式）都作为中间的结果，用来做 KD，上标 t 表示 task，下标则表示模型第几层。\n$$ h^t_{l,c,w,h} = f^t_l(·)\r$$\r对该输出的各层执行各种级别的 POD 蒸馏，作为我们的监督来实现对灾难性遗忘的避免：\n$$ \\mathcal{L}_{\\text {POD-pixel }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)=\\sum_{c=1}^{C} \\sum_{w=1}^{W} \\sum_{h=1}^{H}\\left\\|\\mathbf{h}_{\\ell, c, w, h}^{t-1}-\\mathbf{h}_{\\ell, c, w, h}^{t}\\right\\|^{2}\r$$\r显然 pixel 级别对于模型的约束是最强的\n$$ \\begin{gathered}\r\\mathcal{L}_{\\text {POD-channel }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)=\\sum_{w=1}^{W} \\sum_{h=1}^{H}\\left\\|\\sum_{c=1}^{C} \\mathbf{h}_{\\ell, c, w, h}^{t-1}-\\sum_{c=1}^{C} \\mathbf{h}_{\\ell, c, w, h}^{t}\\right\\|^{2} \\\\\r\\mathcal{L}_{\\text {POD-gap }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)=\\sum_{c=1}^{C}\\left\\|\\sum_{w=1}^{W} \\sum_{h=1}^{H} \\mathbf{h}_{\\ell, c, w, h}^{t-1}-\\sum_{w=1}^{W} \\sum_{h=1}^{H} \\mathbf{h}_{\\ell, c, w, h}^{t}\\right\\|^{2} \\\\\r\\mathcal{L}_{\\text {POD-width }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)=\\sum_{c=1}^{C} \\sum_{h=1}^{H}\\left\\|\\sum_{w=1}^{W} \\mathbf{h}_{\\ell, c, w, h}^{t-1}-\\sum_{w=1}^{W} \\mathbf{h}_{\\ell, c, w, h}^{t}\\right\\|^{2}\r\\end{gathered}\r$$\rpixel 级别的蒸馏对于模型限制比较严格，其他级别的对于模型限制相对较松，需要一个权衡，作者最终选用的是 Spatial 级别的蒸馏，相当于 width 和 height 层面蒸馏 loss 之和\n$$ \\mathcal{L}_{\\text {POD-spatial }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)=\\mathcal{L}_{\\text {POD-width }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)+\\mathcal{L}_{\\text {POD-height }}\\left(\\mathbf{h}_{\\ell}^{t-1}, \\mathbf{h}_{\\ell}^{t}\\right)\r$$\r特征提取模型最终的特征则使用 pixel 级别的蒸馏：\n$$ \\mathcal{L}_{POD-flat}(h^{t-1},h^t) = ||h^{t-1} - h^t||^2\r$$\r将这些蒸馏损失整合起来取代原本的 KD-Loss，再加上我们的 CE 即可：\n$$ \\begin{gathered}\r\\mathcal{L}_{POD-final} = \\frac{\\lambda_c}{L-1}\\sum_{l=1}^{L-1} \\mathcal{L}_{POD-spatial}(f_l^{t-1}(x),f_l^t(x)) + \\\\\r\\lambda_f \\mathcal{L}_{POD-flat}(f_l^{t-1}(x),f_l^t(x))\r\\end{gathered}\r$$\r==Part2 Local Similarity Classifier==\n第一个改进点就是将 Loss 修正为 Cosine 的形式UCiR，实际上就是使用的归一化后的 FC 层，但是如果只使用一个 Cos 相似度，好像多样化的需求无法满足，需要类似一个多头的机制\n和 LT 的地方一样，IL 近年来的主要架构也是两部分进行分离的，所以我们可以考虑从我们的角度来实现类似 POD-Loss 的架构维持，也就是一定程度上为我们的 SSL-SCL 架构的可行性提供了一定的信心。\n该方法迄今为止还是很多增量任务的榜单前几，该方法的蒸馏性能也被验证为有效，但是实际上将该方法用于模型中需要增加大量的特征输出模块，整体架构上修改起来可能会较为复杂。\n基于模型结构的方法 这一部分不是我研究的重点，可以看到有一部分设计的拓张模型或者，堆叠模型，用额外的结构来承载对应的新类的研究，可能考虑到一部分参数公用然后实行协同判断的策略把。\n或者是其他的图模型，拓扑结构（神经气体网络）等等的方法，拓扑结构等方法可能户籍是未来的一个方向。\n特征网络堆叠 DER 特征网络堆叠的方法 其他方法 EWC ：这类方法一般是对网络中每个参数的重要性进行评估，根据每个参数的重要性，调整梯度信息更新参数。 其他问题 这里会收集一部分 IL 中存在的一些现象或者问题\n新类优于旧类 模型倾向于时间上接近的模型有更高的敏感度，这可能是训练的过程决定的，也可能是由于再新类的训练上新类的权重要明显高于旧类，导致的某种数据不均衡的现象。\n此外在传统的设定中，新类的数据量会大大的大于旧类\nFew-Shot Incremental Few-Shot 的增量情景更贴切于我的场景假设，在这种假设的背景之下，增量学习也会面临一些新的困难，这个篇章中我们可能会简要的总结一些方法对抗小样本和灾难性遗忘的思路和策略。\n小样本的类别原型不稳定 容易和旧类别混淆 在进行总结的同时，我们的调研方向也会有所侧重，比如基于拓扑的神经气体网络方法，我们可能暂时不那么关心（精力有限）\n拓扑结构方法 《Few-Shot Class-Incremental Learning》[10] SPPR 《Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning》这篇文章的主要贡献有以下的两点：\n提出了 RESS（随机 episode 选择策略）通过强制特征自适应于各种随机模拟的增量过程来增强特征表示的可扩展性。 引入了一种自提升的原型细化机制(SPPR)，利用新类样本和旧类 prototype 表示之间的关系矩阵来更新现有的 prototypical RESS 实际上应该是类比 Meta Learning 提出的一种训练策略 SPPR 是本文的核心，为了保持旧类之间的依赖和新类置假你都区分度，要对新类的原型进行提炼 理论上讲 SPPR 更新的应该是模型的参数，但是在代码中我暂时没有找到对应的实现的地方\nso we drop this method which is not match our structure\nEvolved classifier 由于数据量少的这个特点，我们解耦 BB 和 CLF，每次增量任务只更新分类器。\n该文章[12]在多个数据集上实现了 SOTA，提出了 CEC（Continually Evolved Classifier），将图模型用在分类器上，它的分类器是一个无参数的 class mean classifier（听起来像 NCM）；\n实际上就是在一个较优的特征空间的基础上调整我们的决策边界的一个策略，该方法引入了图注意力模型（GAT），该方法有一个特性是：\n增加节点而不改变其他的节点， 利用拓扑关系，链接关系的不变性，利于保留旧知识 $$ w_{new} = w_{old} + (\\sum^{w_n}_k=1a_{jk}U_{w_k})\r$$\r使用 GAT 获得线性变换矩阵和注意力系数来更新模型的权重。\n此外提供了一种旋转增强的新型策略，效果特别好==pseudo incremental learning==，可能和 GAT 的一些特性有关，结合 GAT 效果提升巨大，要警惕这种方法是通用的还是特异性的。最好是看看有没有原理分析。\nCEBN 采用三阶段的方式来实现小样本的增量学习，根据上述的任务划分图来确定不同的实验阶段：\n用大量数据训练基准的分类模型，使用的就是 base class 学习 novel class 防止灾难性遗忘，只使用新类数据（修正 CE 考虑小样本问题）（使用参数来正则防止 BB 灾难遗忘） 混合数据进行训练，这个时候使用一个 balance 的数据集，比如说做多次增量的话，在最后一次使用 balance replay 即可。 第二阶段的损失是这里的关键，基于 CEBN 修改 CE，为啥我看不出区别，我感觉实际上就是 CE，只是虽然只用新数据训练，但是分类器是完整的罢了，其实就是 CE：\n$$ CE_{BN}(x) = \\sum_{C_N}y_iln(\\frac{exp(o_i)}{\\sum_{C_N} exp(o_j) + \\sum_{C_B}(o_k)})\r$$\r正则项则通过对前后的 Backbone 进行约束得到：\n$$ L_2^{WC} = \\sum||\\theta_1 - \\theta_2||^2\r$$\r最终整合起来的损失如下：\n$$ Loss = L_2^{WC} + \\lambda CE_{BN}\r$$\rReferences 📚Awesom Incremental Learning Collections | 🌤️Paper w Code Incremental Learning Learning without Forgetting | ZHIHU | ECCV2016 iCaRL Incremental Classifier and Representation Learning | CnBlog ， ZhiHu | CVPR2017 Ene-to-End Incremental Learning | ECCV2018 ⭐ PODNet Pooled Outputs Distillation for Small-Tasks Incremental Learning | ECCV2020 | CSDN Large Sacale Incremental Learning | CVPR2019 | CSDN Learning a Unified Classifier Incrementally via Rebalancing | CVPR2019 | Maintaining discrimination and fairness in class incremental learning | CVPR2020 Rainbow Memory: Continual Learning with a Memory of Diverse Samples | CVPR2021 | CSDN Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning | CVPR2021 | CSDN Few-Shot Class-Incremental Learning | CVPR2020 | CSDN Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning | CVPR2021 | CSDN Few Shot Incremental Learning with Continually Evolved Classifiers | CVPR2021 | Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting | ICCV2021 | CSDN Prototype Augmentation and Self-Supervision for Incremental Learning | CVPR2021 | ZHIHU Contrastive Continual Learning | ICCV2022 | CSDN 一些总结笔记\nClassic Incremental Papers Background and Dilemma Online Continual Learning An Empirical Survey | 2021 | Notion 这篇综述给人的感觉比较一般把，或者可能是总结文档里没有写出比较关键的一些看法和证据。感觉不是特别推荐阅读。 Incremental Learning in 20-21 | 下面的图也来自这篇文章 to be placed in the right place 将一些新的研究先放在这里，到时候看看要组织到笔记的那一部分。\nclass-Incremental learning via Dual Augmentation 该文章认为，类增量学习中灾难性遗忘可以被总结为两个方面带来的：特征表示上的偏差和分类器上的偏差。\n增量过程中如果不对特征提取器进行适应，则对新特征的提取能力不够；如果进行适应则会产生灾难性的遗忘 分类器如果不进行更新，会和新的特征表示不适应，而由于没有旧类的数据，就没有更新旧类的方向 解决的思路是：\n训练的阶段做mixup来做混合类的学习，通过这种预先训练，来帮助模型得到一个较为稳定的表征。 分类上将历史数据的均值和方差记录下来，对模型更新的时候，通过分布信息生成语义特征维持决策边界，防止对旧类分成新类。 第二部分具体细节的实现上还不是很清晰，后续可以看代码，但是目前来看不是我们需要的。\nLooking back on learned experiences for class/task incremental learning 主要贡献：无数据的增量学习，支持经验重放，不需要平行网络输出蒸馏监督。\nkd使用的是最小欧拉距离：L2范数的平方作为损失。\nOvercoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima CSDN 在基础模型训练阶段，企图找到一个损失的下降平坦点而不是简单的一个极小值，平坦极小值的模型的鲁棒性能会比普通的模型优异一些，具体对于平坦点的定义可以参见下面的这张图：\n这种平坦点的研究，实际上和NotZeroLoss的设定具有相当的相似性，帮助模型学习到一个更加稳定的解，而该解在后续进行增量学习的过程中，会减少对应的灾难性遗忘的现象。\nDistilling causal effect of data in class-incremental learning 也是通过因果分析来筹建分类结果，通过TDE的方式消除类别偏差，这一部分实际上和我们的Causal模块和统计均值模块应该是起到了相同的作用，这里暂时不深入进行解读。\n==the two below== is important for our research:\nDo not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting Papers using attention and the bayes formula to calculate the Uncertainty or something else.\nContinual Learning in the Teacher-Student Setup: Impact of Task Similarity Papers do a lot for the loss, which we should pay attention for it.\n","wordCount":"984","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover9.jpeg","datePublished":"2022-01-04T01:38:04Z","dateModified":"2022-01-04T01:38:04Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/il-collection/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">IL Collection</h1><div class=post-meta><span title='2022-01-04 01:38:04 +0000 UTC'>January 4, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;984 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/incremental-learning> Incremental Learning</a>&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/survey> Survey</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/IL-Collection.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover9.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#introduction- aria-label="Introduction 👿">Introduction 👿</a></li><li><a href=#%e5%9f%ba%e4%ba%8e%e8%92%b8%e9%a6%8f%e6%9e%b6%e6%9e%84%e7%9a%84%e6%96%b9%e6%b3%95 aria-label=基于蒸馏架构的方法>基于蒸馏架构的方法</a><ul class=header-level-2><li><a href=#motivation aria-label=Motivation>Motivation</a></li><li><a href=#%e5%bc%95%e5%85%a5%e6%97%a7%e6%a0%b7%e4%be%8b aria-label=引入旧样例>引入旧样例</a></li><li><a href=#%e4%bc%98%e5%8c%96%e5%88%86%e7%b1%bb%e5%99%a8 aria-label=优化分类器>优化分类器</a></li><li><a href=#%e4%bc%98%e5%8c%96%e7%89%b9%e5%be%81%e6%8f%90%e5%8f%96%e5%99%a8 aria-label=优化特征提取器>优化特征提取器</a></li><li><a href=#%e4%bc%98%e5%8c%96%e6%8d%9f%e5%a4%b1%e8%ae%be%e8%ae%a1 aria-label=优化损失设计>优化损失设计</a></li></ul></li><li><a href=#%e5%9f%ba%e4%ba%8e%e6%a8%a1%e5%9e%8b%e7%bb%93%e6%9e%84%e7%9a%84%e6%96%b9%e6%b3%95 aria-label=基于模型结构的方法>基于模型结构的方法</a><ul class=header-level-2><li><a href=#%e7%89%b9%e5%be%81%e7%bd%91%e7%bb%9c%e5%a0%86%e5%8f%a0 aria-label=特征网络堆叠>特征网络堆叠</a></li></ul></li><li><a href=#%e5%85%b6%e4%bb%96%e6%96%b9%e6%b3%95 aria-label=其他方法>其他方法</a></li><li><a href=#%e5%85%b6%e4%bb%96%e9%97%ae%e9%a2%98 aria-label=其他问题>其他问题</a><ul class=header-level-2><li><a href=#%e6%96%b0%e7%b1%bb%e4%bc%98%e4%ba%8e%e6%97%a7%e7%b1%bb aria-label=新类优于旧类>新类优于旧类</a></li><li><a href=#few-shot-incremental aria-label="Few-Shot Incremental">Few-Shot Incremental</a><ul class=header-level-3><li><a href=#%e6%8b%93%e6%89%91%e7%bb%93%e6%9e%84%e6%96%b9%e6%b3%95 aria-label=拓扑结构方法>拓扑结构方法</a></li><li><a href=#sppr aria-label=SPPR>SPPR</a></li><li><a href=#evolved-classifier aria-label="Evolved classifier">Evolved classifier</a></li><li><a href=#cebn aria-label=CEBN>CEBN</a></li></ul></li></ul></li><li><a href=#references aria-label=References>References</a></li><li><a href=#to-be-placed-in-the-right-place aria-label="to be placed in the right place">to be placed in the right place</a><ul class=header-level-2><li><a href=#class-incremental-learning-via-dual-augmentation aria-label="class-Incremental learning via Dual Augmentation">class-Incremental learning via Dual Augmentation</a></li><li><a href=#looking-back-on-learned-experiences-for-classtask-incremental-learning aria-label="Looking back on learned experiences for class/task incremental learning">Looking back on learned experiences for class/task incremental learning</a></li><li><a href=#overcoming-catastrophic-forgetting-in-incremental-few-shot-learning-by-finding-flat-minima aria-label="Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima">Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima</a></li><li><a href=#distilling-causal-effect-of-data-in-class-incremental-learning aria-label="Distilling causal effect of data in class-incremental learning">Distilling causal effect of data in class-incremental learning</a></li><li><a href=#do-not-forget-to-attend-to-uncertainty-while-mitigating-catastrophic-forgetting aria-label="Do not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting">Do not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting</a></li><li><a href=#continual-learning-in-the-teacher-student-setup-impact-of-task-similarity aria-label="Continual Learning in the Teacher-Student Setup: Impact of Task Similarity">Continual Learning in the Teacher-Student Setup: Impact of Task Similarity</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>@AikenHong 2022</p><p>[[Draft/IL 总结]]: Thx 2 wyz to provide some clus for learnning Incremental Learning.</p><p>In this Doc, we may add some related knowledge distill works which is used to design our Incremental Structure.
在这个文档中，我们可能还会添加一些知识蒸馏的相关工作的文献，这些实际上对于我的增量学习架构有一个比较大的启发</p><ul><li><a href=https://blog.csdn.net/weixin_36474809/article/details/116176371 target=_blank rel=noopener>DER</a></li><li>SPPR 没有 get 到方法到底是怎么做的</li></ul><h2 id=introduction->Introduction 👿<a hidden class=anchor aria-hidden=true href=#introduction->#</a></h2><p>在很多视觉应用中，需要在保留旧知识的基础上学习新知识，==举个例子==，理想的情况是，我们可以保留之前学习的参数，而不发生==灾难性遗忘==，或者我们基于之前的数据进行协同训练，灾难性遗忘是 IL 中最核心的问题。</p><p>Incremental 的基本过程可以表示如下<sub>[4]</sub>：<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/20220106101003.png><img alt=dsa loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/20220106101003.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/20220106101003.png style="display:block;margin:0 auto" alt=dsa></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>我们将模型可以划分为以下的两个部分<sub>[1]</sub>：backbone 和 classifier<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220105213925.png><img alt=split loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220105213925.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220105213925.png style="display:block;margin:0 auto" alt=split></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>从 LWF 中我们可以知道经典的 Paradigm，主要有下面的三种来对 $\theta _S$ 和 $\theta_o$ 来进行更新：</p><ul><li>仅重新训练分类器：仅更新 $\theta_o$</li><li>微调特征提取器，重新训练分类器</li><li>联合训练</li></ul><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106111235.png><img loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106111235.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106111235.png style="display:block;margin:0 auto" alt></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h2 id=基于蒸馏架构的方法>基于蒸馏架构的方法<a hidden class=anchor aria-hidden=true href=#基于蒸馏架构的方法>#</a></h2><p>这一系列的方法实际上是 IL 最经典的发展路线，实际上从初始的蒸馏架构开始，最后逐渐的发展到结合回放的策略中，我认为结合<strong>rehearsal</strong>才是该类方法最后的归宿，所以我将基于蒸馏正则化的 Pod 和 LWF 也放到了这一部分。</p><h3 id=motivation>Motivation<a hidden class=anchor aria-hidden=true href=#motivation>#</a></h3><p>《Learning without Forgetting》LWF 主要带来的就是将 KD 损失引入 Joint Training 的范式，也就是我们印象中最原始的增量学习的途径，利用 <code>expand_dim</code> 训练最后输出的新的节点，但是这个范式是不需要旧数据。</p><div>$$
Loss = L_{CE} + L_{KD}
$$</div><p>这里的蒸馏使用的是最终的 pred 输出，后续对于蒸馏损失的有 KDC 的变体，根据新旧样本的比例来赋予权重，考虑模型优化的权重。</p><div>$$
Loss = \lambda L_{CE} + (1-\lambda) L_{KD}
$$</div><p>其中 $\lambda^2 = \frac{|C_{old}|}{|C_{old}|+ |C_{new}|}$</p><p>这就是最经典的 Incremental Learning 的范式，我们首先继承一部分分类器的参数，然后通过这个损失对整个框架进行协同训练。</p><h3 id=引入旧样例>引入旧样例<a hidden class=anchor aria-hidden=true href=#引入旧样例>#</a></h3><p>《ICaRL: Incremental Classifier and Representation Learning》在 LWF 基础上引入部分旧数据来避免灾难遗忘的问题</p><ul><li>基于特征提取器对新旧数据的训练集提取==平均特征向量==（Kmeans + KNN）</li><li>基于最近邻均值分类算法 NME 计算出新旧数据的预测值 计算 LWF 的经典损失，优化模型</li></ul><blockquote><p>本文的亮点主要在于引入了旧的数据进行复习（有一个比较好的数据选取策略），以及最后使用的不是全连接层而是最近邻分类器来作为预测。（Will This Get Better？）</p></blockquote><p>后续在 ==《End-to-End Incremental Learning》== 中，将最近邻分类器替换成分类层，其动机就是对 ICaRL 进行优化。</p><p><strong>memory 保存旧样本 -> CE+KD -> reBalance + Fine-tune</strong></p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106112111.png><img loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106112111.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106112111.png style="display:block;margin:0 auto" alt></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>由于数据量上的有偏，导致分类器会严重有偏与 New-Classes，但是我认为这个可能是对于场景设定的不同，加入新的需求和发现少量的数据两者是一个比较大的不同。</p><p>这里的 <strong>样本选择策略</strong> 可能在后续会比较有用。</p><ul><li>在 ICaRL 中选择的是最确信的样本来 rehearsal，也就是使用特征中心的 KNN 方法来选取样本。</li><li>而在==《Rainbow Memory》==<sub>[8]</sub>中则是选择最难的样本，其 motivation 是选择最接近判别界样本</li></ul><p>RM 的最终实现的思路是通过 Data Augmentation 对样本进行变化，将不同 Augmentaion 后的预测的偏差（不确定程度）来衡量一个样本是 Hard or Simple Task，基于这种方式来选择 Hard-Task（Uncertainty）</p><p>具体而言，标签为 c 的样本，经过 perturbed 后，被网络预测为 c 类的次数越多，则不确定性越弱。</p><h3 id=优化分类器>优化分类器<a hidden class=anchor aria-hidden=true href=#优化分类器>#</a></h3><p>由于新类的大量数据带来的偏差，==《Large Sacale Incremental Learning》== 试图解决这个问题</p><ul><li>将训练集划分一个 rebalance 的 dataset 作为验证集，并用该数据集训练一个 Bias Correction Layer 得到修正的参数，</li></ul><p>该层的输出如下，实际上就是一个线性回归层，只有两个参数</p><div>$$
q_{k}=\left\{\begin{array}{lr}
o_{k} & 1 \leq k \leq n \\
\alpha o_{k}+\beta & n+1 \leq k \leq n+m
\end{array}\right.
$$</div><p>训练该层的时候固定 CLF 和 BB，使用 CE 损失即可，但是模型在大数据集上的表现更佳，在 cifar100 的小数据集上表现一般。</p><p>另外还有借助 Long-Tailed 中的策略，从 $||W||$ 的角度矫正偏差的文章 ==《Learning a Unified Classifier Incrementally via Rebalancing》==</p><p>动机是由于：1）imbalance：new classes 的权重的大小远远高于 old classes 的权重。2）特征与 old classes 的权重关系没有保留。3）一些 new classes 的权重与 old classes 的权重相近（容易混淆的类别），导致歧义性。</p><p>引入了 Cosine Normalization 分类器，实际上就是进分类器之前进行正则化，加入 Margin 损失（可以参考人脸比对的 Cosine Face 之类的）最终损失为：</p><div>$$
L=\frac{1}{|\mathcal{N}|} \sum_{x \in \mathcal{N}}\left(L_{\mathrm{ce}}(x)+\lambda L_{\mathrm{dis}}^{\mathrm{G}}(x)\right)+\frac{1}{\left|\mathcal{N}_{\mathrm{o}}\right|} \sum_{x \in \mathcal{N}_{\mathrm{o}}} L_{\mathrm{mr}}(x)
$$</div><p>更简单的有==《Maintaining discrimination and fairness in class incremental learning》==，通过对于分类器中的新旧模型的**weight **做 Rescale 使其再 W 上达成一致来维持一个较好的效果</p><div>$$
\begin{gathered}
W = (W_{old},W_{new}) ; Norm_{old} = (||W_1||, ···, ||W_{c^b_{old}}) \\
\gamma = \frac{Mean(Norm_{old})}{Mean(Norm_{new}} \\
\hat{W}_{new} = \gamma · W_{new} \\
\end{gathered}
$$</div><h3 id=优化特征提取器>优化特征提取器<a hidden class=anchor aria-hidden=true href=#优化特征提取器>#</a></h3><p>其实Incremental现阶段的任务也倾向于使用两阶段的架构，基于这样的架构，我们首先提名最重要的就是基于SCL的这篇文章<sub>[9]</sub>,这篇文章主要的思路是：</p><center>SCL+projector（Train）+NCM（Test）</center><p>训练的Batch就是普通的Memory+New，但是值得一提的是，这篇文章对Memory的数据选取做了消融实验，得到了这样的结果：</p><p><strong>随机选取</strong>Memory的效果>GSS（NIPS2019）和ASER（AAAI2021），是一个令人惊讶的结果.</p><p>而类似的，也有使用图像旋转的SSL（缓解ce带来的特征bias）+CE结合Prototype（rehearsal避免遗忘）+ KDLoss的研究<sub>[14]</sub>，证明了结合类似的自监督任务能够有效缓解特征之间的重叠。</p><p>使用的SSL任务是常见的Rotate Loss, KD是和上一轮的模型做约束。</p><div>$$
L_{t,total} = L_{t,ce} + \lambda L_{t,protoAug} + \gamma L_{t,kd}
$$</div><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107221329.png><img alt="Feature Compare" loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107221329.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107221329.png style="display:block;margin:0 auto" alt="Feature Compare"></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>同样的C<sup>2</sup>OL<sub>[15]</sub> 这篇方法，就用最基本的对比学习的损失来研究该方法对于IL的实用性，也发现了基于CL学出来的特征确实更适合用在蒸馏的任务之上，验证了我们的猜想。</p><h3 id=优化损失设计>优化损失设计<a hidden class=anchor aria-hidden=true href=#优化损失设计>#</a></h3><p>《PODNet Pooled Outputs Distillation for Small-Tasks Incremental Learning》基于样本回放的方法，改进 KD，定义了 Pooled Output Distillation。</p><ul><li>spatial-based distillation-loss，基于空间的蒸馏损失，改进蒸馏方法</li><li>representation comprising multiplt proxy vectors，代理向量改进了分类器</li></ul><p>==part1 Update KD Loss==</p><center>Pooling 简略图</center><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106095511.png><img alt=pooling loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106095511.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106095511.png style="display:block;margin:0 auto" alt=pooling></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>假设： $\hat{y} = g(f(x))$ 为分类过程，其中 $f(x)$ 代表特征提取过程。
POD 算法则为，不仅将蒸馏应用到特征提取的最终输出，还将其用于 $f(x)$ 的中间过程的输出</p><div>$$
f^t(x) = f^t_L .. ·f^t_l .. ·f^t_1(x)
$$</div><p>中的每一层（如下式）都作为中间的结果，用来做 KD，上标 t 表示 task，下标则表示模型第几层。</p><div>$$
h^t_{l,c,w,h} = f^t_l(·)
$$</div><p>对该输出的各层执行各种级别的 POD 蒸馏，作为我们的监督来实现对灾难性遗忘的避免：</p><div>$$
\mathcal{L}_{\text {POD-pixel }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)=\sum_{c=1}^{C} \sum_{w=1}^{W} \sum_{h=1}^{H}\left\|\mathbf{h}_{\ell, c, w, h}^{t-1}-\mathbf{h}_{\ell, c, w, h}^{t}\right\|^{2}
$$</div><p>显然 pixel 级别对于模型的约束是最强的</p><div>$$
\begin{gathered}
\mathcal{L}_{\text {POD-channel }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)=\sum_{w=1}^{W} \sum_{h=1}^{H}\left\|\sum_{c=1}^{C} \mathbf{h}_{\ell, c, w, h}^{t-1}-\sum_{c=1}^{C} \mathbf{h}_{\ell, c, w, h}^{t}\right\|^{2} \\
\mathcal{L}_{\text {POD-gap }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)=\sum_{c=1}^{C}\left\|\sum_{w=1}^{W} \sum_{h=1}^{H} \mathbf{h}_{\ell, c, w, h}^{t-1}-\sum_{w=1}^{W} \sum_{h=1}^{H} \mathbf{h}_{\ell, c, w, h}^{t}\right\|^{2} \\
\mathcal{L}_{\text {POD-width }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)=\sum_{c=1}^{C} \sum_{h=1}^{H}\left\|\sum_{w=1}^{W} \mathbf{h}_{\ell, c, w, h}^{t-1}-\sum_{w=1}^{W} \mathbf{h}_{\ell, c, w, h}^{t}\right\|^{2}
\end{gathered}
$$</div><p>pixel 级别的蒸馏对于模型限制比较严格，其他级别的对于模型限制相对较松，需要一个权衡，作者最终选用的是 Spatial 级别的蒸馏，相当于 width 和 height 层面蒸馏 loss 之和</p><div>$$
\mathcal{L}_{\text {POD-spatial }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)=\mathcal{L}_{\text {POD-width }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)+\mathcal{L}_{\text {POD-height }}\left(\mathbf{h}_{\ell}^{t-1}, \mathbf{h}_{\ell}^{t}\right)
$$</div><p>特征提取模型最终的特征则使用 pixel 级别的蒸馏：</p><div>$$
\mathcal{L}_{POD-flat}(h^{t-1},h^t) = ||h^{t-1} - h^t||^2
$$</div><p>将这些蒸馏损失整合起来取代原本的 KD-Loss，再加上我们的 CE 即可：</p><div>$$
\begin{gathered}
\mathcal{L}_{POD-final} = \frac{\lambda_c}{L-1}\sum_{l=1}^{L-1} \mathcal{L}_{POD-spatial}(f_l^{t-1}(x),f_l^t(x)) + \\
\lambda_f \mathcal{L}_{POD-flat}(f_l^{t-1}(x),f_l^t(x))
\end{gathered}
$$</div><p>==Part2 Local Similarity Classifier==</p><p>第一个改进点就是将 Loss 修正为 Cosine 的形式<sub>UCiR</sub>，实际上就是使用的归一化后的 FC 层，但是如果只使用一个 Cos 相似度，好像多样化的需求无法满足，需要类似一个多头的机制</p><blockquote><p>和 LT 的地方一样，IL 近年来的主要架构也是两部分进行分离的，所以我们可以考虑从我们的角度来实现类似 POD-Loss 的架构维持，也就是一定程度上为我们的 SSL-SCL 架构的可行性提供了一定的信心。</p></blockquote><p>该方法迄今为止还是很多增量任务的榜单前几，该方法的蒸馏性能也被验证为有效，但是实际上将该方法用于模型中需要增加大量的特征输出模块，整体架构上修改起来可能会较为复杂。</p><h2 id=基于模型结构的方法>基于模型结构的方法<a hidden class=anchor aria-hidden=true href=#基于模型结构的方法>#</a></h2><p>这一部分不是我研究的重点，可以看到有一部分设计的拓张模型或者，堆叠模型，用额外的结构来承载对应的新类的研究，可能考虑到一部分参数公用然后实行协同判断的策略把。</p><p>或者是其他的图模型，拓扑结构（神经气体网络）等等的方法，拓扑结构等方法可能户籍是未来的一个方向。</p><h3 id=特征网络堆叠>特征网络堆叠<a hidden class=anchor aria-hidden=true href=#特征网络堆叠>#</a></h3><ul><li>DER 特征网络堆叠的方法</li></ul><h2 id=其他方法>其他方法<a hidden class=anchor aria-hidden=true href=#其他方法>#</a></h2><ul><li><table><thead><tr><th><a href=https://www.pnas.org/content/pnas/114/13/3521.full.pdf target=_blank rel=noopener>EWC</a>
：这类方法一般是对网络中每个参数的重要性进行评估，根据每个参数的重要性，调整梯度信息更新参数。</th></tr></thead><tbody></tbody></table></li></ul><h2 id=其他问题>其他问题<a hidden class=anchor aria-hidden=true href=#其他问题>#</a></h2><p>这里会收集一部分 IL 中存在的一些现象或者问题</p><h3 id=新类优于旧类>新类优于旧类<a hidden class=anchor aria-hidden=true href=#新类优于旧类>#</a></h3><p>模型倾向于时间上接近的模型有更高的敏感度，这可能是训练的过程决定的，也可能是由于再新类的训练上新类的权重要明显高于旧类，导致的某种数据不均衡的现象。</p><p>此外在传统的设定中，新类的数据量会大大的大于旧类</p><h3 id=few-shot-incremental>Few-Shot Incremental<a hidden class=anchor aria-hidden=true href=#few-shot-incremental>#</a></h3><p>Few-Shot 的增量情景更贴切于我的场景假设，在这种假设的背景之下，增量学习也会面临一些新的困难，这个篇章中我们可能会简要的总结一些方法对抗小样本和灾难性遗忘的思路和策略。</p><ul><li>小样本的类别原型不稳定</li><li>容易和旧类别混淆</li></ul><p>在进行总结的同时，我们的调研方向也会有所侧重，比如基于拓扑的神经气体网络方法，我们可能暂时不那么关心（精力有限）</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107182311.png><img loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107182311.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107182311.png style="display:block;margin:0 auto" alt></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h4 id=拓扑结构方法>拓扑结构方法<a hidden class=anchor aria-hidden=true href=#拓扑结构方法>#</a></h4><ul><li>《Few-Shot Class-Incremental Learning》<sub>[10]</sub></li></ul><h4 id=sppr>SPPR<a hidden class=anchor aria-hidden=true href=#sppr>#</a></h4><p>《Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning》这篇文章的主要贡献有以下的两点：</p><ul><li>提出了 RESS（随机 episode 选择策略）通过强制特征自适应于各种随机模拟的增量过程来增强特征表示的可扩展性。</li><li>引入了一种自提升的原型细化机制(SPPR)，利用新类样本和旧类 prototype 表示之间的关系矩阵来更新现有的 prototypical</li></ul><blockquote><p>RESS 实际上应该是类比 Meta Learning 提出的一种训练策略
SPPR 是本文的核心，为了保持旧类之间的依赖和新类置假你都区分度，要对新类的原型进行提炼
理论上讲 SPPR 更新的应该是模型的参数，但是在代码中我暂时没有找到对应的实现的地方</p></blockquote><p>so we drop this method which is not match our structure</p><h4 id=evolved-classifier>Evolved classifier<a hidden class=anchor aria-hidden=true href=#evolved-classifier>#</a></h4><p>由于数据量少的这个特点，我们解耦 BB 和 CLF，每次增量任务只更新分类器。</p><p>该文章[12]在多个数据集上实现了 SOTA，提出了 CEC（Continually Evolved Classifier），将图模型用在分类器上，它的分类器是一个无参数的 class mean classifier（听起来像 NCM）；</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107175617.png><img loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107175617.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220107175617.png style="display:block;margin:0 auto" alt></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>实际上就是在一个较优的特征空间的基础上调整我们的决策边界的一个策略，该方法引入了图注意力模型（GAT），该方法有一个特性是：</p><ul><li>增加节点而不改变其他的节点，</li><li>利用拓扑关系，链接关系的不变性，利于保留旧知识</li></ul><div>$$
w_{new} = w_{old} + (\sum^{w_n}_k=1a_{jk}U_{w_k})
$$</div><p>使用 GAT 获得线性变换矩阵和注意力系数来更新模型的权重。</p><p>此外提供了一种旋转增强的新型策略，效果特别好==pseudo incremental learning==，可能和 GAT 的一些特性有关，结合 GAT 效果提升巨大，要警惕这种方法是通用的还是特异性的。最好是看看有没有原理分析。</p><h4 id=cebn>CEBN<a hidden class=anchor aria-hidden=true href=#cebn>#</a></h4><p>采用三阶段的方式来实现小样本的增量学习，根据上述的任务划分图来确定不同的实验阶段：</p><ol><li>用大量数据训练基准的分类模型，使用的就是 base class</li><li>学习 novel class 防止灾难性遗忘，只使用新类数据（修正 CE 考虑小样本问题）（使用参数来正则防止 BB 灾难遗忘）</li><li>混合数据进行训练，这个时候使用一个 balance 的数据集，比如说做多次增量的话，在最后一次使用 balance replay 即可。</li></ol><p>第二阶段的损失是这里的关键，基于 CEBN 修改 CE，为啥我看不出区别，我感觉实际上就是 CE，只是虽然只用新数据训练，但是分类器是完整的罢了，其实就是 CE：</p><div>$$
CE_{BN}(x) = \sum_{C_N}y_iln(\frac{exp(o_i)}{\sum_{C_N} exp(o_j) + \sum_{C_B}(o_k)})
$$</div><p>正则项则通过对前后的 Backbone 进行约束得到：</p><div>$$
L_2^{WC} = \sum||\theta_1 - \theta_2||^2
$$</div><p>最终整合起来的损失如下：</p><div>$$
Loss = L_2^{WC} + \lambda CE_{BN}
$$</div><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p><a href=https://github.com/xialeiliu/Awesome-Incremental-Learning target=_blank rel=noopener>📚Awesom Incremental Learning Collections</a>
| <a href=https://paperswithcode.com/task/incremental-learning target=_blank rel=noopener>🌤️Paper w Code Incremental Learning</a></p><ol><li><a href=https://arxiv.org/abs/1606.09282 target=_blank rel=noopener>Learning without Forgetting</a>
| <a href=https://zhuanlan.zhihu.com/p/51587674 target=_blank rel=noopener>ZHIHU</a>
| ECCV2016</li><li><a href=https://arxiv.org/abs/1611.07725 target=_blank rel=noopener>iCaRL Incremental Classifier and Representation Learning</a>
| <a href=https://www.cnblogs.com/marsggbo/p/10321834.html target=_blank rel=noopener>CnBlog</a>
， <a href=https://zhuanlan.zhihu.com/p/51639634 target=_blank rel=noopener>ZhiHu</a>
| CVPR2017</li><li><a href>Ene-to-End Incremental Learning</a>
| ECCV2018</li><li>⭐ <a href=https://arxiv.org/abs/2004.13513 target=_blank rel=noopener>PODNet Pooled Outputs Distillation for Small-Tasks Incremental Learning</a>
| <a href=https://github.com/arthurdouillard/incremental_learning.pytorch target=_blank rel=noopener>ECCV2020</a>
| <a href=https://blog.csdn.net/weixin_36474809/article/details/116140481 target=_blank rel=noopener>CSDN</a></li><li><a href>Large Sacale Incremental Learning</a>
| CVPR2019 | <a href=https://blog.csdn.net/dhaiuda/article/details/102852694 target=_blank rel=noopener>CSDN</a></li><li><a href=https://blog.csdn.net/dhaiuda/article/details/102850853 target=_blank rel=noopener>Learning a Unified Classifier Incrementally via Rebalancing</a>
| CVPR2019 |</li><li><a href=https://arxiv.org/pdf/1911.07053.pdf target=_blank rel=noopener>Maintaining discrimination and fairness in class incremental learning</a>
| CVPR2020</li><li><a href=https://arxiv.org/abs/2103.17230 target=_blank rel=noopener>Rainbow Memory: Continual Learning with a Memory of Diverse Samples</a>
| <a href=https://github.com/clovaai/rainbow-memory target=_blank rel=noopener>CVPR2021</a>
| <a href=https://blog.csdn.net/weixin_36474809/article/details/116140087 target=_blank rel=noopener>CSDN</a></li><li><a href=https://arxiv.org/abs/2103.13885 target=_blank rel=noopener>Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning</a>
| CVPR2021 | <a href=https://blog.csdn.net/weixin_36474809/article/details/116310575 target=_blank rel=noopener>CSDN</a></li><li><a href>Few-Shot Class-Incremental Learning</a>
| CVPR2020 | <a href=https://blog.csdn.net/weixin_36474809/article/details/116176530 target=_blank rel=noopener>CSDN</a></li><li><a href=https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf target=_blank rel=noopener>Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning</a>
| <a href=https://github.com/zhukaii/SPPR target=_blank rel=noopener>CVPR2021</a>
| <a href=https://blog.csdn.net/qq_40825479/article/details/122199901 target=_blank rel=noopener>CSDN</a></li><li><a href>Few Shot Incremental Learning with Continually Evolved Classifiers</a>
| <a href=https://blog.csdn.net/weixin_36474809/article/details/116612960 target=_blank rel=noopener>CVPR2021</a>
|</li><li><a href>Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting</a>
| ICCV2021 | <a href=https://blog.csdn.net/weixin_58666589/article/details/120682594 target=_blank rel=noopener>CSDN</a></li><li><a href="https://link.zhihu.com/?target=https%3A//openaccess.thecvf.com/content/CVPR2021/html/Zhu_Prototype_Augmentation_and_Self-Supervision_for_Incremental_Learning_CVPR_2021_paper.html" target=_blank rel=noopener>Prototype Augmentation and Self-Supervision for Incremental Learning</a>
| <a href="https://link.zhihu.com/?target=https%3A//github.com/Impression2805/CVPR21_PASS" target=_blank rel=noopener>CVPR2021</a>
| <a href="https://zhuanlan.zhihu.com/p/416717749?utm_medium=social&amp;utm_oi=74269941825536" target=_blank rel=noopener>ZHIHU</a></li><li><a href>Contrastive Continual Learning</a>
| ICCV2022 | CSDN</li></ol><p><strong>一些总结笔记</strong></p><ul><li><a href=https://zhuanlan.zhihu.com/p/337287727 target=_blank rel=noopener>Classic Incremental Papers</a></li><li><a href=https://blog.csdn.net/abcdefg90876/article/details/114109237 target=_blank rel=noopener>Background and Dilemma</a></li><li><a href=https://www.sciencedirect.com/science/article/pii/S0925231221014995 target=_blank rel=noopener>Online Continual Learning An Empirical Survey</a>
| 2021 | <a href=https://ripe-heliotrope-6f4.notion.site/Online-Continual-Learning-in-Image-Classification-An-Empirical-Survey-25bbcd8d3c2b492aa983a4320d1150de#a57ead60cdaf4ac5b42b8dce849266b2 target=_blank rel=noopener>Notion</a>
这篇综述给人的感觉比较一般把，或者可能是总结文档里没有写出比较关键的一些看法和证据。感觉不是特别推荐阅读。</li><li><a href=https://blog.csdn.net/weixin_36474809/article/details/116720597 target=_blank rel=noopener>Incremental Learning in 20-21</a>
| 下面的图也来自这篇文章</li></ul><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201641.png><img alt=Fig1 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201641.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201641.png style="display:block;margin:0 auto" alt=Fig1></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201645.png><img alt=Fig2 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201645.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201645.png style="display:block;margin:0 auto" alt=Fig2></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201649.png><img alt=Fig3 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201649.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220106201649.png style="display:block;margin:0 auto" alt=Fig3></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h2 id=to-be-placed-in-the-right-place>to be placed in the right place<a hidden class=anchor aria-hidden=true href=#to-be-placed-in-the-right-place>#</a></h2><p>将一些新的研究先放在这里，到时候看看要组织到笔记的那一部分。</p><h3 id=class-incremental-learning-via-dual-augmentation>class-Incremental learning via Dual Augmentation<a hidden class=anchor aria-hidden=true href=#class-incremental-learning-via-dual-augmentation>#</a></h3><p>该文章认为，类增量学习中灾难性遗忘可以被总结为两个方面带来的：特征表示上的偏差和分类器上的偏差。</p><ol><li>增量过程中如果不对特征提取器进行适应，则对新特征的提取能力不够；如果进行适应则会产生灾难性的遗忘</li><li>分类器如果不进行更新，会和新的特征表示不适应，而由于没有旧类的数据，就没有更新旧类的方向</li></ol><p>解决的思路是：</p><ul><li>训练的阶段做mixup来做混合类的学习，通过这种预先训练，来帮助模型得到一个较为稳定的表征。</li><li>分类上将历史数据的均值和方差记录下来，对模型更新的时候，通过分布信息生成语义特征维持决策边界，防止对旧类分成新类。</li></ul><p>第二部分具体细节的实现上还不是很清晰，后续可以看代码，但是目前来看不是我们需要的。</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220315151105.jpg><img alt=preview loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220315151105.jpg class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220315151105.jpg style="display:block;margin:0 auto" alt=preview></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h3 id=looking-back-on-learned-experiences-for-classtask-incremental-learning>Looking back on learned experiences for class/task incremental learning<a hidden class=anchor aria-hidden=true href=#looking-back-on-learned-experiences-for-classtask-incremental-learning>#</a></h3><p>主要贡献：无数据的增量学习，支持经验重放，不需要平行网络输出蒸馏监督。</p><p>kd使用的是最小欧拉距离：L2范数的平方作为损失。</p><h3 id=overcoming-catastrophic-forgetting-in-incremental-few-shot-learning-by-finding-flat-minima>Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima<a hidden class=anchor aria-hidden=true href=#overcoming-catastrophic-forgetting-in-incremental-few-shot-learning-by-finding-flat-minima>#</a></h3><p><a href=https://blog.csdn.net/qq_40825479/article/details/122352675 target=_blank rel=noopener>CSDN</a></p><p>在基础模型训练阶段，企图找到一个损失的下降平坦点而不是简单的一个极小值，平坦极小值的模型的鲁棒性能会比普通的模型优异一些，具体对于平坦点的定义可以参见下面的这张图：</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220315161428><img alt=img loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220315161428 class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20220315161428 style="display:block;margin:0 auto" alt=img></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>这种平坦点的研究，实际上和NotZeroLoss的设定具有相当的相似性，帮助模型学习到一个更加稳定的解，而该解在后续进行增量学习的过程中，会减少对应的灾难性遗忘的现象。</p><h3 id=distilling-causal-effect-of-data-in-class-incremental-learning>Distilling causal effect of data in class-incremental learning<a hidden class=anchor aria-hidden=true href=#distilling-causal-effect-of-data-in-class-incremental-learning>#</a></h3><p>也是通过因果分析来筹建分类结果，通过TDE的方式消除类别偏差，这一部分实际上和我们的Causal模块和统计均值模块应该是起到了相同的作用，这里暂时不深入进行解读。</p><p>==the two below== is important for our research:</p><h3 id=do-not-forget-to-attend-to-uncertainty-while-mitigating-catastrophic-forgetting>Do not Forget to Attend to Uncertainty while Mitigating Catastrophic Forgetting<a hidden class=anchor aria-hidden=true href=#do-not-forget-to-attend-to-uncertainty-while-mitigating-catastrophic-forgetting>#</a></h3><p><a href=https://arxiv.org/pdf/2102.01906.pdf target=_blank rel=noopener>Papers</a>
using attention and the bayes formula to calculate the Uncertainty or something else.</p><h3 id=continual-learning-in-the-teacher-student-setup-impact-of-task-similarity>Continual Learning in the Teacher-Student Setup: Impact of Task Similarity<a hidden class=anchor aria-hidden=true href=#continual-learning-in-the-teacher-student-setup-impact-of-task-similarity>#</a></h3><p><a href=https://www.ijcai.org/proceedings/2021/0137.pdf target=_blank rel=noopener>Papers</a>
do a lot for the loss, which we should pay attention for it.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/incremental-learning/>Incremental Learning</a></li><li><a href=https://hugotest-phi.vercel.app/tags/machine-learning/>Machine Learning</a></li><li><a href=https://hugotest-phi.vercel.app/tags/survey/>Survey</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/transfer-sync-files/><span class=title>« Prev</span><br><span>Linux 文件传输和同步</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/il-wyz/><span class=title>Next »</span><br><span>WYZ-IL-Collection</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>