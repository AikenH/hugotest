<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>PyTorch Handbook 00 （Archive） | aiken's blog</title>
<meta name=keywords content="Python,Pytorch"><meta name=description content="Basic Part基础设定部分
@AikenH 2020 + 2021
this part is about pytorch basic unit, help me to code deep learning better.
Tensor张量计算
两个tensor的数乘

计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12


# 简单的分析一下算法的逻辑
# 这是割裂出来batch的矩阵相乘形式
batch1 = torch.randn(10,3,4)
batch2 = torch.randn(10,4,5)
out = torch.bmm(batch1, batch2)
out.size()

'''output ans is
torch.size([10,3,5])'''

# 按位相乘
res = torch.mul(batch1,batch2)


view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。
张量命名


1
2
3
4


NCHW = [‘N’, ‘C’, ‘H’, ‘W’]
images = torch.randn(32, 3, 56, 56, names=NCHW)
images.sum('C')
images.select('C', index=0)


类型转换


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12


# tensor 与 nd.array进行互换
ndarray = tensor.cpu().numpy()
tensor = torch.from_numpy(ndarray).float()

# tensor与PIL.IMAGE进行互换
image = torchvision.transforms.functional.to_pil_image(tensor)
path = r'./figure.jpg'
tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))

# np.ndarray 与 PIL.Image的互换
image = PIL.Image.fromarray(nd.array.astype(np.uint8))
ndarray = np.asarray(PIL.Image.open(path))


维度堆叠
Stack，普通的维度堆叠的测试代码如下"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/pytorch/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/pytorch/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/pytorch/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="PyTorch Handbook 00 （Archive）"><meta property="og:description" content="Basic Part基础设定部分 @AikenH 2020 + 2021
this part is about pytorch basic unit, help me to code deep learning better.
Tensor张量计算 两个tensor的数乘 计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数
1 2 3 4 5 6 7 8 9 10 11 12 # 简单的分析一下算法的逻辑 # 这是割裂出来batch的矩阵相乘形式 batch1 = torch.randn(10,3,4) batch2 = torch.randn(10,4,5) out = torch.bmm(batch1, batch2) out.size() '''output ans is torch.size([10,3,5])''' # 按位相乘 res = torch.mul(batch1,batch2) view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。
张量命名 1 2 3 4 NCHW = [‘N’, ‘C’, ‘H’, ‘W’] images = torch.randn(32, 3, 56, 56, names=NCHW) images.sum('C') images.select('C', index=0) 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 # tensor 与 nd.array进行互换 ndarray = tensor.cpu().numpy() tensor = torch.from_numpy(ndarray).float() # tensor与PIL.IMAGE进行互换 image = torchvision.transforms.functional.to_pil_image(tensor) path = r'./figure.jpg' tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) # np.ndarray 与 PIL.Image的互换 image = PIL.Image.fromarray(nd.array.astype(np.uint8)) ndarray = np.asarray(PIL.Image.open(path)) 维度堆叠 Stack，普通的维度堆叠的测试代码如下"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-15T08:00:57+00:00"><meta property="article:modified_time" content="2021-12-15T08:00:57+00:00"><meta property="article:tag" content="Python"><meta property="article:tag" content="Pytorch"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover4.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover4.jpeg"><meta name=twitter:title content="PyTorch Handbook 00 （Archive）"><meta name=twitter:description content="Basic Part基础设定部分
@AikenH 2020 + 2021
this part is about pytorch basic unit, help me to code deep learning better.
Tensor张量计算
两个tensor的数乘

计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12


# 简单的分析一下算法的逻辑
# 这是割裂出来batch的矩阵相乘形式
batch1 = torch.randn(10,3,4)
batch2 = torch.randn(10,4,5)
out = torch.bmm(batch1, batch2)
out.size()

'''output ans is
torch.size([10,3,5])'''

# 按位相乘
res = torch.mul(batch1,batch2)


view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。
张量命名


1
2
3
4


NCHW = [‘N’, ‘C’, ‘H’, ‘W’]
images = torch.randn(32, 3, 56, 56, names=NCHW)
images.sum('C')
images.select('C', index=0)


类型转换


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12


# tensor 与 nd.array进行互换
ndarray = tensor.cpu().numpy()
tensor = torch.from_numpy(ndarray).float()

# tensor与PIL.IMAGE进行互换
image = torchvision.transforms.functional.to_pil_image(tensor)
path = r'./figure.jpg'
tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))

# np.ndarray 与 PIL.Image的互换
image = PIL.Image.fromarray(nd.array.astype(np.uint8))
ndarray = np.asarray(PIL.Image.open(path))


维度堆叠
Stack，普通的维度堆叠的测试代码如下"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"PyTorch Handbook 00 （Archive）","item":"https://hugotest-phi.vercel.app/posts/pytorch/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"PyTorch Handbook 00 （Archive）","name":"PyTorch Handbook 00 （Archive）","description":"Basic Part基础设定部分 @AikenH 2020 + 2021\nthis part is about pytorch basic unit, help me to code deep learning better.\nTensor张量计算 两个tensor的数乘 计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数\n1 2 3 4 5 6 7 8 9 10 11 12 # 简单的分析一下算法的逻辑 # 这是割裂出来batch的矩阵相乘形式 batch1 = torch.randn(10,3,4) batch2 = torch.randn(10,4,5) out = torch.bmm(batch1, batch2) out.size() \u0026#39;\u0026#39;\u0026#39;output ans is torch.size([10,3,5])\u0026#39;\u0026#39;\u0026#39; # 按位相乘 res = torch.mul(batch1,batch2) view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。\n张量命名 1 2 3 4 NCHW = [‘N’, ‘C’, ‘H’, ‘W’] images = torch.randn(32, 3, 56, 56, names=NCHW) images.sum(\u0026#39;C\u0026#39;) images.select(\u0026#39;C\u0026#39;, index=0) 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 # tensor 与 nd.array进行互换 ndarray = tensor.cpu().numpy() tensor = torch.from_numpy(ndarray).float() # tensor与PIL.IMAGE进行互换 image = torchvision.transforms.functional.to_pil_image(tensor) path = r\u0026#39;./figure.jpg\u0026#39; tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) # np.ndarray 与 PIL.Image的互换 image = PIL.Image.fromarray(nd.array.astype(np.uint8)) ndarray = np.asarray(PIL.Image.open(path)) 维度堆叠 Stack，普通的维度堆叠的测试代码如下\n","keywords":["Python","Pytorch"],"articleBody":"Basic Part基础设定部分 @AikenH 2020 + 2021\nthis part is about pytorch basic unit, help me to code deep learning better.\nTensor张量计算 两个tensor的数乘 计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数\n1 2 3 4 5 6 7 8 9 10 11 12 # 简单的分析一下算法的逻辑 # 这是割裂出来batch的矩阵相乘形式 batch1 = torch.randn(10,3,4) batch2 = torch.randn(10,4,5) out = torch.bmm(batch1, batch2) out.size() '''output ans is torch.size([10,3,5])''' # 按位相乘 res = torch.mul(batch1,batch2) view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。\n张量命名 1 2 3 4 NCHW = [‘N’, ‘C’, ‘H’, ‘W’] images = torch.randn(32, 3, 56, 56, names=NCHW) images.sum('C') images.select('C', index=0) 类型转换 1 2 3 4 5 6 7 8 9 10 11 12 # tensor 与 nd.array进行互换 ndarray = tensor.cpu().numpy() tensor = torch.from_numpy(ndarray).float() # tensor与PIL.IMAGE进行互换 image = torchvision.transforms.functional.to_pil_image(tensor) path = r'./figure.jpg' tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) # np.ndarray 与 PIL.Image的互换 image = PIL.Image.fromarray(nd.array.astype(np.uint8)) ndarray = np.asarray(PIL.Image.open(path)) 维度堆叠 Stack，普通的维度堆叠的测试代码如下\n测试代码如下，实际上dim=0就是基本的堆起来，dim=1就是按照行来堆，dim=2就是按照列来堆\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 a = torch.arange(1,10).reshape(3,3) b = torch.arange(10,100,10).reshape(3,3) c = torch.arange(100,1000,100).reshape(3,3) print('-----------------a----------------') print(a) print('-----------------b----------------') print(b) print('-----------------c----------------') print(c) print('-----------------dim =0----------------') d = torch.stack((a,b,c),dim = 0) print(d.shape) print('the value of d:- {}'.format(d[2,1,0])) print(d) # 也就是说，把单个当成整体直接从上往下堆叠 # 以x[:][:]为构成单元 print('-----------------dim =1----------------') d = torch.stack((a,b,c),dim = 1) print(d.shape) print('the value of d:- {}'.format(d[1,2,2])) print(d) # 将每个的第一个维度，按次序纳出来，同value的堆在一起 # for example：[a[i][:],b[i][:],c[i][:] ]组成新的单元块 # 不，另一种理解，以x[i][:] 为单元 print('-----------------dim =2----------------') d = torch.stack((a,b,c),dim = 2) print(d.shape) print('the value of d:- {}'.format(d[1,2,1])) print(d) # 相应的以x[i][j]为单元构成 list的情况下的维度堆叠测试代码如下\n相应的测试代码如下，实际上一般是按照dim=1来进行堆叠\n1 2 3 4 5 6 7 8 A = torch.randn([3,4,2]) B = [A[:,i] for i in range(A.size(1))] # 这样生成的是一个list,按照我们index的排序 print(A) print(B) C = torch.stack(B,dim=1) print('---------------------result-----------------------') print(C) Cat\n实际上应该也是类似的堆叠思路\n基本的张量函数 torch.split() 划分tensor\ntorch.randperm进行list的乱序处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 和shuffle区分，这是另一种乱序的操作 # cat操作 a = [] for i in range(3): a.append(torch.tensor([i,i])) all_inputs = torch.cat(a) # randperm的效果 test1 idx = torch.randperm(all_inputs.size(0)) print(idx) a1, b = all_inputs, all_inputs[idx] print(a1,b) # test2 ， print('-------------------------') # randperm 进行list的shuffle tensor_a = torch.randint(0,10,[8]) print('origin version ', tensor_a) idx = torch.randperm(tensor_a.size(0)) print('shuffle idx ', idx) tensor_b = tensor_a[idx] print('after operation ', tensor_b) .fill_()按照输入的值对张量进行填充\n选取划窗 nn.unfold拆解卷积中的划窗步骤\n1 2 3 4 5 6 7 8 import torch inputs = torch.randn(1,3,224,224) unfold = torch.nn.Unfold(4,stride=4) output = unfold(inputs) # res output output.size() $ [1,4,3136] # 3136 = (224/4) * (224/4) Torch环境设置 pytorch中的随机种子初始化 yTorch 和 Python的随机数生成器就算随机种子一样也不会产生一样的结果。\n我们可以这样来设置Pytorch的随机数种子：（通常和GPU一起使用）\n1 torch.manual_seed(seed) nn.parameter() Main idea：parameter的作用，主要是将参数和model绑定在一起，我们就知道这个模型中，可能需要训练的参数有哪些，可以需要进行训练的参数加进去，但是当我们想要freeze it的时候就使用detach或者直接修改require_grad来让参数不在接受训练就好了， require_grad是其中的一个属性。可以结合上面的代码分析。 tensor变量是不可训练的，只有修改成parameter才能进行训练。 自带的网络结构中的一些weight和bias应该都是parameter的变量 nn.Softmax中的dim 其实没那么复杂，就和数据的维度是一样的，我们需要把那一个维度的数据之后的数据全部加起来处理就用哪个维度去做。\nIMAGE = N* DATA，dim=1 说明dim = 0 的Channel 是需要被排外的。也就是我们的softmax是基于data进行的。可以找寻源码进行进一步分析解释。\n测试、验证模块 基本编写 model.eval()和model.train()的区别 通常在模型测试的时候会执行model.eval()切换模型的状态，而在训练的时候会执行model.train()，model在这两个状态下的区别主要有：\n在train状态下会启用BN和Dropout，而在eval不启用这两个模块；\n启用BN指的是：用到每一个Batch数据的均值和方差；不启用则指的是使用整体的均值和方差（同时停止更新mean和var） 而对于Dropout来说：启用的时候指的是会随机进行dropout，而关闭的话就会用到全部的网络链接 with torch.no_grad() 上下文管理器，wrap起来的部分不会track grade\n主要用于停止autograd模块的工作，被with包裹起来的部分会停止梯度的更新，得到进一步的加速把，因为我们实际上在验证的时候不会执行step()等操作，所以能够节省计算模型梯度的时间。\n模型的保存和读取专题 @Aiken 2020\n基于onenote笔记，我们知道关键在于如何自由的读取模型中的参数，并选择性的取出来。\npytorch 模型部分参数的加载_LXX516的博客-CSDN博客_pytorch 加载部分参数 1 2 3 4 5 6 7 8 9 10 11 # 至少基于这样的方式我们能把模型中参数的string取出来。 pretrained_dict=torch.load(model_weight) model_dict=myNet.state_dict() # 1. filter out unnecessary keys pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict} # 2. overwrite entries in the existing state dict model_dict.update(pretrained_dict) myNet.load_state_dict(model_dict) GPU相关的设置 @written by Aiken, 2020 this document is about Pytorch‘s CUDA, \u0026 GPU setting.\n查看GPU状态 设置默认GPU设备 一般使用GPU之前，我们需要知道系统中有多少GPU设备，因为默认的GPU设备是0，而且，大家一般都直接使用这张卡，所以我们如果只使用单卡的话，切换一下默认的GPU设备，能够避免一定的冲突。\n1 2 3 4 # 查看GPU使用状态 $ nvidia-smi # or $ gpustat [--watch] 设备基本信息 查看是否存在GPU，数量，类型\n1 2 3 4 5 import torch # 查看是否存在GPU，数量，类型 torch.cuda.is_available() torch.cuda.device_count() torch.cuda.get_device_name(0) 查看指定的GPU的容量和名称\n1 2 torch.cuda.get_device_capability(device) torch.cuda.get_device_name(device) 设置当前系统的默认gpu_devices，推荐使用os来设置（实际上是命令行中的操作）实际上是系统设定针对当前进程的可见GPU，其他的GPU会对当前的程序隐藏，所以默认的0\n1 2 os.environ['CUDA_VISIBLE_DEVICES'] = \"id\" #推荐用法 # 可以在vscode的launch.json中设置env 注意事项：该命令需要在所有调用了CUDA的代码、子程序之前，包括import，所以很多代码的import都是在main()中的。\nGPU使用率优化（注意事项） 缓存爆炸问题 GPU使用途中需要注意的地方，在每次iteration之后记得清除在GPU中占用的memory，cache等，不然有时候会导致缓存和内存的递增和爆炸。\n具体操作：\n1 2 torch.cuda.empty_cache() # after every iteration 运行效率优化 cudnn.benchmark、pytorch论坛 pytorch中文网 、zhihu究极分析文 基本使用思路：\n在程序的开始，让cudnn花费一点额外的时间，找到适用于当前配置的最佳算法，从而优化运行效率。\n注意事项：\n但是如果我们的input_size在每个iteration都存在变化的话，那么每一个iteration都要执行一次搜索，反而得不偿失。\n具体操作\n1 torch.backends.cudnn.benchmark = true 设置使用GPU的方式 设置相应的随机种子 1 2 3 4 torch.cuda.empty_cache() # part2 设置随机种子 torch.cuda.manual_seed(seed) torch.cuda.manual_seed_all(seed) CUDA转换 使用.cuda()来对模型，数据，Loss进行赋值，或者使用to_devices()来设置到相应的GPU设备\n将模型转化到cuda中要在优化器的建立之前执行，因为optimizer是对于模型建立的，对模型执行cuda后已经和原本的参数和模型都不是同一个了，所以一定要在建立优化器之前就对模型进行Cuda 的转化。\n是否要对loss转换到CUDA，取决于一下的两种情况：\n损失函数是Functional：这样的话只要传入的参数是CUDA的就会再CUDA上计算 损失函数是Class with params：如果类内有参数的话，也要转换到CUDA才能一起在CUDA上计算 1 2 3 4 5 if torch.cuda.is_available(): try: loss = loss.cuda() except AttributeError: print('the loss is not cuda-able {}'.format(type(loss))) 多GPU并行 主要使用的命令nn.DataParallel()\n1 2 model = nn.DataParaller(model,device_ids=None) # 如果不设定id的话，应该是自动指定全部可见的GPU的 CPU 偶然会由于pin_memory 的设置来致使CPU的不正常运行（满载等等），并非总是这样。\n核心和线程数设置 限制或增加pytorch的线程个数！指定核数或者满核运行Pytorch！！！_lei_qi的博客-CSDN博客 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import os from multiprocessing import cpu_count # 设置环境变量来控制线程多发的情况 cpu_num = cpu_count() # 核心代码 os.environ['OMP_NUM_THREADS'] = str(cpu_num) # 下面这些应该是不一定药有 os.environ ['OPENBLAS_NUM_THREADS'] = str(cpu_num) os.environ ['MKL_NUM_THREADS'] = str(cpu_num) os.environ ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num) os.environ ['NUMEXPR_NUM_THREADS'] = str(cpu_num) # 从其他资料中可以感觉这条代码应该是和核心代码一样的功能，所以两个写一个应该就可以了 torch.set_num_threds(cpu_num) 网络定义模块 数据定义模块 利用TorchVision读取本地数据 torchvision.datasets.imagefolder() 这个函数实际上能代替我们之前写的函数，但是由于自己写的有一部分统一规则可以使得我们的自定义程度很高，所以目前我们在绝大多数情况下不使用该方法来进行替代。\n但是由于是一个重要的函数，我们在这里还是介绍一下该工具的使用方式：\ntorch 自定义Dataset后的使用 自定义dataset的继承以及后续调用需要注意的是不能忘记将其转换成dataloaer，然后进行iter命令的执行。 也可以用enumerate函数来进行调用，就是记得调用的格式是什么就好 可以参考basicunit中的对shuffle的认知对该函数进行进一步的理解。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 定义dataset的部分 class RL_AET_Dataset(torch.utils.data.Dataset): def __init__(self): super(RL_AET_Dataset,self).__init__() pass def __len__(self): pass def __getitem(self): pass # 声明和构建部分 要记得使用dataloader train_l_dataset = RL_AET_Dataset(x_l, y_l, args) train_l_dataloader =torch.utils.data.DataLoader(train_l_dataset,batch_size=args['b_s'],shuffle=True,num_workers=args['num_workers'],drop_last=True,pin_memory=True) #调用迭代部分 labeled_loader = iter(train_l_dataloader) #all_label_info = [*next(labeled_loader)] Dataloader中的transformer（）： 疑惑解答 用compose集成的所有transform，都会应用，有个to_tensor，切to_tensor会自动转换PIL中的channel和数值范围。\ncompose中的变换组合的顺序关系\nPIL处理的图像变换（比如数据增强之类的方法） to_tensor() 处理tensor的方法：normalize 示例代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 data_transforms = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(). transforms.ToTensor(), transforms.Normalize([a,b,c],[A,B,C])]) # 然后直接加入dataset中的参数，或者是我们自定义的部分 # 在dataset中的写法如下，我们可以在自己的dataset中进行定义 if self.transformer is not None: img = self.transform(img) # 具体的源码细节表现如下 for t in self.transforms: img = t(img) return img Dataloader中的参数 shuffle机制\n主要解决问题：\n是否每次调用的时候都进行随机的操作，还是只有在初始化的时候才进行随机 两种不同使用Dataloader的方式是否会对shuffle的方式进行区分 结论：\n每次对dataloader进行重新调用（重新放到enumerate），或者重新定义iter，都会重新进行shuffle。 num_worker\n参考资料1 参考资料2：pytorch中文文档👇\nnum_workers (int, optional) – 用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0) 用num_worker个子进程加载数据，所以能够将数据在主进程展示还没有调用到该数据之前就将后续的数据存入RAM，所以在数据读取上会比较快，但是占用的RAM和CPU资源会比较大。\nsamples:\ntorch.utils.data - PyTorch 1.9.0 documentation 一文弄懂Pytorch的DataLoader, DataSet, Sampler之间的关系 官方的解释是：\nsampler (Sampler or Iterable, optional) – defines the strategy to draw samples from the dataset. Can be any Iterable with len implemented. If specified, shuffle must not be specified.\n定义从数据集（还是最开始的哪个数据集，不能是额外的数据集）中提取样本的策略：是否能通过该Method去实现Hard-Task或者像Meta-Task一样的采样过程呢？从Meta-Transfer-Learning中看来是可以的，可以学习一下它的写法。\ncollate_fn() collate_fn的作用就是将一个batch的数据进行合并操作。默认的collate_fn是将img和label分别合并成imgs和labels，所以如果你的__getitem__方法只是返回 img, label,那么你可以使用默认的collate_fn方法, 但是如果你每次读取的数据有img, box, label等等，那么你就需要自定义collate_fn来将对应的数据合并成一个batch数据，这样方便后续的训练步骤。\n编写collate_fn可以参考qidong的文章主要是接受数据和标签列表，将其整合成一个矩阵的形式; 如果对传参有需求,可以参考lambda的形式或者是类定义的形式去传入 1 2 3 4 5 6 7 8 9 10 11 dataload = DataLoader(dataset, lambda x: collate_fn(x, **params)) class collater(): def __init__(**params): self.params = ... def __call(self,datas): # make it a batch in this function, then we will instance this class ... def _helpful_fn(self): ... using collate_fn, we can augment the dataset more flexible.\n编写模型 模型基本单元 nn.conv2D：\nkernel_size[1]应该指的是卷积核的宽（不一定都是正方形的） 模型参数共享： pytorch：对比clone、detach以及copy_等张量复制操作 1 2 3 # 假设有modela和modelb，我们需要在进行下降的时候执行参数统一， for a_para,b_para in zip(modela.parameters(),modelb.parameters()): b_para.data.copy_(a_para.data) 网络定义的方式对比分析 @Aiken 2021 主要对比的是ModuleList和Sequtial\n**结论：**通常使用的话，这里我个人推荐使用的是sequtial结合collection中的orderdict来构建的方法，这个方法集成了内部的forward，同时通过``orderdict`也能给print带来更好的可视化效果。\n但是还是有一些特殊的使用场景我们会用到ModuleList\n详解PyTorch中的ModuleList和Sequential 主要区别：\nnn.Sequential内部实现了forward函数，因此可以不用写forward函数。而nn.ModuleList则没有实现内部forward函数。\nnn.Sequential可以使用OrderedDict对每层进行命名，上面已经阐述过了；\nnn.Sequential里面的模块按照顺序进行排列的，所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的。而nn.ModuleList 并没有定义一个网络，它只是将不同的模块储存在一起，这些模块之间并没有什么先后顺序可言。网络的执行顺序按照我们在forward中怎么编写来决定的\n有的时候网络中有很多相似或者重复的层，我们一般会考虑用 for 循环来创建它们，而不是一行一行地写，这种时候就使用ModuleList：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class net4(nn.Module): def __init__(self): super(net4, self).__init__() layers = [nn.Linear(10, 10) for i in range(5)] self.linears = nn.ModuleList(layers) def forward(self, x): for layer in self.linears: x = layer(x) return x net = net4() print(net) # net4( # (linears): ModuleList( # (0): Linear(in_features=10, out_features=10, bias=True) # (1): Linear(in_features=10, out_features=10, bias=True) # (2): Linear(in_features=10, out_features=10, bias=True) # ) # ) 基本使用：\nnn.sequential\n可以通过list和*以及add moudle来进行迭代的定义，同时这种定义方式，会方便我们的重复注册\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from collections import OrderedDict class net_seq(nn.Module): def __init__(self): super(net_seq, self).__init__() self.seq = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) def forward(self, x): return self.seq(x) net_seq = net_seq() print(net_seq) #net_seq( # (seq): Sequential( # (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1)) # (relu1): ReLU() # (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1)) # (relu2): ReLU() # ) #) nn.ModuleList:与python自带的List不同的地方在于他会自动将网络注册到Parameter中，成为网络，但是需要自己去编写forward过程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class net_modlist(nn.Module): def __init__(self): super(net_modlist, self).__init__() self.modlist = nn.ModuleList([ nn.Conv2d(1, 20, 5), nn.ReLU(), nn.Conv2d(20, 64, 5), nn.ReLU() ]) def forward(self, x): for m in self.modlist: x = m(x) return x net_modlist = net_modlist() print(net_modlist) #net_modlist( # (modlist): ModuleList( # (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1)) # (1): ReLU() # (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1)) # (3): ReLU() # ) #) for param in net_modlist.parameters(): print(type(param.data), param.size()) #","wordCount":"2434","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover4.jpeg","datePublished":"2021-12-15T08:00:57Z","dateModified":"2021-12-15T08:00:57Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/pytorch/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">PyTorch Handbook 00 （Archive）</h1><div class=post-meta><span title='2021-12-15 08:00:57 +0000 UTC'>December 15, 2021</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2434 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/python> Python</a>&nbsp;·&nbsp;<a href=/tags/pytorch> Pytorch</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/PyTorch.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover4.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#basic-part%e5%9f%ba%e7%a1%80%e8%ae%be%e5%ae%9a%e9%83%a8%e5%88%86 aria-label="Basic Part基础设定部分">Basic Part基础设定部分</a><ul class=header-level-1><li><a href=#tensor%e5%bc%a0%e9%87%8f%e8%ae%a1%e7%ae%97 aria-label=Tensor张量计算>Tensor张量计算</a><ul class=header-level-2><li><a href=#%e4%b8%a4%e4%b8%aatensor%e7%9a%84%e6%95%b0%e4%b9%98 aria-label=两个tensor的数乘>两个tensor的数乘</a></li><li><a href=#%e5%bc%a0%e9%87%8f%e5%91%bd%e5%90%8d aria-label=张量命名>张量命名</a></li><li><a href=#%e7%b1%bb%e5%9e%8b%e8%bd%ac%e6%8d%a2 aria-label=类型转换>类型转换</a></li><li><a href=#%e7%bb%b4%e5%ba%a6%e5%a0%86%e5%8f%a0 aria-label=维度堆叠>维度堆叠</a></li></ul></li><li><a href=#%e5%9f%ba%e6%9c%ac%e7%9a%84%e5%bc%a0%e9%87%8f%e5%87%bd%e6%95%b0 aria-label=基本的张量函数>基本的张量函数</a><ul class=header-level-2><li><a href=#%e9%80%89%e5%8f%96%e5%88%92%e7%aa%97 aria-label=选取划窗>选取划窗</a></li></ul></li><li><a href=#torch%e7%8e%af%e5%a2%83%e8%ae%be%e7%bd%ae aria-label=Torch环境设置>Torch环境设置</a><ul class=header-level-2><li><a href=#pytorch%e4%b8%ad%e7%9a%84%e9%9a%8f%e6%9c%ba%e7%a7%8d%e5%ad%90%e5%88%9d%e5%a7%8b%e5%8c%96 aria-label=pytorch中的随机种子初始化>pytorch中的随机种子初始化</a></li><li><a href=#nnparameter aria-label=nn.parameter()>nn.parameter()</a></li><li><a href=#nnsoftmax%e4%b8%ad%e7%9a%84dim aria-label=nn.Softmax中的dim>nn.Softmax中的dim</a></li></ul></li><li><a href=#%e6%b5%8b%e8%af%95%e9%aa%8c%e8%af%81%e6%a8%a1%e5%9d%97 aria-label=测试、验证模块>测试、验证模块</a><ul class=header-level-2><li><a href=#%e5%9f%ba%e6%9c%ac%e7%bc%96%e5%86%99 aria-label=基本编写>基本编写</a></li><li><a href=#modeleval%e5%92%8cmodeltrain%e7%9a%84%e5%8c%ba%e5%88%ab aria-label=model.eval()和model.train()的区别>model.eval()和model.train()的区别</a></li><li><a href=#with-torchno_grad aria-label="with torch.no_grad()">with torch.no_grad()</a></li><li><a href=#%e6%a8%a1%e5%9e%8b%e7%9a%84%e4%bf%9d%e5%ad%98%e5%92%8c%e8%af%bb%e5%8f%96%e4%b8%93%e9%a2%98 aria-label=模型的保存和读取专题>模型的保存和读取专题</a></li></ul></li></ul></li><li><a href=#gpu%e7%9b%b8%e5%85%b3%e7%9a%84%e8%ae%be%e7%bd%ae aria-label=GPU相关的设置>GPU相关的设置</a><ul class=header-level-1><li><a href=#%e6%9f%a5%e7%9c%8bgpu%e7%8a%b6%e6%80%81 aria-label=查看GPU状态>查看GPU状态</a><ul class=header-level-2><li><a href=#%e8%ae%be%e7%bd%ae%e9%bb%98%e8%ae%a4gpu%e8%ae%be%e5%a4%87 aria-label=设置默认GPU设备>设置默认GPU设备</a></li><li><a href=#%e8%ae%be%e5%a4%87%e5%9f%ba%e6%9c%ac%e4%bf%a1%e6%81%af aria-label=设备基本信息><strong>设备基本信息</strong></a></li></ul></li><li><a href=#gpu%e4%bd%bf%e7%94%a8%e7%8e%87%e4%bc%98%e5%8c%96%e6%b3%a8%e6%84%8f%e4%ba%8b%e9%a1%b9 aria-label=GPU使用率优化（注意事项）>GPU使用率优化（注意事项）</a><ul class=header-level-2><li><a href=#%e7%bc%93%e5%ad%98%e7%88%86%e7%82%b8%e9%97%ae%e9%a2%98 aria-label=缓存爆炸问题>缓存爆炸问题</a></li><li><a href=#%e8%bf%90%e8%a1%8c%e6%95%88%e7%8e%87%e4%bc%98%e5%8c%96 aria-label=运行效率优化>运行效率优化</a></li><li><a href=#%e8%ae%be%e7%bd%ae%e4%bd%bf%e7%94%a8gpu%e7%9a%84%e6%96%b9%e5%bc%8f aria-label=设置使用GPU的方式>设置使用GPU的方式</a></li><li><a href=#%e8%ae%be%e7%bd%ae%e7%9b%b8%e5%ba%94%e7%9a%84%e9%9a%8f%e6%9c%ba%e7%a7%8d%e5%ad%90 aria-label=设置相应的随机种子>设置相应的随机种子</a></li><li><a href=#cuda%e8%bd%ac%e6%8d%a2 aria-label=CUDA转换>CUDA转换</a></li><li><a href=#%e5%a4%9agpu%e5%b9%b6%e8%a1%8c aria-label=多GPU并行>多GPU并行</a></li></ul></li></ul></li><li><a href=#cpu aria-label=CPU>CPU</a><ul class=header-level-1><li><a href=#%e6%a0%b8%e5%bf%83%e5%92%8c%e7%ba%bf%e7%a8%8b%e6%95%b0%e8%ae%be%e7%bd%ae aria-label=核心和线程数设置>核心和线程数设置</a></li></ul></li><li><a href=#%e7%bd%91%e7%bb%9c%e5%ae%9a%e4%b9%89%e6%a8%a1%e5%9d%97 aria-label=网络定义模块>网络定义模块</a><ul class=header-level-1><li><a href=#%e6%95%b0%e6%8d%ae%e5%ae%9a%e4%b9%89%e6%a8%a1%e5%9d%97 aria-label=数据定义模块>数据定义模块</a><ul class=header-level-2><li><a href=#%e5%88%a9%e7%94%a8torchvision%e8%af%bb%e5%8f%96%e6%9c%ac%e5%9c%b0%e6%95%b0%e6%8d%ae aria-label=利用TorchVision读取本地数据>利用TorchVision读取本地数据</a></li><li><a href=#torch-%e8%87%aa%e5%ae%9a%e4%b9%89dataset%e5%90%8e%e7%9a%84%e4%bd%bf%e7%94%a8 aria-label="torch 自定义Dataset后的使用">torch 自定义Dataset后的使用</a></li><li><a href=#dataloader%e4%b8%ad%e7%9a%84transformer aria-label=Dataloader中的transformer（）：>Dataloader中的transformer（）：</a></li><li><a href=#dataloader%e4%b8%ad%e7%9a%84%e5%8f%82%e6%95%b0 aria-label=Dataloader中的参数>Dataloader中的参数</a><ul class=header-level-3><li><a href=#collate_fn aria-label=collate_fn()>collate_fn()</a></li></ul></li></ul></li><li><a href=#%e7%bc%96%e5%86%99%e6%a8%a1%e5%9e%8b aria-label=编写模型>编写模型</a><ul class=header-level-2><li><a href=#%e6%a8%a1%e5%9e%8b%e5%9f%ba%e6%9c%ac%e5%8d%95%e5%85%83 aria-label=模型基本单元>模型基本单元</a></li><li><a href=#%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e5%85%b1%e4%ba%ab aria-label=模型参数共享：>模型参数共享：</a></li><li><a href=#%e7%bd%91%e7%bb%9c%e5%ae%9a%e4%b9%89%e7%9a%84%e6%96%b9%e5%bc%8f%e5%af%b9%e6%af%94%e5%88%86%e6%9e%90 aria-label=网络定义的方式对比分析>网络定义的方式对比分析</a></li><li><a href=#detach--detach_ aria-label="Detach & detach_">Detach & detach_</a></li><li><a href=#%e6%a8%a1%e5%9e%8b%e8%b0%83%e7%94%a8%e7%9a%84tips aria-label=模型调用的Tips>模型调用的Tips</a></li><li><a href=#warm-up-factor aria-label="Warm-up factor">Warm-up factor</a></li><li><a href=#weight-decayl2 aria-label="Weight decay（L2）">Weight decay（L2）</a></li><li><a href=#learning-rate-decay aria-label="Learning Rate Decay">Learning Rate Decay</a></li></ul></li><li><a href=#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0 aria-label=损失函数>损失函数</a><ul class=header-level-2><li><a href=#crossentropy%e4%ba%a4%e5%8f%89%e7%86%b5 aria-label=CrossEntropy交叉熵>CrossEntropy交叉熵</a></li></ul></li><li><a href=#%e4%bc%98%e5%8c%96%e5%99%a8%e8%ae%be%e8%ae%a1 aria-label=优化器设计>优化器设计</a></li><li><a href=#%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e5%88%9d%e5%a7%8b%e5%8c%96%e5%92%8c%e6%9e%b6%e6%9e%84%e6%9f%a5%e7%9c%8b%e6%96%b9%e6%b3%95 aria-label=模型参数初始化和架构查看方法>模型参数初始化和架构查看方法</a><ul class=header-level-2><li><a href=#childrenmodulesparameters aria-label=children、modules、parameters：>children、modules、parameters：</a></li><li><a href=#%e5%88%9d%e5%a7%8b%e5%8c%96%e5%8e%9f%e5%88%99%e7%bb%a7%e7%bb%ad%e8%b0%83%e7%a0%94 aria-label=初始化原则：（继续调研）>初始化原则：（继续调研）</a></li><li><a href=#%e5%85%b8%e5%9e%8b%e7%9a%84%e5%8f%82%e6%95%b0%e5%88%9d%e5%a7%8b%e5%8c%96%e6%96%b9%e6%b3%95 aria-label=典型的参数初始化方法>典型的参数初始化方法</a></li></ul></li><li><a href=#%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b%e5%92%8c%e7%bb%b4%e5%ba%a6 aria-label=数据类型和维度>数据类型和维度</a><ul class=header-level-2><li><a href=#%e8%be%93%e5%85%a5%e6%95%b0%e6%8d%ae%e7%9a%84%e9%80%9a%e9%81%93 aria-label=输入数据的通道>输入数据的通道</a></li><li><a href=#%e6%a0%87%e7%ad%be%e7%9a%84%e5%bd%a2%e5%bc%8f%e8%bd%ac%e6%8d%a2one-hot aria-label=标签的形式转换one-hot>标签的形式转换one-hot</a></li></ul></li></ul></li><li><a href=#visualize-%e5%8f%af%e8%a7%86%e5%8c%96%e9%83%a8%e5%88%86 aria-label="Visualize 可视化部分">Visualize 可视化部分</a><ul class=header-level-1><li><a href=#tensorboard-in-pytorch aria-label="Tensorboard in Pytorch">Tensorboard in Pytorch</a><ul class=header-level-2><li><a href=#histogram-%e7%9b%b4%e6%96%b9%e5%9b%be%e5%8f%82%e6%95%b0%e7%bb%9f%e8%ae%a1 aria-label="Histogram 直方图参数统计">Histogram 直方图参数统计</a></li><li><a href=#embedding-projection aria-label="Embedding Projection">Embedding Projection</a></li><li><a href=#pr_curve aria-label=PR_CURVE>PR_CURVE</a></li><li><a href=#add_text aria-label=Add_TEXT>Add_TEXT</a></li><li><a href=#add_figure aria-label=ADD_Figure>ADD_Figure</a></li></ul></li><li><a href=#%e5%8f%af%e8%a7%86%e5%8c%96%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%83%ad%e5%8a%9b%e5%9b%becam aria-label=可视化神经网络热力图（CAM）>可视化神经网络热力图（CAM）</a><ul class=header-level-2><li><a href=#%e7%ae%97%e6%b3%95%e5%8e%9f%e7%90%86 aria-label=算法原理>算法原理</a></li><li><a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0 aria-label=代码实现：>代码实现：</a></li></ul></li><li><a href=#bugs aria-label=BUGs>BUGs</a></li></ul></li><li><a href=#debug aria-label=DEBUG>DEBUG</a><ul class=header-level-1><li><a href=#1importerror-cannot-import-name-pillow_version aria-label="1.ImportError: cannot import name &lsquo;PILLOW_VERSION&rsquo;">1.ImportError: cannot import name &lsquo;PILLOW_VERSION&rsquo;</a></li><li><a href=#2%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e8%ae%a1%e7%ae%97%e9%87%8f%e7%bb%9f%e8%ae%a1-and-debug%e8%be%93%e5%87%ba aria-label="2.模型参数&计算量统计 and Debug输出">2.模型参数&计算量统计 and Debug输出</a></li><li><a href=#3pytorch%e5%8a%a0%e8%bd%bd%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b aria-label=3.PyTorch加载预训练模型>3.PyTorch加载预训练模型</a></li><li><a href=#4some-of-the-strides-of-a-given-numpy-array-are-negative aria-label="4.some of the strides of a given numpy array are negative.">4.some of the strides of a given numpy array are negative.</a></li><li><a href=#5%e8%af%bb%e5%8f%96loader%e7%9a%84%e6%97%b6%e5%80%99%e5%9b%be%e5%83%8f%e7%9a%84%e5%a4%a7%e5%b0%8f%e4%b8%8d%e4%b8%80 aria-label=5.读取loader的时候图像的大小不一>5.读取loader的时候图像的大小不一</a></li><li><a href=#6bus-error-dataloader-num_worker aria-label="6.bus error dataloader num_worker">6.bus error dataloader num_worker</a></li><li><a href=#7bus-errorinsufficient-shared-memoryshm aria-label="7.bus error：insufficient shared memory（shm）">7.bus error：insufficient shared memory（shm）</a></li><li><a href=#8%e8%ae%ad%e7%bb%83%e8%bf%87%e7%a8%8b%e4%b8%adcache%e5%92%8cmemory%e7%9a%84%e5%8d%a0%e7%94%a8%e9%80%90%e6%b8%90%e5%8d%87%e9%ab%98 aria-label=8.训练过程中Cache和Memory的占用逐渐升高>8.训练过程中Cache和Memory的占用逐渐升高</a></li><li><a href=#9%e6%a2%af%e5%ba%a6%e7%88%86%e7%82%b8%e9%97%ae%e9%a2%98%e7%ae%97%e6%b3%95%e6%b2%a1%e6%9c%89%e5%ad%a6%e4%b9%a0%e6%95%88%e6%9e%9c aria-label=9.梯度爆炸问题，算法没有学习效果>9.梯度爆炸问题，算法没有学习效果</a></li><li><a href=#10%e7%b1%bb%e5%9e%8b%e8%bd%ac%e6%8d%a2%e9%97%ae%e9%a2%98%e6%b1%87%e6%80%bb aria-label=10.类型转换问题汇总>10.类型转换问题汇总</a></li><li><a href=#11%e6%95%b0%e6%8d%ae%e7%bb%b4%e5%ba%a6%e4%b8%8d%e5%af%b9%e5%ba%94%e9%97%ae%e9%a2%98%e6%b1%87%e6%80%bb aria-label=11.数据维度不对应问题汇总>11.数据维度不对应问题汇总</a></li><li><a href=#12%e5%8f%96%e5%87%ba%e5%85%b7%e4%bd%93%e6%95%b0%e5%80%bc%e6%97%b6%e5%80%99%e7%9a%84%e9%97%ae%e9%a2%98 aria-label=12.取出具体数值时候的问题>12.取出具体数值时候的问题</a></li><li><a href=#13cpu%e5%8d%a0%e7%94%a899 aria-label=13.CPU占用99%>13.CPU占用99%</a></li><li><a href=#14-%e9%a2%84%e6%b5%8b%e5%80%bc%e5%85%a8%e4%b8%ba0%e6%a8%a1%e5%9e%8b%e6%94%b6%e6%95%9b%e5%88%b0%e5%a5%87%e6%80%aa%e7%9a%84%e5%9c%b0%e6%96%b9%e6%8d%9f%e5%a4%b1%e4%bf%9d%e6%8c%81%e4%b8%80%e8%87%b4%e5%85%a8%e5%9d%87%e7%ad%89 aria-label="14. 预测值全为0，模型收敛到奇怪的地方，损失保持一致（全均等）">14. 预测值全为0，模型收敛到奇怪的地方，损失保持一致（全均等）</a></li><li><a href=#15%e6%a8%a1%e5%9e%8b%e9%83%a8%e5%88%86-%e8%ae%ad%e7%bb%83%e4%b8%ad%e6%a8%a1%e5%9e%8b%e5%87%86%e7%a1%ae%e7%8e%87%e4%b8%8d%e4%b8%8a%e5%8d%87 aria-label="15.模型部分： 训练中模型准确率不上升">15.模型部分： 训练中模型准确率不上升</a></li><li><a href=#16-on-entry-to-sgemm-parameter-number-8-had-an-illegal-value aria-label="16. On entry to SGEMM parameter number 8 had an illegal value">16. On entry to SGEMM parameter number 8 had an illegal value</a></li><li><a href=#17-cuda-error-device-side-assert-triggered-cuda-kernel-errors-might-be-asynchronously-reported-at-some-other-api-call aria-label="17. CUDA error: device-side assert triggered CUDA kernel errors might be asynchronously reported at some other API call">17. CUDA error: device-side assert triggered CUDA kernel errors might be asynchronously reported at some other API call</a></li><li><a href=#runtimeerror-the-derivative-for-target-is-not-implemented aria-label="RuntimeError the derivative for target is not implemented">RuntimeError the derivative for target is not implemented</a></li><li><a href=#only-tensors-created-explicitly-by-the-user-graph-leaves-support-the-deepcopy-protocol-at-the-moment aria-label="Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment">Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=basic-part基础设定部分>Basic Part基础设定部分<a hidden class=anchor aria-hidden=true href=#basic-part基础设定部分>#</a></h1><p>@AikenH 2020 + 2021</p><p>this part is about pytorch basic unit, help me to code deep learning better.</p><h2 id=tensor张量计算>Tensor张量计算<a hidden class=anchor aria-hidden=true href=#tensor张量计算>#</a></h2><h3 id=两个tensor的数乘>两个tensor的数乘<a hidden class=anchor aria-hidden=true href=#两个tensor的数乘>#</a></h3><p>计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 简单的分析一下算法的逻辑</span>
</span></span><span class=line><span class=cl><span class=c1># 这是割裂出来batch的矩阵相乘形式</span>
</span></span><span class=line><span class=cl><span class=n>batch1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>batch2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bmm</span><span class=p>(</span><span class=n>batch1</span><span class=p>,</span> <span class=n>batch2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>out</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;&#39;&#39;output ans is
</span></span></span><span class=line><span class=cl><span class=s1>torch.size([10,3,5])&#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 按位相乘</span>
</span></span><span class=line><span class=cl><span class=n>res</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>batch1</span><span class=p>,</span><span class=n>batch2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>view和permute</strong>的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。</p><h3 id=张量命名>张量命名<a hidden class=anchor aria-hidden=true href=#张量命名>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>NCHW</span> <span class=o>=</span> <span class=p>[</span><span class=err>‘</span><span class=n>N</span><span class=err>’</span><span class=p>,</span> <span class=err>‘</span><span class=n>C</span><span class=err>’</span><span class=p>,</span> <span class=err>‘</span><span class=n>H</span><span class=err>’</span><span class=p>,</span> <span class=err>‘</span><span class=n>W</span><span class=err>’</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>images</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>56</span><span class=p>,</span> <span class=mi>56</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=n>NCHW</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>images</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=s1>&#39;C&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>images</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s1>&#39;C&#39;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=类型转换>类型转换<a hidden class=anchor aria-hidden=true href=#类型转换>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># tensor 与 nd.array进行互换</span>
</span></span><span class=line><span class=cl><span class=n>ndarray</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>ndarray</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># tensor与PIL.IMAGE进行互换</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>transforms</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>to_pil_image</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>path</span> <span class=o>=</span> <span class=sa>r</span><span class=s1>&#39;./figure.jpg&#39;</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>transforms</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>(</span><span class=n>PIL</span><span class=o>.</span><span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>path</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># np.ndarray 与 PIL.Image的互换</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>PIL</span><span class=o>.</span><span class=n>Image</span><span class=o>.</span><span class=n>fromarray</span><span class=p>(</span><span class=n>nd</span><span class=o>.</span><span class=n>array</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>ndarray</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>asarray</span><span class=p>(</span><span class=n>PIL</span><span class=o>.</span><span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>path</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=维度堆叠>维度堆叠<a hidden class=anchor aria-hidden=true href=#维度堆叠>#</a></h3><p>Stack，<strong>普通的维度堆叠的测试代码如下</strong></p><p>测试代码如下，实际上dim=0就是基本的堆起来，dim=1就是按照行来堆，dim=2就是按照列来堆</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span><span class=mi>100</span><span class=p>,</span><span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>c</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span><span class=mi>1000</span><span class=p>,</span><span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-----------------a----------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-----------------b----------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-----------------c----------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>c</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-----------------dim =0----------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>c</span><span class=p>),</span><span class=n>dim</span> <span class=o>=</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>d</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;the value of d:-    </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>d</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 也就是说，把单个当成整体直接从上往下堆叠</span>
</span></span><span class=line><span class=cl><span class=c1># 以x[:][:]为构成单元</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-----------------dim =1----------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>c</span><span class=p>),</span><span class=n>dim</span> <span class=o>=</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>d</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;the value of d:-    </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>d</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 将每个的第一个维度，按次序纳出来，同value的堆在一起</span>
</span></span><span class=line><span class=cl><span class=c1># for example：[a[i][:],b[i][:],c[i][:] ]组成新的单元块</span>
</span></span><span class=line><span class=cl><span class=c1># 不，另一种理解，以x[i][:] 为单元</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-----------------dim =2----------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>c</span><span class=p>),</span><span class=n>dim</span> <span class=o>=</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>d</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;the value of d:-    </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>d</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 相应的以x[i][j]为单元构成</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>list的情况下的维度堆叠测试代码如下</strong></p><p>相应的测试代码如下，实际上一般是按照dim=1来进行堆叠</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>A</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>2</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>B</span> <span class=o>=</span> <span class=p>[</span><span class=n>A</span><span class=p>[:,</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>A</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>))]</span>
</span></span><span class=line><span class=cl><span class=c1># 这样生成的是一个list,按照我们index的排序</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>A</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>B</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>C</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>B</span><span class=p>,</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;---------------------result-----------------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Cat</strong></p><p>实际上应该也是类似的堆叠思路</p><h2 id=基本的张量函数>基本的张量函数<a hidden class=anchor aria-hidden=true href=#基本的张量函数>#</a></h2><p>torch.split() 划分tensor</p><p>torch.randperm进行list的乱序处理</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 和shuffle区分，这是另一种乱序的操作</span>
</span></span><span class=line><span class=cl><span class=c1># cat操作</span>
</span></span><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>a</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>i</span><span class=p>,</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>all_inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># randperm的效果 test1</span>
</span></span><span class=line><span class=cl><span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=n>all_inputs</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>a1</span><span class=p>,</span> <span class=n>b</span> <span class=o>=</span> <span class=n>all_inputs</span><span class=p>,</span> <span class=n>all_inputs</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>a1</span><span class=p>,</span><span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># test2 ，</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-------------------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># randperm 进行list的shuffle</span>
</span></span><span class=line><span class=cl><span class=n>tensor_a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>10</span><span class=p>,[</span><span class=mi>8</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;origin version &#39;</span><span class=p>,</span> <span class=n>tensor_a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=n>tensor_a</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;shuffle idx &#39;</span><span class=p>,</span> <span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tensor_b</span> <span class=o>=</span> <span class=n>tensor_a</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;after operation &#39;</span><span class=p>,</span> <span class=n>tensor_b</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>.fill_()按照输入的值对张量进行填充</p><h3 id=选取划窗>选取划窗<a hidden class=anchor aria-hidden=true href=#选取划窗>#</a></h3><p><code>nn.unfold</code>拆解卷积中的划窗步骤</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>224</span><span class=p>,</span><span class=mi>224</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>unfold</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Unfold</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>unfold</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># res output</span>
</span></span><span class=line><span class=cl><span class=n>output</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=err>$</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>3136</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># 3136 = (224/4) * (224/4)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=torch环境设置>Torch环境设置<a hidden class=anchor aria-hidden=true href=#torch环境设置>#</a></h2><h3 id=pytorch中的随机种子初始化>pytorch中的随机种子初始化<a hidden class=anchor aria-hidden=true href=#pytorch中的随机种子初始化>#</a></h3><p>yTorch 和 Python的随机数生成器就算随机种子一样也不会产生一样的结果。</p><p>我们可以这样来设置Pytorch的随机数种子：（通常和GPU一起使用）</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=nnparameter>nn.parameter()<a hidden class=anchor aria-hidden=true href=#nnparameter>#</a></h3><ol><li>Main idea：<strong>parameter的作用，主要是将参数和model绑定在一起</strong>，我们就知道这个模型中，可能需<strong>要训练的参数</strong>有哪些，可以需要进行训练的参数加进去，但是当我们想要freeze it的时候就使用detach或者直接修改require_grad来让参数不在接受训练就好了， require_grad是其中的一个属性。可以结合上面的代码分析。</li><li>tensor变量是不可训练的，只有修改成parameter才能进行训练。</li><li>自带的网络结构中的一些weight和bias应该都是parameter的变量</li></ol><h3 id=nnsoftmax中的dim>nn.Softmax中的dim<a hidden class=anchor aria-hidden=true href=#nnsoftmax中的dim>#</a></h3><p>其实没那么复杂，就和数据的维度是一样的，我们需要把那一个维度的数据之后的数据全部加起来处理就用哪个维度去做。</p><p>IMAGE = N* DATA，dim=1 说明dim = 0 的Channel 是需要被排外的。也就是我们的softmax是基于data进行的。可以找寻源码进行进一步分析解释。</p><h2 id=测试验证模块>测试、验证模块<a hidden class=anchor aria-hidden=true href=#测试验证模块>#</a></h2><h3 id=基本编写>基本编写<a hidden class=anchor aria-hidden=true href=#基本编写>#</a></h3><h3 id=modeleval和modeltrain的区别>model.eval()和model.train()的区别<a hidden class=anchor aria-hidden=true href=#modeleval和modeltrain的区别>#</a></h3><p>通常在模型测试的时候会执行<code>model.eval()</code>切换模型的状态，而在训练的时候会执行<code>model.train()</code>，model在这两个状态下的区别主要有：</p><p>在<strong>train</strong>状态下会启用BN和Dropout，而在<strong>eval</strong>不启用这两个模块；</p><ul><li>启用BN指的是：用到每一个Batch数据的均值和方差；不启用则指的是使用整体的均值和方差（同时停止更新mean和var）</li><li>而对于Dropout来说：启用的时候指的是会随机进行dropout，而关闭的话就会用到全部的网络链接</li></ul><h3 id=with-torchno_grad>with torch.no_grad()<a hidden class=anchor aria-hidden=true href=#with-torchno_grad>#</a></h3><p>上下文管理器，wrap起来的部分不会track grade</p><p>主要用于停止autograd模块的工作，被<code>with</code>包裹起来的部分会停止梯度的更新，得到进一步的加速把，因为我们实际上在验证的时候不会执行<code>step()</code>等操作，所以能够节省计算模型梯度的时间。</p><h3 id=模型的保存和读取专题>模型的保存和读取专题<a hidden class=anchor aria-hidden=true href=#模型的保存和读取专题>#</a></h3><p>@Aiken 2020</p><p>基于onenote笔记，我们知道关键在于如何自由的读取模型中的参数，并选择性的取出来。</p><p><a href=https://blog.csdn.net/LXX516/article/details/80124768 target=_blank rel=noopener>pytorch 模型部分参数的加载_LXX516的博客-CSDN博客_pytorch 加载部分参数</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 至少基于这样的方式我们能把模型中参数的string取出来。</span>
</span></span><span class=line><span class=cl><span class=n>pretrained_dict</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>model_weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model_dict</span><span class=o>=</span><span class=n>myNet</span><span class=o>.</span><span class=n>state_dict</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. filter out unnecessary keys</span>
</span></span><span class=line><span class=cl><span class=n>pretrained_dict</span> <span class=o>=</span> <span class=p>{</span><span class=n>k</span><span class=p>:</span> <span class=n>v</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>pretrained_dict</span><span class=o>.</span><span class=n>items</span><span class=p>()</span> <span class=k>if</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>model_dict</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. overwrite entries in the existing state dict</span>
</span></span><span class=line><span class=cl><span class=n>model_dict</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>pretrained_dict</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>myNet</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>model_dict</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=gpu相关的设置>GPU相关的设置<a hidden class=anchor aria-hidden=true href=#gpu相关的设置>#</a></h1><p>@written by Aiken, 2020 this document is about Pytorch‘s CUDA, & GPU setting.</p><h2 id=查看gpu状态>查看GPU状态<a hidden class=anchor aria-hidden=true href=#查看gpu状态>#</a></h2><h3 id=设置默认gpu设备>设置默认GPU设备<a hidden class=anchor aria-hidden=true href=#设置默认gpu设备>#</a></h3><p>一般使用GPU之前，我们需要知道系统中有多少GPU设备，因为默认的GPU设备是0，而且，大家一般都直接使用这张卡，所以我们如果只使用单卡的话，切换一下默认的GPU设备，能够避免一定的冲突。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 查看GPU使用状态</span>
</span></span><span class=line><span class=cl>$ nvidia-smi
</span></span><span class=line><span class=cl><span class=c1># or</span>
</span></span><span class=line><span class=cl>$ gpustat <span class=o>[</span>--watch<span class=o>]</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=设备基本信息><strong>设备基本信息</strong><a hidden class=anchor aria-hidden=true href=#设备基本信息>#</a></h3><ol><li><p>查看是否存在GPU，数量，类型</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=c1># 查看是否存在GPU，数量，类型</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>查看指定的GPU的容量和名称</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_capability</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>设置当前系统的默认gpu_devices，推荐使用os来设置（实际上是命令行中的操作）实际上是系统设定针对当前进程的可见GPU，其他的GPU会对当前的程序隐藏，所以默认的0</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;id&#34;</span> <span class=c1>#推荐用法</span>
</span></span><span class=line><span class=cl><span class=c1># 可以在vscode的launch.json中设置env</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>注意事项：该命令需要在所有调用了CUDA的代码、子程序之前，包括<code>import</code>，所以很多代码的import都是在main()中的。</strong></p></li></ol><h2 id=gpu使用率优化注意事项>GPU使用率优化（注意事项）<a hidden class=anchor aria-hidden=true href=#gpu使用率优化注意事项>#</a></h2><h3 id=缓存爆炸问题>缓存爆炸问题<a hidden class=anchor aria-hidden=true href=#缓存爆炸问题>#</a></h3><p>GPU使用途中需要注意的地方，在每次iteration之后记得<strong>清除在GPU中占用</strong>的memory，cache等，不然有时候会导致缓存和内存的递增和爆炸。</p><p>具体操作：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># after every iteration</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=运行效率优化>运行效率优化<a hidden class=anchor aria-hidden=true href=#运行效率优化>#</a></h3><p><code>cudnn.benchmark</code>、<a href=https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936 target=_blank rel=noopener>pytorch论坛</a>
<a href=https://www.pytorchtutorial.com/when-should-we-set-cudnn-benchmark-to-true/ target=_blank rel=noopener>pytorch中文网</a>
、<a href=https://zhuanlan.zhihu.com/p/73711222 target=_blank rel=noopener>zhihu究极分析文</a></p><p><strong>基本使用思路</strong>：</p><p>在程序的开始，让cudnn花费一点额外的时间，找到适用于当前配置的最佳算法，从而优化运行效率。</p><p><strong>注意事项：</strong></p><p>但是如果我们的input_size在每个iteration都存在变化的话，那么每一个iteration都要执行一次搜索，反而得不偿失。</p><p><strong>具体操作</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>benchmark</span> <span class=o>=</span> <span class=n>true</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=设置使用gpu的方式>设置使用GPU的方式<a hidden class=anchor aria-hidden=true href=#设置使用gpu的方式>#</a></h3><h3 id=设置相应的随机种子>设置相应的随机种子<a hidden class=anchor aria-hidden=true href=#设置相应的随机种子>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># part2 设置随机种子</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>manual_seed_all</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=cuda转换>CUDA转换<a hidden class=anchor aria-hidden=true href=#cuda转换>#</a></h3><p>使用<code>.cuda()</code>来对<code>模型</code>，<code>数据</code>，<code>Loss</code>进行赋值，或者使用<code>to_devices()</code>来设置到相应的GPU设备</p><p>将模型转化到cuda中要在优化器的建立之前执行，因为optimizer是对于模型建立的，对模型执行cuda后已经和原本的参数和模型都不是同一个了，所以一定<strong>要在建立优化器之前就对模型进行Cuda 的转化</strong>。</p><p>是否要对loss转换到CUDA，取决于一下的两种情况：</p><ul><li>损失函数是Functional：这样的话只要传入的参数是CUDA的就会再CUDA上计算</li><li>损失函数是Class with params：如果类内有参数的话，也要转换到CUDA才能一起在CUDA上计算</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span></span><span class=line><span class=cl>	<span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>except</span> <span class=ne>AttributeError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=nb>print</span><span class=p>(</span><span class=s1>&#39;the loss is not cuda-able </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>loss</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=多gpu并行>多GPU并行<a hidden class=anchor aria-hidden=true href=#多gpu并行>#</a></h3><p>主要使用的命令<code>nn.DataParallel()</code></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParaller</span><span class=p>(</span><span class=n>model</span><span class=p>,</span><span class=n>device_ids</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 如果不设定id的话，应该是自动指定全部可见的GPU的</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=cpu>CPU<a hidden class=anchor aria-hidden=true href=#cpu>#</a></h1><p>偶然会由于<code>pin_memory</code> 的设置来致使CPU的不正常运行（满载等等），并非总是这样。</p><h2 id=核心和线程数设置>核心和线程数设置<a hidden class=anchor aria-hidden=true href=#核心和线程数设置>#</a></h2><p><a href=https://blog.csdn.net/lei_qi/article/details/115358703 target=_blank rel=noopener>限制或增加pytorch的线程个数！指定核数或者满核运行Pytorch！！！_lei_qi的博客-CSDN博客</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>multiprocessing</span> <span class=kn>import</span> <span class=n>cpu_count</span>
</span></span><span class=line><span class=cl><span class=c1># 设置环境变量来控制线程多发的情况</span>
</span></span><span class=line><span class=cl><span class=n>cpu_num</span> <span class=o>=</span> <span class=n>cpu_count</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 核心代码</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;OMP_NUM_THREADS&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>cpu_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 下面这些应该是不一定药有</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span> <span class=p>[</span><span class=s1>&#39;OPENBLAS_NUM_THREADS&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>cpu_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span> <span class=p>[</span><span class=s1>&#39;MKL_NUM_THREADS&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>cpu_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span> <span class=p>[</span><span class=s1>&#39;VECLIB_MAXIMUM_THREADS&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>cpu_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span> <span class=p>[</span><span class=s1>&#39;NUMEXPR_NUM_THREADS&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>cpu_num</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 从其他资料中可以感觉这条代码应该是和核心代码一样的功能，所以两个写一个应该就可以了</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>set_num_threds</span><span class=p>(</span><span class=n>cpu_num</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=网络定义模块>网络定义模块<a hidden class=anchor aria-hidden=true href=#网络定义模块>#</a></h1><h2 id=数据定义模块>数据定义模块<a hidden class=anchor aria-hidden=true href=#数据定义模块>#</a></h2><h3 id=利用torchvision读取本地数据>利用TorchVision读取本地数据<a hidden class=anchor aria-hidden=true href=#利用torchvision读取本地数据>#</a></h3><p><code>torchvision.datasets.imagefolder()</code> 这个函数实际上能代替我们之前写的函数，但是由于自己写的有一部分统一规则可以使得我们的自定义程度很高，所以目前我们在绝大多数情况下不使用该方法来进行替代。</p><p>但是由于是一个重要的函数，我们在这里还是介绍一下该工具的使用方式：</p><h3 id=torch-自定义dataset后的使用>torch 自定义Dataset后的使用<a hidden class=anchor aria-hidden=true href=#torch-自定义dataset后的使用>#</a></h3><ol><li>自定义dataset的继承以及后续调用需要注意的是不能忘记将其转换成dataloaer，然后进行iter命令的执行。</li><li>也可以用enumerate函数来进行调用，就是记得调用的格式是什么就好</li><li>可以参考basicunit中的对shuffle的认知对该函数进行进一步的理解。</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 定义dataset的部分</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>RL_AET_Dataset</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>RL_AET_Dataset</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>__getitem</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span><span class=line><span class=cl><span class=c1># 声明和构建部分 要记得使用dataloader</span>
</span></span><span class=line><span class=cl><span class=n>train_l_dataset</span> <span class=o>=</span> <span class=n>RL_AET_Dataset</span><span class=p>(</span><span class=n>x_l</span><span class=p>,</span> <span class=n>y_l</span><span class=p>,</span> <span class=n>args</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_l_dataloader</span> <span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>train_l_dataset</span><span class=p>,</span><span class=n>batch_size</span><span class=o>=</span><span class=n>args</span><span class=p>[</span><span class=s1>&#39;b_s&#39;</span><span class=p>],</span><span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span><span class=n>num_workers</span><span class=o>=</span><span class=n>args</span><span class=p>[</span><span class=s1>&#39;num_workers&#39;</span><span class=p>],</span><span class=n>drop_last</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span><span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#调用迭代部分</span>
</span></span><span class=line><span class=cl><span class=n>labeled_loader</span> <span class=o>=</span> <span class=nb>iter</span><span class=p>(</span><span class=n>train_l_dataloader</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#all_label_info =  [*next(labeled_loader)]</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=dataloader中的transformer>Dataloader中的transformer（）：<a hidden class=anchor aria-hidden=true href=#dataloader中的transformer>#</a></h3><p><strong>疑惑解答 用compose集成的所有transform，都会应用，有个to_tensor，切to_tensor会自动转换PIL中的channel和数值范围。</strong></p><ol><li><p>compose中的变换组合的顺序关系</p><ul><li>PIL处理的图像变换（比如数据增强之类的方法）</li><li><code>to_tensor()</code></li><li>处理tensor的方法：<code>normalize</code></li></ul></li><li><p>示例代码</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>data_transforms</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                        <span class=n>transforms</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                        <span class=n>transforms</span><span class=o>.</span><span class=n>RandomHorizontalFlip</span><span class=p>()</span><span class=o>.</span>
</span></span><span class=line><span class=cl>                        <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                        <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>([</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>c</span><span class=p>],[</span><span class=n>A</span><span class=p>,</span><span class=n>B</span><span class=p>,</span><span class=n>C</span><span class=p>])])</span>
</span></span><span class=line><span class=cl><span class=c1># 然后直接加入dataset中的参数，或者是我们自定义的部分</span>
</span></span><span class=line><span class=cl><span class=c1># 在dataset中的写法如下，我们可以在自己的dataset中进行定义</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>transformer</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 具体的源码细节表现如下</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>transforms</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>t</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>img</span>
</span></span></code></pre></td></tr></table></div></div></li></ol><h3 id=dataloader中的参数>Dataloader中的参数<a hidden class=anchor aria-hidden=true href=#dataloader中的参数>#</a></h3><p>shuffle机制</p><p>主要解决问题：</p><ol><li>是否每次调用的时候都进行随机的操作，还是只有在初始化的时候才进行随机</li><li>两种不同使用Dataloader的方式是否会对shuffle的方式进行区分</li></ol><p>结论：</p><ol><li>每次对dataloader进行重新调用（重新放到enumerate），或者重新定义iter，都会重新进行shuffle。</li></ol><p>num_worker</p><p><a href=https://www.cnblogs.com/hesse-summer/p/11343870.html target=_blank rel=noopener>参考资料1</a>
参考资料2：pytorch中文文档👇</p><p><strong>num_workers</strong> (<em>int</em>, optional) – 用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0)
用num_worker个子进程加载数据，所以能够将数据在主进程展示还没有调用到该数据之前就将后续的数据存入RAM，所以在数据读取上会比较快，但是占用的RAM和CPU资源会比较大。</p><p>samples:</p><p><a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader" target=_blank rel=noopener>torch.utils.data - PyTorch 1.9.0 documentation</a></p><p><a href=https://www.cnblogs.com/marsggbo/p/11308889.html target=_blank rel=noopener>一文弄懂Pytorch的DataLoader, DataSet, Sampler之间的关系</a></p><p>官方的解释是：</p><p>sampler (Sampler or Iterable, optional) – defines the strategy to draw samples from the dataset. Can be any Iterable with <strong>len</strong> implemented. If specified, shuffle must not be specified.</p><p>定义从数据集（还是最开始的哪个数据集，不能是额外的数据集）中提取样本的策略：是否能通过该Method去实现Hard-Task或者像Meta-Task一样的采样过程呢？从Meta-Transfer-Learning中看来是可以的，可以学习一下它的写法。</p><h4 id=collate_fn>collate_fn()<a hidden class=anchor aria-hidden=true href=#collate_fn>#</a></h4><p>collate_fn的作用就是将一个batch的数据进行合并操作。默认的collate_fn是将img和label分别合并成imgs和labels，所以如果你的__getitem__方法只是返回 img, label,那么你可以使用默认的collate_fn方法,
但是如果你每次读取的数据有img, box, label等等，那么你就需要自定义collate_fn来将对应的数据合并成一个batch数据，这样方便后续的训练步骤。</p><ul><li>编写collate_fn可以参考qidong的文章主要是接受数据和标签列表，将其整合成一个矩阵的形式;</li><li>如果对传参有需求,可以参考<code>lambda</code>的形式或者是类定义的形式去传入</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dataload</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>collate_fn</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=o>**</span><span class=n>params</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>collater</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>params</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>params</span> <span class=o>=</span> <span class=o>...</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>__call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>datas</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># make it a batch in this function, then we will instance this class</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_helpful_fn</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span></code></pre></td></tr></table></div></div><p>using collate_fn, we can augment the dataset more flexible.</p><h2 id=编写模型>编写模型<a hidden class=anchor aria-hidden=true href=#编写模型>#</a></h2><h3 id=模型基本单元>模型基本单元<a hidden class=anchor aria-hidden=true href=#模型基本单元>#</a></h3><p>nn.conv2D：</p><ul><li>kernel_size[1]应该指的是卷积核的宽（不一定都是正方形的）</li></ul><h3 id=模型参数共享>模型参数共享：<a hidden class=anchor aria-hidden=true href=#模型参数共享>#</a></h3><p><a href=https://www.cnblogs.com/wwzone/articles/12917333.html target=_blank rel=noopener>pytorch：对比clone、detach以及copy_等张量复制操作</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 假设有modela和modelb，我们需要在进行下降的时候执行参数统一，</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>a_para</span><span class=p>,</span><span class=n>b_para</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>modela</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>modelb</span><span class=o>.</span><span class=n>parameters</span><span class=p>()):</span>
</span></span><span class=line><span class=cl>        <span class=n>b_para</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>copy_</span><span class=p>(</span><span class=n>a_para</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=网络定义的方式对比分析>网络定义的方式对比分析<a hidden class=anchor aria-hidden=true href=#网络定义的方式对比分析>#</a></h3><p>@Aiken 2021 主要对比的是ModuleList和Sequtial</p><p>**结论：**通常使用的话，这里我个人推荐使用的是<code>sequtial</code>结合<code>collection</code>中的<code>orderdict</code>来构建的方法，这个方法集成了内部的<code>forward</code>，同时通过``orderdict`也能给print带来更好的可视化效果。</p><p>但是还是有一些特殊的使用场景我们会用到<code>ModuleList</code></p><p><a href=https://zhuanlan.zhihu.com/p/75206669 target=_blank rel=noopener>详解PyTorch中的ModuleList和Sequential</a></p><p>主要区别：</p><ol><li><p>nn.Sequential内部实现了forward函数，因此可以不用写forward函数。而nn.ModuleList则没有实现内部forward函数。</p></li><li><p>nn.Sequential可以使用OrderedDict对每层进行命名，上面已经阐述过了；</p></li><li><p>nn.Sequential里面的模块按照顺序进行排列的，所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的。而nn.ModuleList 并没有定义一个网络，它只是将不同的模块储存在一起，这些模块之间并没有什么先后顺序可言。<strong>网络的执行顺序按照我们在forward中怎么编写来决定的</strong></p></li><li><p>有的时候网络中有很多相似或者重复的层，我们一般会考虑用 for 循环来创建它们，而不是一行一行地写，这种时候就使用ModuleList：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>net4</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>net4</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>layers</span> <span class=o>=</span> <span class=p>[</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linears</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>(</span><span class=n>layers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>linears</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>net</span> <span class=o>=</span> <span class=n>net4</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>net</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># net4(</span>
</span></span><span class=line><span class=cl><span class=c1>#   (linears): ModuleList(</span>
</span></span><span class=line><span class=cl><span class=c1>#     (0): Linear(in_features=10, out_features=10, bias=True)</span>
</span></span><span class=line><span class=cl><span class=c1>#     (1): Linear(in_features=10, out_features=10, bias=True)</span>
</span></span><span class=line><span class=cl><span class=c1>#     (2): Linear(in_features=10, out_features=10, bias=True)</span>
</span></span><span class=line><span class=cl><span class=c1>#   )</span>
</span></span><span class=line><span class=cl><span class=c1># )</span>
</span></span></code></pre></td></tr></table></div></div></li></ol><p>基本使用：</p><ol><li><p>nn.sequential</p><p>可以通过list和*以及add moudle来进行迭代的定义，同时这种定义方式，会方便我们的重复注册</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>OrderedDict</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>net_seq</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>net_seq</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>seq</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=n>OrderedDict</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                        <span class=p>(</span><span class=s1>&#39;conv1&#39;</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>20</span><span class=p>,</span><span class=mi>5</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>                         <span class=p>(</span><span class=s1>&#39;relu1&#39;</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>                          <span class=p>(</span><span class=s1>&#39;conv2&#39;</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span><span class=mi>64</span><span class=p>,</span><span class=mi>5</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>                       <span class=p>(</span><span class=s1>&#39;relu2&#39;</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>())</span>
</span></span><span class=line><span class=cl>                       <span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>seq</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>net_seq</span> <span class=o>=</span> <span class=n>net_seq</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>net_seq</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#net_seq(</span>
</span></span><span class=line><span class=cl><span class=c1>#  (seq): Sequential(</span>
</span></span><span class=line><span class=cl><span class=c1>#    (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span>
</span></span><span class=line><span class=cl><span class=c1>#    (relu1): ReLU()</span>
</span></span><span class=line><span class=cl><span class=c1>#    (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span>
</span></span><span class=line><span class=cl><span class=c1>#    (relu2): ReLU()</span>
</span></span><span class=line><span class=cl><span class=c1>#  )</span>
</span></span><span class=line><span class=cl><span class=c1>#)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>nn.ModuleList:与python自带的List不同的地方在于他会自动将网络注册到Parameter中，成为网络，但是需要自己去编写forward过程</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>net_modlist</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>net_modlist</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>modlist</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                       <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                       <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                        <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                        <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>modlist</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=n>m</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>net_modlist</span> <span class=o>=</span> <span class=n>net_modlist</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>net_modlist</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1>#net_modlist(</span>
</span></span><span class=line><span class=cl><span class=c1>#  (modlist): ModuleList(</span>
</span></span><span class=line><span class=cl><span class=c1>#    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span>
</span></span><span class=line><span class=cl><span class=c1>#    (1): ReLU()</span>
</span></span><span class=line><span class=cl><span class=c1>#    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span>
</span></span><span class=line><span class=cl><span class=c1>#    (3): ReLU()</span>
</span></span><span class=line><span class=cl><span class=c1>#  )</span>
</span></span><span class=line><span class=cl><span class=c1>#)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>net_modlist</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>param</span><span class=o>.</span><span class=n>data</span><span class=p>),</span> <span class=n>param</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=c1>#&lt;class &#39;torch.Tensor&#39;&gt; torch.Size([20, 1, 5, 5])</span>
</span></span><span class=line><span class=cl><span class=c1>#&lt;class &#39;torch.Tensor&#39;&gt; torch.Size([20])</span>
</span></span><span class=line><span class=cl><span class=c1>#&lt;class &#39;torch.Tensor&#39;&gt; torch.Size([64, 20, 5, 5])</span>
</span></span><span class=line><span class=cl><span class=c1>#&lt;class &#39;torch.Tensor&#39;&gt; torch.Size([64])</span>
</span></span></code></pre></td></tr></table></div></div></li></ol><h3 id=detach--detach_>Detach & detach_<a hidden class=anchor aria-hidden=true href=#detach--detach_>#</a></h3><p>这个模块在后续进行pretrain或者transfer的时候应该会经常被用到，所以这种方法还是需要熟练掌握的</p><p><a href=https://www.cnblogs.com/wanghui-garcia/p/10677071.html target=_blank rel=noopener>详细的分析介绍</a></p><p><code>detach</code>是产生一组不需要下降的“<code>Copy</code>”：如果要修改原值的话就要进行赋值操作。</p><p><code>detach_</code>则是修改本身参数的属性（<code>require_grad</code>etc.）执行函数就能将参数修改为不需要下降的情况，不需要执行赋值处理。</p><h3 id=模型调用的tips>模型调用的Tips<a hidden class=anchor aria-hidden=true href=#模型调用的tips>#</a></h3><p><strong>使用list进行多模型的混合调用</strong></p><p>由于python默认的是引用赋值，也就是浅拷贝的方式？
通过list来进行模型的批量构建，通过list来将模型整合起来，是<strong>不会</strong>使用<strong>额外的存储空间</strong>的，它们指向同一个地址。基于这样的假设，我们可以基于list来简化代码，通过LOOP来执行，相关的调用操作，比如生成器或者预测之类的，来<strong>简化</strong>代码结构。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model1</span> <span class=o>=</span> <span class=n>AET_model</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>,</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model2</span> <span class=o>=</span> <span class=n>AET_model</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>,</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>model1</span><span class=p>,</span><span class=n>model2</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=nb>id</span><span class=p>(</span><span class=n>model1</span><span class=p>)</span><span class=o>==</span><span class=nb>id</span><span class=p>(</span><span class=n>model2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;the address of those model is same, so donot need extra space&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 具体可以简化什么类型的操作：</span>
</span></span><span class=line><span class=cl><span class=n>optimizer_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>models_t</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>model_list</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=n>models_t</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                            <span class=n>lr</span><span class=p>,</span><span class=n>mom</span><span class=err>，</span><span class=n>wd</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>optimizer1</span> <span class=o>=</span> <span class=n>_</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>optimizer2</span> <span class=o>=</span> <span class=n>_</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># like this</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=warm-up-factor>Warm-up factor<a hidden class=anchor aria-hidden=true href=#warm-up-factor>#</a></h3><p>对于这一部分的概念我还是有些不了解，是否和冷启动和热启动的概念是相关的，如果不是的话，顺便就学习一下冷启动和热启动的概念。</p><p>具体解析：</p><ol><li><a href=https://stackoverflow.com/questions/55933867/what-does-learning-rate-warm-up-mean target=_blank rel=noopener>neural network - What does &ldquo;learning rate warm-up&rdquo; mean? - Stack Overflow</a></li><li><a href=https://blog.csdn.net/qq_36387683/article/details/97265084 target=_blank rel=noopener>关于warm_up学习率_云中寻雾的博客-CSDN博客</a></li></ol><p><a href=https://blog.csdn.net/xys430381_1/article/details/107468446 target=_blank rel=noopener>pytorch学习率调整方法（warm up） ，label smooth、apex混合精度训练、梯度累加_xys430381_1的专栏-CSDN博客</a></p><p><a href=https://www.zhihu.com/question/338066667 target=_blank rel=noopener>神经网络中 warmup 策略为什么有效；有什么理论解释么？</a></p><h3 id=weight-decayl2>Weight decay（L2）<a hidden class=anchor aria-hidden=true href=#weight-decayl2>#</a></h3><p>实际上就是对权重进行L2正则化，让权重衰减到更小的值，在一定程度上减少模型的过拟合问题，所以权重衰减实际上也叫L2正则化。</p><p>具体的数学推导后续将集成到<strong>GoodNote笔记</strong>上，将正则化单独作为一个模块去整理。</p><p><strong>权重衰减（L2正则化）的作用</strong></p><p><strong>作用：</strong> 权重衰减（L2正则化）可以避免模型过拟合问题。</p><p><strong>思考：</strong> L2正则化项有让w变小的效果，但是为什么w变小可以防止过拟合呢？</p><p><strong>原理：</strong> （1）从模型的复杂度上解释：更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合更好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。（2）从数学方面的解释：过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。</p><p><div class=post-img-view><a data-fancybox=gallery href=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png><img alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png loading=lazy src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png class=responsive-image src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png style="display:block;margin:0 auto" alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175236273.png></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>image-20201205175236273</p><p>内容来自： <a href=https://blog.csdn.net/u012162613/article/details/44261657 target=_blank rel=noopener>正则化方法：L1和L2 regularization、数据集扩增、dropout</a></p><h3 id=learning-rate-decay>Learning Rate Decay<a hidden class=anchor aria-hidden=true href=#learning-rate-decay>#</a></h3><p>当我们选择了一个合适的lr，但是损失训练到一定程度以后就不再下降了，就在一个区间中来回动荡，可能是出现了一下的问题：</p><p><div class=post-img-view><a data-fancybox=gallery href=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png><img alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png loading=lazy src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png class=responsive-image src=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png style="display:block;margin:0 auto" alt=https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20201205175605729.png></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>image-20201205175605729</p><p>对这种问题的解决就是通过学习率衰减来实现的：将学习率随着训练的进行来进行衰减，这个方法就比较直观了。具体的方法描述可以在 <code>../project_note/训练参数调整策略.md</code>中找到。</p><p>也可以参考如下连接：<a href=https://blog.csdn.net/weixin_42662358/article/details/93732852 target=_blank rel=noopener>详细理解pytorch的六种学习率pytorch</a></p><h2 id=损失函数>损失函数<a hidden class=anchor aria-hidden=true href=#损失函数>#</a></h2><p>nn中自带的Loss Function比如说MSE之类的，计算出来的值本身就已经对batch取了平均值，同时我们进行交叉熵的计算的时候，我们不需要实现对他进行softmax，因为再CE中已经集成了softmax的操作。</p><h3 id=crossentropy交叉熵>CrossEntropy交叉熵<a hidden class=anchor aria-hidden=true href=#crossentropy交叉熵>#</a></h3><p>这里会介绍一下Pytorch中的CE损失的具体实现的方法，这里给出三种方式的对比。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=c1># initial data and calculate method</span>
</span></span><span class=line><span class=cl><span class=n>input_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>((</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>label</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>cri</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>nll_f</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>NLLLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># output softmax and logsoftmax and pred</span>
</span></span><span class=line><span class=cl><span class=n>softamx_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>input_x</span><span class=p>,</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logsoftmax_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>softamx_x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;softamx_x </span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>softamx_x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;pre_res </span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>softamx_x</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;log_softamx_x </span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>logsoftmax_x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># calculate official ce and NLL</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;torch ce </span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span><span class=n>cri</span><span class=p>(</span><span class=n>input_x</span><span class=p>,</span><span class=n>label</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;nll_cal </span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>nll_f</span><span class=p>(</span><span class=n>logsoftmax_x</span><span class=p>,</span><span class=n>label</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># calculate the manual ce loss we cal</span>
</span></span><span class=line><span class=cl><span class=n>res</span> <span class=o>=</span> <span class=p>[</span><span class=o>-</span><span class=n>logsoftmax_x</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>label</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>label</span><span class=p>))]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;manual cal </span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span><span class=nb>sum</span><span class=p>(</span><span class=n>res</span><span class=p>)</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>label</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>可以发现三种方式计算出来的损失是一样的，这就说明了我们在计算的时候要记住，ce中是自己集成了softmax的操作，同时在Nll中是存在了取negative的操作的。按照这个操作手册去实现自己相应的损失函数设计</p><h2 id=优化器设计>优化器设计<a hidden class=anchor aria-hidden=true href=#优化器设计>#</a></h2><p>这一部分主要添加一些常见的优化器参数的设置包括SGD和Adam的对应设置，主要介绍一下设置Adam
实际上Adam的设置对于学习率来说没有那么敏感，但是我们还是要了解参数的意思才知道怎么去设置该优化器</p><h2 id=模型参数初始化和架构查看方法>模型参数初始化和架构查看方法<a hidden class=anchor aria-hidden=true href=#模型参数初始化和架构查看方法>#</a></h2><p>实际上对参数初始化也就是需要对整体的架构进行遍历，所以这两个会归为一个子课题</p><p>参数的初始化方法只要使用如下的方式，无论我们采取那种定义的方式，，都能遍历到其中所包含的所有网络层</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 如果直接在网络定义的时候直接进行初始化</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>kaiming_normal_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span><span class=n>mode</span><span class=o>=</span><span class=s1>&#39;fan_out&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span><span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 如果是在模型定义的外部的话</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>kaiming_normal_</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span><span class=n>mode</span><span class=o>=</span><span class=s1>&#39;fan_out&#39;</span><span class=p>,</span> <span class=n>nonlinearity</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>layer</span><span class=o>.</span><span class=n>bias</span> <span class=n>isnotNone</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span> <span class=n>val</span><span class=o>=</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>val</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span> <span class=n>val</span><span class=o>=</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_normal_</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>layer</span><span class=o>.</span><span class=n>bias</span> <span class=n>isnotNone</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=n>layer</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span> <span class=n>val</span><span class=o>=</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>layer</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 也可以使用其他的方法比如parameters，children</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=childrenmodulesparameters>children、modules、parameters：<a hidden class=anchor aria-hidden=true href=#childrenmodulesparameters>#</a></h3><p><code>model.modules</code>会遍历model中所有的子层，而<code>children</code>只会遍历当前层，也就是最外层的情况，所以如果要进行参数的初始化的话，最好是用类内或者类外的两种方法来实现初始化</p><p><code>parameter</code>返回的是模型的所有参数，所以初始化最好使用的是``modules`，而parameter一般用来初始化参数</p><p><strong>用numel与parameters计算参数的个数</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#可以简洁的写成下面的形式</span>
</span></span><span class=line><span class=cl><span class=c1>#numel()函数本身的作用是返回数组中元素的个数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>count_parameters</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=n>P</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>P</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()</span> <span class=k>if</span> <span class=n>P</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#帮助理解的结构形式可以表达如下：</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>count_parameters</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>ans</span> <span class=o>+=</span> <span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=初始化原则继续调研>初始化原则：（继续调研）<a hidden class=anchor aria-hidden=true href=#初始化原则继续调研>#</a></h3><p><a href=https://blog.csdn.net/ys1305/article/details/94332007 target=_blank rel=noopener>pytorch中的参数初始化方法总结_ys1305的博客-CSDN博客_pytorch 参数初始化</a></p><p><strong>Batch-Normalization</strong>：<a href=https://www.cnblogs.com/shine-lee/p/11989612.html target=_blank rel=noopener>Batch Normalization详解 - shine-lee - 博客园 (cnblogs.com)</a></p><ul><li>conv：<code>kaming_normal_</code></li><li>fc：<code>constan_,xvaier</code></li><li>bn：<code>normal_\constant|</code></li></ul><h3 id=典型的参数初始化方法>典型的参数初始化方法<a hidden class=anchor aria-hidden=true href=#典型的参数初始化方法>#</a></h3><p>EnAET中可以看到参考的源码如下，需要注意的是，BN中只有两个参数，所以不需要进行参数的初始化，或者直接置0、1即可.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算参数</span>
</span></span><span class=line><span class=cl>        <span class=n>n</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>kernel_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>m</span><span class=o>.</span><span class=n>kernel_size</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>m</span><span class=o>.</span><span class=n>out_channels</span>
</span></span><span class=line><span class=cl>        <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mf>2.</span> <span class=o>/</span> <span class=n>n</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span><span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>fill_</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>zero_</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_normal_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>    <span class=c1># what&#39;s this method</span>
</span></span><span class=line><span class=cl>        <span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>zero_</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=数据类型和维度>数据类型和维度<a hidden class=anchor aria-hidden=true href=#数据类型和维度>#</a></h2><p>在算法编写的过程中，数据的类型和维度的对齐和channel是很重要的，在这里也很容易出现很多的bug，在这里做一个信息的汇总</p><h3 id=输入数据的通道>输入数据的通道<a hidden class=anchor aria-hidden=true href=#输入数据的通道>#</a></h3><p>结论：pytorch网络输入图片的shape要求通道是<strong>channel_first</strong>（通道在前）的，所以如果我们的图片不是这样的话，我们就需要执行相应的变化。</p><p>TODO：整理各种数据读取方式读入的channel first 或是 last : skimage,PIL,numpy</p><p>整理相应的各种数据类型进行transpose（numpy）的方式</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 也可以使用view函数，但是相应的，view需要计算出各个维度相应的数值</span>
</span></span><span class=line><span class=cl><span class=c1># view（）直接使用的时候不改变原值的大小，permute也不改变，使用的方法不同而已</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>3</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=标签的形式转换one-hot>标签的形式转换one-hot<a hidden class=anchor aria-hidden=true href=#标签的形式转换one-hot>#</a></h3><p>进行训练之前要将数据转化为onehot的形式，才能输入训练，而且一般因为是batch_size的形式，所以我们需要转化为矩阵形式的onehot，不能用单个label的转化方法。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>make_onehot_single</span><span class=p>(</span><span class=n>num</span><span class=p>,</span><span class=n>index</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;&#39;&#39;根据类别数量和index生成single，onehot&#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>    <span class=c1># BTW：scatter方法也能生成one-hot</span>
</span></span><span class=line><span class=cl>    <span class=n>onehot</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>num</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>onehot</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>onehot</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 主要是下面这种方法需要掌握，</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>make_onehot_array</span><span class=p>(</span><span class=n>width</span><span class=p>,</span><span class=n>target</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;&#39;&#39;根据label生成onehot矩阵。
</span></span></span><span class=line><span class=cl><span class=s1>    width：类别数 target：具体的labeldata&#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>length</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>target</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>ValueError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;the type of target is </span><span class=si>{}</span><span class=s1> &#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>target</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>Exception</span><span class=p>(</span><span class=s1>&#39;break down&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>onehot</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>length</span><span class=p>,</span> <span class=n>width</span><span class=p>)</span><span class=o>.</span><span class=n>scatter_</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=n>target</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>),</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>onehot</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=visualize-可视化部分>Visualize 可视化部分<a hidden class=anchor aria-hidden=true href=#visualize-可视化部分>#</a></h1><h2 id=tensorboard-in-pytorch>Tensorboard in Pytorch<a hidden class=anchor aria-hidden=true href=#tensorboard-in-pytorch>#</a></h2><p>@Aiken H 2021 review 之前这一部分的projection和model都没有成功显示，这次在新框架中展示一下。</p><p><a href=https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html target=_blank rel=noopener>Visualizing Models, Data, and Training with TensorBoard - PyTorch Tutorials 1.8.1+cu102 documentation</a></p><p><a href=https://blog.csdn.net/bigbennyguo/article/details/87956434 target=_blank rel=noopener>详解PyTorch项目使用TensorboardX进行训练可视化_浅度寺-CSDN博客_tensorboardx</a></p><p><a href="https://pytorch.apachecn.org/#/docs/1.7/17?id=%e4%bd%bf%e7%94%a8-tensorboard-%e5%8f%af%e8%a7%86%e5%8c%96%e6%a8%a1%e5%9e%8b%ef%bc%8c%e6%95%b0%e6%8d%ae%e5%92%8c%e8%ae%ad%e7%bb%83" target=_blank rel=noopener>使用 TensorBoard 可视化模型，数据和训练 (apachecn.org)</a></p><p>在pytorch教程中的Projection可以结合后续输出的Feature使用来分析相应的聚类和分类可靠性</p><p>可以尝试使用，教程写的很简单易懂。</p><h3 id=histogram-直方图参数统计>Histogram 直方图参数统计<a hidden class=anchor aria-hidden=true href=#histogram-直方图参数统计>#</a></h3><p>一般来说用来统计模型中间的一些参数的分布情况，具体的使用在训练的epoch之间，和val是一个比较类似的机制，具体的代码样例如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># visualize those parameter as historgram</span>
</span></span><span class=line><span class=cl><span class=c1># we can add other model here</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>i</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span><span class=n>param</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>main_model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>writer</span><span class=o>.</span><span class=n>add_histogram</span><span class=p>(</span><span class=s1>&#39;main_model&#39;</span><span class=o>+</span><span class=n>name</span><span class=p>,</span><span class=n>param</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>pass</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=embedding-projection>Embedding Projection<a hidden class=anchor aria-hidden=true href=#embedding-projection>#</a></h3><p>@Aiken H 2021 这一部分可能才是神经网络的特征分布的可视化图。</p><p>下面这个是Google的Embedding Projection，需要上传.tsv保存的数据，但是实际上就是Tensorboard上也有集成的功能</p><p><a href=http://projector.tensorflow.org/ target=_blank rel=noopener>Embedding projector - visualization of high-dimensional data</a></p><p><a href=https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin target=_blank rel=noopener>Visualizing Data using the Embedding Projector in TensorBoard</a></p><h3 id=pr_curve>PR_CURVE<a hidden class=anchor aria-hidden=true href=#pr_curve>#</a></h3><p>这里会贴上pr_curve中需要的参数和我们这边编写的示例代码</p><h3 id=add_text>Add_TEXT<a hidden class=anchor aria-hidden=true href=#add_text>#</a></h3><p>换行失效问题, 这是因为在Tensorboard中这一部分使用的是Markdown的格式, 所以在这里我们在换行符<code>\n</code>之前, 需要保留两个空格才能实现真正的换行</p><h3 id=add_figure>ADD_Figure<a hidden class=anchor aria-hidden=true href=#add_figure>#</a></h3><p>有时候我们会发现我们编写的figure在step中没有全部现实出来, 这是我们可以通过启动命令来展示所有的图片</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>--</span><span class=n>samples_per_plugin</span> <span class=n>images</span><span class=o>=</span><span class=mi>9999</span>
</span></span><span class=line><span class=cl><span class=c1># 999 &gt; the num you want to displ</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=可视化神经网络热力图cam>可视化神经网络热力图（CAM）<a hidden class=anchor aria-hidden=true href=#可视化神经网络热力图cam>#</a></h2><p>@Aiken2020 为了便于查看神经网络的<strong>输出</strong>，对于图像的哪一部分<strong>更加的侧重</strong>，也就是指导网络进行分类的主要是图像的哪些区域，（相应的也可以按照类似的方法查看Attention Network的效果把），就想着<strong>可视化一下CAM</strong>。看指导分类的高响应区域是否落在核心区域。</p><p>参考链接：</p><p><a href=https://blog.csdn.net/sinat_37532065/article/details/103362517 target=_blank rel=noopener>CAM Pytorch</a></p><h3 id=算法原理>算法原理<a hidden class=anchor aria-hidden=true href=#算法原理>#</a></h3><p>其计算方法如下图所示。对于一个CNN模型，对其最后一个featuremap做全局平均池化（GAP）计算各通道均值，然后通过FC层等映射到class score，找出argmax，<strong>计算最大的那一类的输出相对于最后一个featuremap的梯度</strong>（实际上就是最后一个map中哪些对于分类的变化其更大的作用，也就是类似权重的机制），再把这个梯度可视化到原图上即可。直观来说，就是看一下<strong>网络抽取到的高层特征的哪部分对最终的classifier影响更大</strong>。</p><p><div class=post-img-view><a data-fancybox=gallery href=https://raw.githubusercontent.com/AikenH/md-image/master/img/20191203102807477.png><img alt=ImgInGIthu loading=lazy src=https://raw.githubusercontent.com/AikenH/md-image/master/img/20191203102807477.png class=responsive-image src=https://raw.githubusercontent.com/AikenH/md-image/master/img/20191203102807477.png style="display:block;margin:0 auto" alt=ImgInGIthu></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><ul><li><p>Quote: 找到了一篇基于Keras的CAM实现，感谢：</p><p><a href=https://blog.csdn.net/Einstellung/article/details/82858974 target=_blank rel=noopener>https://blog.csdn.net/Einstellung/article/details/82858974</a>
但是我还是习惯用Pytorch一点，所以参考着改了一版Pytorch的实现。其中，有一个地方困扰了一下，因为Pytorch的自动求导机制，一般只会保存函数值对输入的导数值，而中间变量的导数值都没有保留，而此处我们需要计算输出层相对于最后一个feature map梯度，所以参考https://blog.csdn.net/qq_27061325/article/details/84728539解决了该问题。</p></li></ul><h3 id=代码实现>代码实现：<a hidden class=anchor aria-hidden=true href=#代码实现>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>draw_CAM</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>img_path</span><span class=p>,</span> <span class=n>save_path</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>visual_heatmap</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>    绘制 Class Activation Map
</span></span></span><span class=line><span class=cl><span class=s1>    :param model: 加载好权重的Pytorch model
</span></span></span><span class=line><span class=cl><span class=s1>    :param img_path: 测试图片路径
</span></span></span><span class=line><span class=cl><span class=s1>    :param save_path: CAM结果保存路径
</span></span></span><span class=line><span class=cl><span class=s1>    :param transform: 输入图像预处理方法
</span></span></span><span class=line><span class=cl><span class=s1>    :param visual_heatmap: 是否可视化原始heatmap（调用matplotlib）
</span></span></span><span class=line><span class=cl><span class=s1>    :return:
</span></span></span><span class=line><span class=cl><span class=s1>    &#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 图像加载&amp;预处理</span>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>img_path</span><span class=p>)</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s1>&#39;RGB&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>transform</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>transform</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 获取模型输出的feature/score</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>features</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>features</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>classifier</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 为了能读取到中间梯度定义的辅助函数</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>extract</span><span class=p>(</span><span class=n>g</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>global</span> <span class=n>features_grad</span>
</span></span><span class=line><span class=cl>        <span class=n>features_grad</span> <span class=o>=</span> <span class=n>g</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 预测得分最高的那一类对应的输出score</span>
</span></span><span class=line><span class=cl>    <span class=n>pred</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>output</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>pred_class</span> <span class=o>=</span> <span class=n>output</span><span class=p>[:,</span> <span class=n>pred</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>features</span><span class=o>.</span><span class=n>register_hook</span><span class=p>(</span><span class=n>extract</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pred_class</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span> <span class=c1># 计算梯度</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>grads</span> <span class=o>=</span> <span class=n>features_grad</span>   <span class=c1># 获取梯度</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pooled_grads</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>adaptive_avg_pool2d</span><span class=p>(</span><span class=n>grads</span><span class=p>,</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 此处batch size默认为1，所以去掉了第0维（batch size维）</span>
</span></span><span class=line><span class=cl>    <span class=n>pooled_grads</span> <span class=o>=</span> <span class=n>pooled_grads</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>features</span> <span class=o>=</span> <span class=n>features</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 512是最后一层feature的通道数</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>512</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>features</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=o>...</span><span class=p>]</span> <span class=o>*=</span> <span class=n>pooled_grads</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=o>...</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 以下部分同Keras版实现</span>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>=</span> <span class=n>features</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>heatmap</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>maximum</span><span class=p>(</span><span class=n>heatmap</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>/=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>heatmap</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 可视化原始热力图</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>visual_heatmap</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>matshow</span><span class=p>(</span><span class=n>heatmap</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=n>img_path</span><span class=p>)</span>  <span class=c1># 用cv2加载原始图像</span>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>resize</span><span class=p>(</span><span class=n>heatmap</span><span class=p>,</span> <span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>  <span class=c1># 将热力图的大小调整为与原始图像相同</span>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>(</span><span class=mi>255</span> <span class=o>*</span> <span class=n>heatmap</span><span class=p>)</span>  <span class=c1># 将热力图转换为RGB格式</span>
</span></span><span class=line><span class=cl>    <span class=n>heatmap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>applyColorMap</span><span class=p>(</span><span class=n>heatmap</span><span class=p>,</span> <span class=n>cv2</span><span class=o>.</span><span class=n>COLORMAP_JET</span><span class=p>)</span>  <span class=c1># 将热力图应用于原始图像</span>
</span></span><span class=line><span class=cl>    <span class=n>superimposed_img</span> <span class=o>=</span> <span class=n>heatmap</span> <span class=o>*</span> <span class=mf>0.4</span> <span class=o>+</span> <span class=n>img</span>  <span class=c1># 这里的0.4是热力图强度因子</span>
</span></span><span class=line><span class=cl>    <span class=n>cv2</span><span class=o>.</span><span class=n>imwrite</span><span class=p>(</span><span class=n>save_path</span><span class=p>,</span> <span class=n>superimposed_img</span><span class=p>)</span>  <span class=c1># 将图像保存到硬盘</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=bugs>BUGs<a hidden class=anchor aria-hidden=true href=#bugs>#</a></h2><p>如果想要展示出所有step的图片, 我们可以在命令行里执行tensoroard的时候执行下列命令.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>tensorboard --logdir log/cifar100_resnet18 --samples_per_plugin <span class=nv>images</span><span class=o>=</span><span class=m>999999</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=debug>DEBUG<a hidden class=anchor aria-hidden=true href=#debug>#</a></h1><h2 id=1importerror-cannot-import-name-pillow_version>1.ImportError: cannot import name &lsquo;PILLOW_VERSION&rsquo;<a hidden class=anchor aria-hidden=true href=#1importerror-cannot-import-name-pillow_version>#</a></h2><p>PIL版本过高，换低就可以，他不配是一个棘手的问题</p><p><code>pip install Pillow==6.2.2 --user</code></p><h2 id=2模型参数计算量统计-and-debug输出>2.模型参数&计算量统计 and Debug输出<a hidden class=anchor aria-hidden=true href=#2模型参数计算量统计-and-debug输出>#</a></h2><ol><li>用来计算模型构建中网络的参数，空间大小，MAdd，FLOPs等指标，count_params很好写，然后剩下的计算我们交给两个第三方的库来实现：<code>torchstat</code>,<code>thop</code></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchstat</span> <span class=kn>import</span> <span class=n>stat</span>
</span></span><span class=line><span class=cl><span class=n>stat</span><span class=p>(</span><span class=n>model</span><span class=p>,(</span><span class=mi>3</span><span class=p>,</span><span class=mi>224</span><span class=p>,</span><span class=mi>224</span><span class=p>))</span> <span class=c1>#that‘s all using it in the eval stage</span>
</span></span></code></pre></td></tr></table></div></div><ol><li>也可以使用<code>torchsummary</code>来查看各层输出的数据的维度数目</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchsummary</span> <span class=kn>import</span> <span class=n>summary</span>
</span></span><span class=line><span class=cl><span class=n>summary</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>(),</span><span class=n>input_size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span><span class=mi>224</span><span class=p>,</span><span class=mi>224</span><span class=p>),</span><span class=n>batch_size</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol><li>相应的Debug还可以使用<code>torchsnooper</code>进行：变量的类型和维度追踪这个模块通过<code>@xxxx</code>修饰器的方法调用在指定的method前面，能够在训练过程中输出一些<strong>参数值的类型</strong>和<strong>数值变化</strong>的较为详细的信息。个人理解的最佳使用环境是，用于调试或者监控<strong>类型之间的错误</strong>。</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 这个package如果没记错的话好像是使用装饰器的方法去进行测试</span>
</span></span><span class=line><span class=cl><span class=o>@...</span>
</span></span><span class=line><span class=cl><span class=n>method</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=3pytorch加载预训练模型>3.PyTorch加载预训练模型<a hidden class=anchor aria-hidden=true href=#3pytorch加载预训练模型>#</a></h2><p>具体错误：在于模型Dict中的Key和预训练model中的Key不对应，无法匹配。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=err>Unexpected</span> <span class=err>key(s)</span> <span class=err>in</span> <span class=err>state_dict:</span> <span class=s2>&#34;module.features. ...&#34;</span><span class=err>.，Expected</span> <span class=s2>&#34;.features....&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>问题分析：</p><p><strong>situation1</strong>：可以看到前面多了module这个str，这一般是由于其中一方使用了多GPU训练后直接保存的，也就是<code>DataParallel</code>模式下导致的不匹配问题。</p><p><strong>solution1</strong>： <a href=https://blog.csdn.net/qq_32998593/article/details/89343507 target=_blank rel=noopener>参考资料</a></p><ol><li><p>load模型后去掉多余的参数在事先的时候发现这个方法还是存在问题的，并不是简单的dict封装的结构，所以没法这样简单的进行赋值处理:x:</p></li><li><p>用空白代替module，暂时还没尝试，但是我觉得会遇到和第一个一样的问题:x:</p></li><li><p>:zap:最简单的方法：加载模型后将模型进行DataParallel，再进行数据的转化，将数据进行并行化。具体的操作如下</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 将ids设置成拥有的GPU即可，但是不知道单GPU的情况可不可以实现这种情况</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li></ol><p><strong>Situation2：</strong> 保存模型格式为.pth.tar，无法载入训练好的模型</p><p><strong>Solution2</strong>：</p><p>原因是因为被保存的模型是在高版本的pytorch下实现的，但是再低版本中读取的模型是.pth格式的，就会出现版本冲突。
解决方法如下👇：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 在高版本的环境中load model，然后再重新保存，保存的时候添加参数，使得保存成旧版本即可</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>,</span><span class=n>save_path</span><span class=p>,</span><span class=n>_use_new_zipfile_serialization</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># DONE</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>xxx is a zip archive(did you mean to use torch.jit.load()?)</strong></p><p>使用低版本的Torch去Load高版本（>1.6）保存的模型（.pth.tar）遇到的问题,</p><p>这种错误，主要是模型的版本冲突。</p><p><strong>解决办法</strong>：在高版本的环境中，重新load模型，然后直接save，在保存的时候添加参数</p><p><code>torch.save(model.state_dict(),model_path,_use_new_zipfile_serialization=False)</code></p><p>就可以保存成.pth的模型，也能在低版本的torch环境中使用了</p><h2 id=4some-of-the-strides-of-a-given-numpy-array-are-negative>4.some of the strides of a given numpy array are negative.<a hidden class=anchor aria-hidden=true href=#4some-of-the-strides-of-a-given-numpy-array-are-negative>#</a></h2><p>ver：torch1.2 这个问题可能会在后续的版本中被优化。</p><p><strong>Situation</strong>：</p><p><a href=https://www.cnblogs.com/devilmaycry812839668/p/13761613.html target=_blank rel=noopener>https://www.cnblogs.com/devilmaycry812839668/p/13761613.html</a>
问题出现在flat操作中，反向切片<code>[::-1]</code>会导致数据存储在内存上不连续，在旧版本中无法实现，对这样数据进行存储。
<strong>Solution1</strong>:
所以在执倒排切片的时候执行，<code>img2 = np.ascontiguousarray(img)</code> 使得数据在内存空间上连续。</p><p><strong>Solution2</strong>:</p><p>或者执行倒排切片的时候，直接<code>return img.copy()</code></p><h2 id=5读取loader的时候图像的大小不一>5.读取loader的时候图像的大小不一<a hidden class=anchor aria-hidden=true href=#5读取loader的时候图像的大小不一>#</a></h2><p>使用Crop对图像进行处理的时候，不注意的话就是会出现这样的问题，图像的size随机改变，导致的输出不统一。也可能是Crop函数写的有问题。</p><p><strong>bug info</strong>如下</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got <span class=m>182</span> and <span class=m>360</span> in dimension <span class=m>2</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Solution：</strong></p><p>resize，spp，padding，<strong>adaptiveMaxPooling</strong>（自适应的pooling，pooling到指定的size（channel除外））</p><h2 id=6bus-error-dataloader-num_worker>6.bus error dataloader num_worker<a hidden class=anchor aria-hidden=true href=#6bus-error-dataloader-num_worker>#</a></h2><p>原因暂时还不是太清楚，但是我们可以把num_worker设置为0 来解决这个问题.jpg</p><h2 id=7bus-errorinsufficient-shared-memoryshm>7.bus error：insufficient shared memory（shm）<a hidden class=anchor aria-hidden=true href=#7bus-errorinsufficient-shared-memoryshm>#</a></h2><p>这种原因通常会在docker环境中出现，由于未指定shm容量大小，比如<code>ipc=host</code>之类的命令，就会导致docker的shm只有64m，于是在运行的时候就会出问题。这种情况下<strong>只能重新run docker</strong>（目前只找到了这个方法）。</p><p>如果要妥协的话，就只能<strong>试着减小batch_size</strong>。但是随着模型的设计上，这其实不是一个可以逃避的问题，也会增加莫须有的其他成本，所以。</p><h2 id=8训练过程中cache和memory的占用逐渐升高>8.训练过程中Cache和Memory的占用逐渐升高<a hidden class=anchor aria-hidden=true href=#8训练过程中cache和memory的占用逐渐升高>#</a></h2><p>主要的体现是：<strong>逐渐升高</strong>这一点，而不是稳定的情况；</p><p>有点玄学，但是在这种情况下，我们在每个iteration结束的时候使用清楚显存的函数，竟然就能进行控制了，虽然我不知道为啥清楚显存的函数会顺便连内存中的cache也一起清除了，但是就是，学。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=9梯度爆炸问题算法没有学习效果>9.梯度爆炸问题，算法没有学习效果<a hidden class=anchor aria-hidden=true href=#9梯度爆炸问题算法没有学习效果>#</a></h2><p>梯度爆炸问题，分析可能出现存在的问题：</p><ul><li>某一部分的学习参数可能的lr过高，权重过高，导致误差快速传播。</li><li>问题的复杂度过高，算法overpower了把。</li></ul><p>针对于第一点的话，我们参考工程笔记中的学习率调整策略即可。</p><p>如果是问题的复杂度过高，那么可能是问题对于我们的模型来说已经overpower的，我们可能需要去加深网络的层数，或者对网络进行进一步的设计和对数据的分析问题。</p><h2 id=10类型转换问题汇总>10.类型转换问题汇总<a hidden class=anchor aria-hidden=true href=#10类型转换问题汇总>#</a></h2><ol><li><p>比如<code>scatter_</code>需要将数据从int32的格式转换成int64，我们要掌握一下在Pytorch中进行数据类型转换的技巧。</p></li><li><p><strong>Expected object of scalar type Float but got scalar type Double for argument #2 &rsquo;target&rsquo;</strong> 数据类型不匹配，一个是np.float32,另一个是64
参考解决方案：<a href=https://stackoverflow.com/questions/56741087/how-to-fix-runtimeerror-expected-object-of-scalar-type-float-but-got-scalar-typ target=_blank rel=noopener>重要</a></p></li><li><p><strong>Expected object of scalar type Long but got scalar type Float for argument</strong>
希望得到的是Long型标量数据，但是得到了Float型的数据（实际上可能是我们进行测试的时候使用了小数带来的，但是我们也能将其转化就是了）</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>Longtensor</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>type</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>longtensor</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.DoubleTensor) should be the same</strong>
<strong>RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same</strong>问题实际上都是和权重的数据类型不匹配，需要将字节型或者是FLoat型向Weight的数据类型转换，但是可能这里的问题实际上出现在就是我们导入的数据类型是不正确的。还是使用<code>type()</code>命令来进行数据类型的转换，但是关键还是：<strong>检查输入数据的类型以及数值范围，同时看看在进行dataloader的时候有没有指定to_tensor的变换等等</strong></p></li></ol><p><a href=https://www.jianshu.com/p/75dff8e7ed18 target=_blank rel=noopener>参考资料链接</a></p><p><strong>进行数据转换的几种方式</strong></p><ol><li><p>使用函数<code>tensor1.type_as(tensor2)</code>将1的数据类型转换成2的数据类型。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tensor_1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tensor_2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>IntTensor</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>tensor_1</span> <span class=o>=</span> <span class=n>tensor_1</span><span class=o>.</span><span class=n>type_as</span><span class=p>(</span><span class=n>tensor_2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><code>tensor.type(torch.IntTensor)</code></p></li><li><p><code>tensor.long()</code>,<code>tensor.char()</code>,<code>tensor.int()</code>,<code>tensor.byte()</code>,<code>tensor.double()</code></p></li><li><p><code>tenosr.to(torch.long)</code></p></li></ol><h2 id=11数据维度不对应问题汇总>11.数据维度不对应问题汇总<a hidden class=anchor aria-hidden=true href=#11数据维度不对应问题汇总>#</a></h2><ol><li><p><strong>multi-target not supported at</strong>问题实际上可以翻译成：维度上和交叉熵损失函数的需求不对应。在使用交叉熵损失函数的时候，target的形状应该是和label的形状一致或者是只有batchsize这一个维度的。如果target是这样的【batchszie，1】就会出现上述的错误</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>使用squeeze</span><span class=err>（）</span><span class=n>函数降低维度</span>
</span></span></code></pre></td></tr></table></div></div></li></ol><h2 id=12取出具体数值时候的问题>12.取出具体数值时候的问题<a hidden class=anchor aria-hidden=true href=#12取出具体数值时候的问题>#</a></h2><ol><li>**RuntimeError: Can&rsquo;t call numpy() on Variable that requires grad. Use var.detach().numpy()**对于输出的结果要转换成具体的数值的时候，如果我们后续还需要这个数值的梯度，就不能转换到<code>cpu</code>后再转换到<code>numpy</code>,就好比说，我们要取出Loss的时候，我们可以直接使用item()取出具体的数值，而不需要转到CPU<a href=#>上</a></li></ol><h2 id=13cpu占用99>13.CPU占用99%<a hidden class=anchor aria-hidden=true href=#13cpu占用99>#</a></h2><p>问题描述：使用torch自带的dataset中的cifar10的时候，在每个epoch结束的时候，CPU占用率高达99%，并不随着num_workder而改变，问题可能由于pytorch开辟了太多的线程</p><p><a href=https://blog.csdn.net/stay_zezo/article/details/107809409 target=_blank rel=noopener>windows10下pytorch的GPU利用率低，占用率低_stay_zezo的博客-CSDN博客</a></p><p>可能是由于GPU运算太快了，启用了多线程进行加载数据，这种时候启用<code>pin_memory=true</code> 能起到一定的作用把，加快一点数据读取。</p><p>最终解决方案 ：<code>pin-memory=false</code> 反正原因很神奇，但是最终就是因为这个解决的，可能是因为memory超了，所以每次都需要重新empty_cache 重新装进页，所以反而加重了CPU的负担</p><h2 id=14-预测值全为0模型收敛到奇怪的地方损失保持一致全均等>14. 预测值全为0，模型收敛到奇怪的地方，损失保持一致（全均等）<a hidden class=anchor aria-hidden=true href=#14-预测值全为0模型收敛到奇怪的地方损失保持一致全均等>#</a></h2><p>这种情况通常是由于模型设计中存在一点问题：</p><p>比如这次是由于模型中fc后面添加了relu，这样导致输出的负值全被抑制了，导致学习出现了严重的错误后果。</p><h2 id=15模型部分-训练中模型准确率不上升>15.模型部分： 训练中模型准确率不上升<a hidden class=anchor aria-hidden=true href=#15模型部分-训练中模型准确率不上升>#</a></h2><p>由于框架已经验证过是可以进行正常训练的，在这种情况下出现模型的准确率不上升可能是由于模型本身设计（内部代码编写）上的问题。</p><h2 id=16-on-entry-to-sgemm-parameter-number-8-had-an-illegal-value>16. On entry to SGEMM parameter number 8 had an illegal value<a hidden class=anchor aria-hidden=true href=#16-on-entry-to-sgemm-parameter-number-8-had-an-illegal-value>#</a></h2><p>Tracing failed sanity checks!
Graphs differed across invocations!</p><p>fc的问题，输入fc和对应的网络输入层不一致，检查阶段数目和feature输出的特征维度</p><h2 id=17-cuda-error-device-side-assert-triggered-cuda-kernel-errors-might-be-asynchronously-reported-at-some-other-api-call>17. CUDA error: device-side assert triggered CUDA kernel errors might be asynchronously reported at some other API call<a hidden class=anchor aria-hidden=true href=#17-cuda-error-device-side-assert-triggered-cuda-kernel-errors-might-be-asynchronously-reported-at-some-other-api-call>#</a></h2><p>这个问题的出现的根本原因在于：</p><p>维度不匹配：标签的dimension 超出了全连接层最后输出的dimension，这一部分错误的触发，和Loss的计算，Acc的计算，有着强烈的相关关系。</p><p>为了解决这个问题，我们在训练相关的验证和训练环节，需要保持训练数据集和验证数据集在类别数目上的一致性，而在我们需要对数据集外的数据进行测试的时候，我们避免进行Loss的计算，在对Acc进行计算的时候，也尽量避免Torch中的自有库，避免产生该类的问题/</p><h2 id=runtimeerror-the-derivative-for-target-is-not-implemented>RuntimeError the derivative for target is not implemented<a hidden class=anchor aria-hidden=true href=#runtimeerror-the-derivative-for-target-is-not-implemented>#</a></h2><p>问题通常出现在损失计算的过程中，这个错误是由于我们在损失中的第二项 <code>targets</code>不应该有梯度，但是在这个地方却存在梯度导致的.</p><p>在这里我们可以通过仅仅取出 <code>tensor</code>的<code>data</code>或者使用<code>detach</code>and<code>copy</code>来进行数值的传递</p><h2 id=only-tensors-created-explicitly-by-the-user-graph-leaves-support-the-deepcopy-protocol-at-the-moment>Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment<a hidden class=anchor aria-hidden=true href=#only-tensors-created-explicitly-by-the-user-graph-leaves-support-the-deepcopy-protocol-at-the-moment>#</a></h2><p>该错误是由deepcopy和require_grad, require_fn同时构成, 如果我们对一个需要计算梯度的非叶子节点进行deepcopy就会触发这个错误。</p><p>如果我们需要对这个数据进行存储的话，我们可以执行</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>save</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>feature</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/python/>Python</a></li><li><a href=https://hugotest-phi.vercel.app/tags/pytorch/>Pytorch</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/nerualnetworktraining/><span class=title>« Prev</span><br><span>Training Strategy</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/loss-whyzero/><span class=title>Next »</span><br><span>Loss-WhyZero</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>