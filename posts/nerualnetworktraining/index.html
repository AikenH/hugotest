<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Training Strategy | aiken's blog</title>
<meta name=keywords content="Machine Learning,Pytorch,Acceleration"><meta name=description content="@Aiken 2020，
主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。
参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。
优化器
Some Material

实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：
Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。
但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。
学习率
$\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，
==Basic==

  
      
          
          学习率大
          学习率小
      
  
  
      
          学习速度
          快
          慢
      
      
          使用情景
          刚开始训练时
          一定的次数过后
      
      
          副作用
          1. Loss爆炸 2.振荡
          1.过拟合 2.收敛速度慢
      
  

学习率的基本设置

在训练过程中，一般根据训练轮数设置动态变化的学习率。

刚开始训练时：学习率以 0.01 ~ 0.001 为宜。
一定轮数过后：逐渐减缓。
接近训练结束：学习速率的衰减应该在100倍以上。

Note：
如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 微调 。
学习率变化方法
==warm up==
warm up为什么有用

warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：
这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。
而这样的跑偏对于大模型而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。


  
    
  




"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/nerualnetworktraining/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/nerualnetworktraining/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/nerualnetworktraining/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Training Strategy"><meta property="og:description" content="@Aiken 2020，
主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。
参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。
优化器 Some Material 实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：
Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。
但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。
学习率 $\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，
==Basic==
学习率大 学习率小 学习速度 快 慢 使用情景 刚开始训练时 一定的次数过后 副作用 1. Loss爆炸 2.振荡 1.过拟合 2.收敛速度慢 学习率的基本设置 在训练过程中，一般根据训练轮数设置动态变化的学习率。
刚开始训练时：学习率以 0.01 ~ 0.001 为宜。 一定轮数过后：逐渐减缓。 接近训练结束：学习速率的衰减应该在100倍以上。 Note： 如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 微调 。
学习率变化方法 ==warm up==
warm up为什么有用 warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：
这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。
而这样的跑偏对于大模型而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。 "><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-16T08:34:44+00:00"><meta property="article:modified_time" content="2021-12-16T08:34:44+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Pytorch"><meta property="article:tag" content="Acceleration"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover10.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover10.jpeg"><meta name=twitter:title content="Training Strategy"><meta name=twitter:description content="@Aiken 2020，
主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。
参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。
优化器
Some Material

实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：
Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。
但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。
学习率
$\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，
==Basic==

  
      
          
          学习率大
          学习率小
      
  
  
      
          学习速度
          快
          慢
      
      
          使用情景
          刚开始训练时
          一定的次数过后
      
      
          副作用
          1. Loss爆炸 2.振荡
          1.过拟合 2.收敛速度慢
      
  

学习率的基本设置

在训练过程中，一般根据训练轮数设置动态变化的学习率。

刚开始训练时：学习率以 0.01 ~ 0.001 为宜。
一定轮数过后：逐渐减缓。
接近训练结束：学习速率的衰减应该在100倍以上。

Note：
如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 微调 。
学习率变化方法
==warm up==
warm up为什么有用

warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：
这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。
而这样的跑偏对于大模型而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。


  
    
  




"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"Training Strategy","item":"https://hugotest-phi.vercel.app/posts/nerualnetworktraining/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Training Strategy","name":"Training Strategy","description":"@Aiken 2020，\n主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。\n参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。\n优化器 Some Material 实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：\nAdam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。\n但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。\n学习率 $\\omega^{n} \\leftarrow \\omega^{n}-\\eta \\frac{\\partial L}{\\partial \\omega^{n}}$ 其中的权重就是学习率lr，\n==Basic==\n学习率大 学习率小 学习速度 快 慢 使用情景 刚开始训练时 一定的次数过后 副作用 1. Loss爆炸 2.振荡 1.过拟合 2.收敛速度慢 学习率的基本设置 在训练过程中，一般根据训练轮数设置动态变化的学习率。\n刚开始训练时：学习率以 0.01 ~ 0.001 为宜。 一定轮数过后：逐渐减缓。 接近训练结束：学习速率的衰减应该在100倍以上。 Note： 如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 微调 。\n学习率变化方法 ==warm up==\nwarm up为什么有用 warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：\n这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。\n而这样的跑偏对于大模型而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。 ","keywords":["Machine Learning","Pytorch","Acceleration"],"articleBody":"@Aiken 2020，\n主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。\n参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。\n优化器 Some Material 实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：\nAdam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。\n但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。\n学习率 $\\omega^{n} \\leftarrow \\omega^{n}-\\eta \\frac{\\partial L}{\\partial \\omega^{n}}$ 其中的权重就是学习率lr，\n==Basic==\n学习率大 学习率小 学习速度 快 慢 使用情景 刚开始训练时 一定的次数过后 副作用 1. Loss爆炸 2.振荡 1.过拟合 2.收敛速度慢 学习率的基本设置 在训练过程中，一般根据训练轮数设置动态变化的学习率。\n刚开始训练时：学习率以 0.01 ~ 0.001 为宜。 一定轮数过后：逐渐减缓。 接近训练结束：学习速率的衰减应该在100倍以上。 Note： 如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 微调 。\n学习率变化方法 ==warm up==\nwarm up为什么有用 warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：\n这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。\n而这样的跑偏对于大模型而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # MultiStepLR without warm up scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \\ milestones=args.milestones, gamma=0.1) # warm_up_with_multistep_lr warm_up_with_multistep_lr = lambda epoch: epoch / args.warm_up_epochs if \\ epoch \u003c= args.warm_up_epochs else 0.1**len([m for m in args.milestones if m \u003c= epoch]) scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warm_up_with_multistep_lr) # warm_up_with_cosine_lr warm_up_with_cosine_lr = lambda epoch: epoch / args.warm_up_epochs if \\ epoch \u003c= args.warm_up_epochs else 0.5 *\\ ( math.cos((epoch - args.warm_up_epochs) /(args.epochs - args.warm_up_epochs) * math.pi) + 1) scheduler = torch.optim.lr_scheduler.LambdaLR( optimizer, lr_lambda=warm_up_with_cosine_lr) ==Scheduler Setting：==\n分组的学习率也能通过scheduler进行学习率的更新，可以放心使用。\n轮数减缓 指数减缓 分数减缓 step decay exponential decay 1/t1/t decay 每N轮学习率减半 学习率按训练轮数增长指数插值递减 lrt=lr0/(1+kt)，k 控制减缓幅度，t 为训练轮数 Pytorch的Scheduler pytorch中提供了很多scheduler的方法，其中用的最多的可能还是multistep，考虑到后续可能会用到基于指标调整的学习率，这里特别提一个cosine的学习率调整策略，它的学习率呈现的是一种周期变化的样子。\n==Custom Scheduler==\nPytorch为可能的自定义提供了一个方便的Scheduler接口，ReduceLROnPlateau，通过step 调用指标的变化，进行学习率的调整，极其方便。\n1 2 3 4 5 scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=False, threshold=1e-4, threshold_model='rel', cooldown=0, min_lr=1e-8) scheduler.step(acc) 基本的参数包括：\nmode 很好理解，max（acc），min（loss）值 factor 学习率下降的参数 patience 多少次没有变化就调整 cooldown 调整后多久的冷却期 threshold，threshold_model 调整我们的动态上下限 threshold (float) – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\nthreshold_mode (str) – One of rel, abs. In rel mode, dynamic_threshold = best * ( 1 + threshold ) in ‘max’ mode or best * ( 1 - threshold ) in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.\n分析学习率的大小 在训练过程中可视化Loss下降曲线是相当重要的，那么针对Loss出现异常的情况我们应该怎么样去调整使得Loss逐步趋于正常呢？\n曲线 初始时 上扬 [红线]：（直接起飞梯度爆炸） 初始 学习率过大 导致 振荡，应减小学习率，并从头开始训练 。\n曲线 初始时 强势下降 没多久 归于水平 [紫线]： Solution：后期学习率过大导致无法拟合，应减小学习率，并重新训练后几轮 。\n曲线 全程缓慢 [黄线]： Solution：初始 学习率过小 导致收敛慢，应增大学习率，并从头开始训练 。\n过拟合欠拟合现象 过拟合-\u003e各种泛化能力差的现象在这里我个人对这个现象的定义为以下的几种：\n训练阶段的准确率和验证/测试阶段的准确率相差大 训练过程和验证过程中的损失下降不一致，验证集中的准确率没有随着训练提升 典型的过拟合导致这样的现象 下面整理一下李沐对该部分的讲解 bug部分可能是由于增强做的过高或者问题太难, 但是在正常的表现下也不应该出现这种问题, 误差应该是差不多的.\n上面的这张图片也说明了, 我们模型和问题的难度是需要相互匹配的, 如果不匹配就会出现各种各样的问题, 模型的复杂度, 通常可以从可学习参数的数来进行简单的判断的.\n过拟合问题定义和分析 定义：模型对于训练集的假设过度严格，导致对训练集的数据拟合的“很好”，但是在测试验证集中效果不理想。可能会出现的典型现象如下：\n验证损失先下降后上升 训练集和测试集稳定后的准确率相差很大 下面这张图, 显示的是模型的复杂度和相应的泛化和训练误差之间的关系, 在训练的时候复杂度还是需要自我调整.\n收敛过快泛化能力差 过拟合的一种衍生问题，当模型在训练集中快速收敛，在这种情况下可能会陷入极小值，由于损失太小，模型参数难以跳出极小值点，这种情况下，如果不加以约束会影响泛化能力，可以考虑使用，\nflood 方法来设计我们的loss（效果未知，作为一种策略把，保证模型能够有一定量的损失，同时希望验证集上的损失能够下降到一个平缓的地方，来保证泛化能力） 产生的原因分析 训练数据样本单一，数据量不足 噪声干扰过大：失去了真实的输入输出之间的关系 模型的复杂度太高，足够死记硬背所有训练集的数据，导致不知道变通 数据的复杂度分析: 大部分情况下进行数据的对比还是一个比较直观的情况, 其实可以从这几个方面进行比较\n数据集的样本数, 类别 数据集的分辨率 数据的时空结构和多样性 常见的解决方式 :zap:添加正则化L1，L2（weight decay），\nweight decay等权重下降的方法，需要熟练掌握在pytorch上的设置\n:zap:降低模型的复杂度，对应模型的设计和问题的规模需要更好的分析。\n:zap:数据增强，使得数据的多样化指标进一步上升\n:zap:Dropout，Early Stop\nBatchNormalization\n集成学习方法，通过对多个模型进行集成来降低单一模型的过拟合风险\n图像增强 这里我们为图像增强另外开一个文档，图像增强的内容实际上可以考虑《数字图像处理》的这样一门课。\n自监督学习和对比学习 (qq.com) 文中提到对准确率提升最多的一些增强方式是如下的三种：\nCrop，Resize ，Flip Colour Distortion Gaussian Blur 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from torchvision import transforms # Size used in SimCLR size = 224 crop_resize_flip = transforms.Compose([transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(3/4, 4/3)), transforms.RandomHorizontalFlip(p=0.5)]) # Higher means stronger s = 1.0 # 0.8*s and 0.2*s are from the paper colour_jitter = transforms.ColorJitter(brightness=0.8*s, contrast=0.8*s, saturation=0.8*s, hue=0.2*s) colour_jitter = transforms.RandomApply([colour_jitter], p=0.8) colour_distortion = transforms.Compose([colour_jitter, transforms.RandomGrayscale(p=0.2)]) kernel_size = int(0.1*size) # The size of the kernel must be odd kernel_size = kernel_size if kernel_size%2 == 1 else kernel_size+1 gaussian_blur = transforms.GaussianBlur(kernel_size, sigma=(0.1, 2.0)) gaussian_blur = transforms.RandomApply([gaussian_blur], p=0.5) augment = transforms.Compose([crop_resize_flip, colour_distortion, gaussian_blur]) 早停法 MicroSoft Ai 教程 ES 因为准确率都不再提高了，损失值反而上升了，再继续训练也是无益的，只会浪费训练的时间。那么该做法的一个重点便是怎样才认为验证集不再提高了呢？并不是说准确率一降下来便认为不再提高了，因为可能在这个Epoch上，准确率降低了，但是随后的Epoch准确率又升高了，所以不能根据一两次的连续降低就判断不再提高。\n对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降（Gradient descent）学习算法。Early stopping便是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。\n更好的一个方式应该是使用一个类来进行计数\n1 2 3 4 5 6 7 8 9 10 class TrainingTrace(): def __init__(self, need_earlystop=False, patience=10, mode='max'): self.early_stop = need_earlystop self.patience = patience self.patience_count = 0 self.last_vid_metrric = float('inf') if model =='min' else float('-inf') self.compare = new_min if model == 'min' else new_max def step(self, value): 在得到早停的迭代次数和权重矩阵参数后，后续有几种方法可以选择。\n彻底停止 就是啥也不做了，最多再重复几次早停的试验，看看是不是稳定，然后就使用做为训练结果。\n再次训练 由于第一次早停是通过验证集计算loss值来实现的，所以这次不再分训练集和验证集，记住了早停时的迭代次数，可以重新初始化权重矩阵参数，使用所有数据再次训练，然后到达第一次的时停止。\n但是由于样本多了，更新批次也会变多，所以可以比较两种策略：\n总迭代次数epoch保持不变 2) 总更新梯度的次数保持不变 优点：使用更多的样本可以达到更好的泛化能力。\n缺点：需要重新花时间训练。\n继续训练 得到后，用全部训练数据（不再分训练集和验证集），在此基础上继续训练若干轮，并且继续用以前的验证集来监控损失函数值，如果能得到比以前更低的损失值，将会是比较理想的情况。\n优点：可以避免重新训练的成本。\n缺点：有可能不能达到目的，损失值降不到理想位置，从而不能终止训练。\n效率优化 and there are some tips in this article , we should read and learn about it\n这一部分希望通过trick或者对应的一些代码技巧，优化训练过程中带来的资源占用和损耗，进一步提升训练时效性和资源上的有效利用\n1 2 3 4 5 6 7 # making relu inplace will save memory def inplace_relu(m): classname = m.__class__.__name__ if classname.find('ReLU') != -1: m.inplace=True # we need to learn this function model.apply(inplace_relu) relu(inplace = True)\nrapidAI Thanks to Nvidia, we could using np, spicy, pandas, sklearn on CUDA, which is much more faster. Achieve this by those repo: cuml for sklearn, cupy for numpy and spicy, cudf for dataframe and so on.\n借助这几个仓库的文档, 我们可以学习如何调用这些库去加速和实现我们的代码.\n在这里要注意的是, 使用这几个仓库的同时会引入更多的数据类型, 以及设备存储情况, 我们要在必要的时候对数据的存储位置进行分析和迁移.\n过于频繁的数据移动可能反而会减慢运行速度, 但是如果是后续不需要的数据我们可以进行迁移.\nInstall\n如果版本和torch的匹配(old version) 10.2 可以通过以下的命令安装cuml, 但是要注意panda版本 == 1.3.0, 首先对panda版本进行修改, 这种时候可能使用pip结合conda是一个更好的选择 如果版本不匹配, 我们可以首先配置rapidai的环境, 在安装pytorch即可, 或者使用nvidia发布的相同cuda版本的pytorch. torch.Cuda.AMP 使用Torch自带的AMP取代APEX的AMP进行优化，在\u003e=1.6的情况下，Torch已经自动支持了AMP混合, 而且事实证明在大多数情况下, Torch对amp的支持相比APEX来说要更加稳定和性能友好。\n使用方法： 较为简单，只需要在训练的主流程中进行如下的嵌入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from torch.cuda.amp import autocast, GradScaler # 在训练最开始的阶段实例化一个GradScaler对象 scaler = GradScaler() for i in epochs: for j in iterators: ... # model and loss with autocast(): out = model(input) loss = loss_fn(output, target) # and change the update and backward phas # 放大loss scaler.scale(loss).backward() # 对inf和nan进行判断，没有问题的话就进行step scaler.step(optimizer) # 是否对scaler进行更新 scaler.update() APEX_显存优化 this session is write for the nvidia module APEX which can save a lot of memory and accelerate the training speed. we should learn how to use it .\n通过APEX好像能优化接近50%的显存，而且在修改原框架代码中的要求很小，所以在这里有必要通过APEX去优化我们的框架\n理论参考：基于Apex的混合精度加速 ；\n其中opt_level分别表示：O0纯FP32，O1混合精度训练，O2几乎FP16除了BN，O3纯FP16很不稳定，但是速度最快\n安装：\n验证cuda版本，验证torch的cuda版本\n1 2 3 4 5 nvcc -V # nvcc 很可能会找不到命令，去如下路径搜索是否cuda正确安装 cd /usr/local/cuda*/bin # 其中若有nvcc命令的话可以直接执行 nvcc -V 1 2 import torch print(torch.version.cuda) 安装apex\n1 2 3 git clone https://github.com/NVIDIA/apex cd apex pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./ import验证安装成功\n1 import apex 使用：\n参考官方示例，我们可以知道APEX的使用场景主要集中在几个部分：\nmodel,optimizer,loss upgrade and parallel\n故而我们对原始代码修改或添加如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from apex import amp from apex.parallel import DistributedDataParallel model = resnet() optimizer = torch.optim.SGD(model.parameters(),lr=1e-3) # MODEL PART: after model and optimizer design model, optimizer = amp.initialize(model, optimizer, opt_level = \"O1\") # DISTRIBUTION PART: # replace nn.parallel.DistributedDataParallel() model = DistributedDataParallel(model) # LOSS PART: # replace the loss BP process # loss.backward() with amp.scale_loss(loss, optimizer) as scaled_loss: scaled_loss.backward() optimizer.step() 此外，如果我们希望使用APEX在训练过程中执行resume的话，我们还需要对代码做如下的添加\nNote that we recommend restoring the model using the same opt_level. Also note that we recommend calling the load_state_dict methods after amp.initialize.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Save checkpoint checkpoint = { 'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'amp': amp.state_dict() } torch.save(checkpoint, 'amp_checkpoint.pt') ... # Restore model = ... optimizer = ... checkpoint = torch.load('amp_checkpoint.pt') model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level) model.load_state_dict(checkpoint['model']) optimizer.load_state_dict(checkpoint['optimizer']) amp.load_state_dict(checkpoint['amp']) # Continue training ... 安装过程中遇到了很多的问题：\nBuild error “fatal error: ATen/cuda/CUDAGraphsUtils.cuh: No such file or directory” · Issue #1043 · NVIDIA/apex (github.com) 1 2 # rollback apex to the previous commit git reset --hard 3fe10b5597ba14a748ebb271a6ab97c09c5701ac cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n1 2 pip install -U cpython # this method is not useful command ‘gcc’ failed with exit status 1\n1 git checkout f3a960f80244cf9e80558ab30f7f7e8cbf03c0a0 限制网络的输出范围 实际上，这一部分的应用就属于激活函数的数学理念问题了，我们倘若需要将网络的输出限制在一定的范围内，除了自己编写相关的数据处理手段之外，激活函数实际上有一部分原因就是为了这点设置的。\n神经网络基于对非线性运算的需要，引入了激活函数，强化了网络的学习能力； 同时神经网络对于输出有所要求（很多时候是以一种概率表达的方式输出的）所以就会需要softmax（0，1同时sum==1）之类的函数，可以将分类器的原始输出映射为概率。 Sigmoid tanh之类的将输出限制在（0，1），但是并没有对加和有要求，这里可以做一个区分https://www.cnblogs.com/jins-note/p/12528412.html区分sigmoid（多分类）和Softmax（单分类） Softmax和tanh可能会出现梯度消失的问题，ReLU将输出限制在（0，1） 一部分激活函数的特点 所以很显然，我们可以通过对于相应的激活函数的应用，来限制我们的网络输出范围。\n","wordCount":"1045","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover10.jpeg","datePublished":"2021-12-16T08:34:44Z","dateModified":"2021-12-16T08:34:44Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/nerualnetworktraining/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Training Strategy</h1><div class=post-meta><span title='2021-12-16 08:34:44 +0000 UTC'>December 16, 2021</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1045 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/machine-learning> Machine Learning</a>&nbsp;·&nbsp;<a href=/tags/pytorch> Pytorch</a>&nbsp;·&nbsp;<a href=/tags/acceleration> Acceleration</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/NerualNetworkTraining.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover10.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%bc%98%e5%8c%96%e5%99%a8 aria-label=优化器>优化器</a></li><li><a href=#%e5%ad%a6%e4%b9%a0%e7%8e%87 aria-label=学习率>学习率</a><ul class=header-level-2><li><a href=#%e5%ad%a6%e4%b9%a0%e7%8e%87%e7%9a%84%e5%9f%ba%e6%9c%ac%e8%ae%be%e7%bd%ae aria-label=学习率的基本设置>学习率的基本设置</a></li><li><a href=#%e5%ad%a6%e4%b9%a0%e7%8e%87%e5%8f%98%e5%8c%96%e6%96%b9%e6%b3%95 aria-label=学习率变化方法>学习率变化方法</a></li><li><a href=#%e5%88%86%e6%9e%90%e5%ad%a6%e4%b9%a0%e7%8e%87%e7%9a%84%e5%a4%a7%e5%b0%8f aria-label=分析学习率的大小>分析学习率的大小</a></li></ul></li><li><a href=#%e8%bf%87%e6%8b%9f%e5%90%88%e6%ac%a0%e6%8b%9f%e5%90%88%e7%8e%b0%e8%b1%a1 aria-label=过拟合欠拟合现象>过拟合欠拟合现象</a><ul class=header-level-2><li><a href=#%e8%bf%87%e6%8b%9f%e5%90%88%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89%e5%92%8c%e5%88%86%e6%9e%90 aria-label=过拟合问题定义和分析>过拟合问题定义和分析</a></li><li><a href=#%e6%94%b6%e6%95%9b%e8%bf%87%e5%bf%ab%e6%b3%9b%e5%8c%96%e8%83%bd%e5%8a%9b%e5%b7%ae aria-label=收敛过快泛化能力差>收敛过快泛化能力差</a></li><li><a href=#%e4%ba%a7%e7%94%9f%e7%9a%84%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90 aria-label=产生的原因分析>产生的原因分析</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e7%9a%84%e5%a4%8d%e6%9d%82%e5%ba%a6%e5%88%86%e6%9e%90 aria-label=数据的复杂度分析:>数据的复杂度分析:</a></li><li><a href=#%e5%b8%b8%e8%a7%81%e7%9a%84%e8%a7%a3%e5%86%b3%e6%96%b9%e5%bc%8f aria-label=常见的解决方式>常见的解决方式</a></li><li><a href=#%e5%9b%be%e5%83%8f%e5%a2%9e%e5%bc%ba aria-label=图像增强>图像增强</a></li></ul></li><li><a href=#%e6%97%a9%e5%81%9c%e6%b3%95 aria-label=早停法>早停法</a></li><li><a href=#%e6%95%88%e7%8e%87%e4%bc%98%e5%8c%96 aria-label=效率优化>效率优化</a><ul class=header-level-2><li><a href=#rapidai aria-label=rapidAI>rapidAI</a></li><li><a href=#torchcudaamp aria-label=torch.Cuda.AMP>torch.Cuda.AMP</a></li><li><a href=#apex_%e6%98%be%e5%ad%98%e4%bc%98%e5%8c%96 aria-label=APEX_显存优化>APEX_显存优化</a></li></ul></li><li><a href=#%e9%99%90%e5%88%b6%e7%bd%91%e7%bb%9c%e7%9a%84%e8%be%93%e5%87%ba%e8%8c%83%e5%9b%b4 aria-label=限制网络的输出范围>限制网络的输出范围</a></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>@Aiken 2020，</p><p>主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。</p><p>参数调整过程中最重要的就是优化器（优化或者说是下降算法）和学习率（优化算法的核心参数），此外像是数据增强策略还是Normalization策略，都能极大的影响一个模型的好坏。</p><h2 id=优化器>优化器<a hidden class=anchor aria-hidden=true href=#优化器>#</a></h2><p><a href=https://wizardforcel.gitbooks.io/learn-dl-with-pytorch-liaoxingyu/content/ target=_blank rel=noopener>Some Material</a>
实际上虽然有很多的优化算法，但是到最后最常用的还是 SGD+Mon 和 Adam两种：</p><p>Adam主要的有事在于自适应学习率，他对我们设计的学习率实际上没有那么敏感，但是在具体实验中往往不会有调的好的SGD那么好，只是在SGD的参数调整中会比较费劲。</p><p>但是有了根据patient调整lr的scheduler后，我们基本上可以使用SGD做一个较为简单的调整，只要设计好初始的lr的实验以及用来调整学习率的参数值。</p><h2 id=学习率>学习率<a hidden class=anchor aria-hidden=true href=#学习率>#</a></h2><p>$\omega^{n} \leftarrow \omega^{n}-\eta \frac{\partial L}{\partial \omega^{n}}$ 其中的权重就是学习率lr，</p><p>==Basic==</p><table><thead><tr><th></th><th>学习率大</th><th>学习率小</th></tr></thead><tbody><tr><td>学习速度</td><td>快</td><td>慢</td></tr><tr><td>使用情景</td><td>刚开始训练时</td><td>一定的次数过后</td></tr><tr><td>副作用</td><td>1. Loss爆炸 2.振荡</td><td>1.过拟合 2.收敛速度慢</td></tr></tbody></table><h3 id=学习率的基本设置>学习率的基本设置<a hidden class=anchor aria-hidden=true href=#学习率的基本设置>#</a></h3><p>在训练过程中，一般根据训练轮数设置动态变化的学习率。</p><ul><li>刚开始训练时：学习率以 0.01 ~ 0.001 为宜。</li><li>一定轮数过后：逐渐减缓。</li><li>接近训练结束：学习速率的衰减应该在100倍以上。</li></ul><p><strong>Note：</strong>
如果是 <strong>迁移学习</strong> ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4) 在新数据上进行 <strong>微调</strong> 。</p><h3 id=学习率变化方法>学习率变化方法<a hidden class=anchor aria-hidden=true href=#学习率变化方法>#</a></h3><p>==warm up==</p><p><a href=https://www.zhihu.com/question/338066667/answer/771252708 target=_blank rel=noopener>warm up为什么有用</a></p><p>warm up衰减策略与上述的策略有些不同，它是先从一个极低的学习率开始增加，增加到某一个值后再逐渐减少, 这点上倒是和Cosine Anneal LR有一定的相似之处，将这两种结合起来是一种常见的训练策略：</p><p>这样训练模型更加稳定，因为在刚开始时模型的参数都是随机初始化的，此时如果学习率应该取小一点，这样就不会使模型一下子跑偏。</p><p>而这样的跑偏对于<strong>大模型</strong>而言，可能是导致很严重的影响，后面收敛了也可能不会达到最佳的效果，一开始的跑偏，可能会造成准确率在后面的严重结果。<div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211216001833.png><img alt=warmup loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211216001833.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211216001833.png style="display:block;margin:0 auto" alt=warmup></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># MultiStepLR without warm up</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>MultiStepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> \
</span></span><span class=line><span class=cl>								<span class=n>milestones</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>milestones</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># warm_up_with_multistep_lr</span>
</span></span><span class=line><span class=cl>    <span class=n>warm_up_with_multistep_lr</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>epoch</span><span class=p>:</span> <span class=n>epoch</span> <span class=o>/</span> <span class=n>args</span><span class=o>.</span><span class=n>warm_up_epochs</span> <span class=k>if</span> \
</span></span><span class=line><span class=cl>	<span class=n>epoch</span> <span class=o>&lt;=</span> <span class=n>args</span><span class=o>.</span><span class=n>warm_up_epochs</span> <span class=k>else</span> <span class=mf>0.1</span><span class=o>**</span><span class=nb>len</span><span class=p>([</span><span class=n>m</span> <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=n>args</span><span class=o>.</span><span class=n>milestones</span> <span class=k>if</span> <span class=n>m</span> <span class=o>&lt;=</span> <span class=n>epoch</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>LambdaLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>												  <span class=n>lr_lambda</span><span class=o>=</span><span class=n>warm_up_with_multistep_lr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># warm_up_with_cosine_lr</span>
</span></span><span class=line><span class=cl>    <span class=n>warm_up_with_cosine_lr</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>epoch</span><span class=p>:</span> <span class=n>epoch</span> <span class=o>/</span> <span class=n>args</span><span class=o>.</span><span class=n>warm_up_epochs</span> <span class=k>if</span> \
</span></span><span class=line><span class=cl>	<span class=n>epoch</span> <span class=o>&lt;=</span> <span class=n>args</span><span class=o>.</span><span class=n>warm_up_epochs</span> <span class=k>else</span> <span class=mf>0.5</span> <span class=o>*</span>\
</span></span><span class=line><span class=cl>	<span class=p>(</span> <span class=n>math</span><span class=o>.</span><span class=n>cos</span><span class=p>((</span><span class=n>epoch</span> <span class=o>-</span> <span class=n>args</span><span class=o>.</span><span class=n>warm_up_epochs</span><span class=p>)</span> <span class=o>/</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>epochs</span> <span class=o>-</span> <span class=n>args</span><span class=o>.</span><span class=n>warm_up_epochs</span><span class=p>)</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>pi</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>LambdaLR</span><span class=p>(</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>lr_lambda</span><span class=o>=</span><span class=n>warm_up_with_cosine_lr</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>==Scheduler Setting：==</p><p>分组的学习率也能通过scheduler进行学习率的更新，可以放心使用。</p><table><thead><tr><th>轮数减缓</th><th>指数减缓</th><th>分数减缓</th></tr></thead><tbody><tr><td>step decay</td><td>exponential decay</td><td>1/t1/t decay</td></tr><tr><td>每N轮学习率减半</td><td>学习率按训练轮数增长指数插值递减</td><td>lrt=lr0/(1+kt)，k 控制减缓幅度，t 为训练轮数</td></tr></tbody></table><p><a href=https://blog.csdn.net/weixin_42662358/article/details/93732852 target=_blank rel=noopener>Pytorch的Scheduler</a>
pytorch中提供了很多scheduler的方法，其中用的最多的可能还是<code>multistep</code>，考虑到后续可能会用到基于指标调整的学习率，这里特别提一个<code>cosine</code>的学习率调整策略，它的学习率呈现的是一种周期变化的样子。</p><p>==Custom Scheduler==</p><p>Pytorch为可能的自定义提供了一个方便的Scheduler接口，<code>ReduceLROnPlateau</code>，通过<code>step</code> 调用指标的变化，进行学习率的调整，极其方便。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>ReduceLROnPlateau</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;max&#39;</span><span class=p>,</span>  
</span></span><span class=line><span class=cl>			<span class=n>factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>patience</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>			<span class=n>threshold_model</span><span class=o>=</span><span class=s1>&#39;rel&#39;</span><span class=p>,</span> <span class=n>cooldown</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>min_lr</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>acc</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>基本的参数包括：</p><ul><li>mode 很好理解，max（acc），min（loss）值</li><li>factor 学习率下降的参数</li><li>patience 多少次没有变化就调整</li><li>cooldown 调整后多久的冷却期</li><li>threshold，threshold_model 调整我们的动态上下限</li></ul><p><strong>threshold (float)</strong> – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.</p><p><strong>threshold_mode (str)</strong> – One of rel, abs. In rel mode, <code>dynamic_threshold = best * ( 1 + threshold )</code> in ‘max’ mode or <code>best * ( 1 - threshold )</code> in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.</p><h3 id=分析学习率的大小>分析学习率的大小<a hidden class=anchor aria-hidden=true href=#分析学习率的大小>#</a></h3><p>在训练过程中可视化Loss下降曲线是相当重要的，那么针对Loss出现异常的情况我们应该怎么样去调整使得Loss逐步趋于正常呢？</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911210315.png><img alt=image-20201120105459815 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911210315.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911210315.png style="display:block;margin:0 auto" alt=image-20201120105459815></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>曲线 初始时 上扬 [红线]：（直接起飞梯度爆炸）
初始 <strong>学习率过大</strong> 导致 振荡，应减小学习率，并从头开始训练 。</p><p>曲线 初始时 强势下降 没多久 归于水平 [紫线]：
Solution：后期<strong>学习率过大</strong>导致无法拟合，应减小学习率，并重新训练后几轮 。</p><p>曲线 全程缓慢 [黄线]：
Solution：初始 <strong>学习率过小</strong> 导致收敛慢，应增大学习率，并从头开始训练 。</p><h2 id=过拟合欠拟合现象>过拟合欠拟合现象<a hidden class=anchor aria-hidden=true href=#过拟合欠拟合现象>#</a></h2><p>过拟合->各种泛化能力差的现象在这里我个人对这个现象的定义为以下的几种：</p><ul><li>训练阶段的准确率和验证/测试阶段的准确率相差大</li><li>训练过程和验证过程中的损失下降不一致，验证集中的准确率没有随着训练提升</li><li>典型的过拟合导致这样的现象</li></ul><p>下面整理一下<a href="https://www.bilibili.com/video/BV1ah411t7Pp?spm_id_from=333.999.0.0" target=_blank rel=noopener>李沐对该部分的讲解</a></p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114181130.png><img alt=image-20211114181128291 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114181130.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114181130.png style="display:block;margin:0 auto" alt=image-20211114181128291></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>bug部分可能是由于增强做的过高或者问题太难, 但是在正常的表现下也不应该出现这种问题, 误差应该是差不多的.</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114181412.png><img alt=image-20211114181411611 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114181412.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114181412.png style="display:block;margin:0 auto" alt=image-20211114181411611></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p>上面的这张图片也说明了, 我们模型和问题的难度是需要相互匹配的, 如果不匹配就会出现各种各样的问题, 模型的复杂度, 通常可以从可学习参数的数来进行简单的判断的.</p><h3 id=过拟合问题定义和分析>过拟合问题定义和分析<a hidden class=anchor aria-hidden=true href=#过拟合问题定义和分析>#</a></h3><p>定义：模型对于训练集的假设过度严格，导致对训练集的数据拟合的“很好”，但是在测试验证集中效果不理想。可能会出现的典型现象如下：</p><ol><li>验证损失先下降后上升</li><li>训练集和测试集稳定后的准确率相差很大</li></ol><p>下面这张图, 显示的是模型的复杂度和相应的泛化和训练误差之间的关系, 在训练的时候复杂度还是需要自我调整.</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211026161951.png><img alt=image-20211026161949994 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211026161951.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20211026161951.png style="display:block;margin:0 auto" alt=image-20211026161949994></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114182734.png><img alt=image-20211114182733584 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114182734.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211114182734.png style="display:block;margin:0 auto" alt=image-20211114182733584></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h3 id=收敛过快泛化能力差>收敛过快泛化能力差<a hidden class=anchor aria-hidden=true href=#收敛过快泛化能力差>#</a></h3><p>过拟合的一种衍生问题，当模型在训练集中快速收敛，在这种情况下可能会陷入极小值，由于损失太小，模型参数难以跳出极小值点，这种情况下，如果不加以约束会影响泛化能力，可以考虑使用，</p><ul><li><code>flood</code> 方法来设计我们的loss（效果未知，作为一种策略把，保证模型能够有一定量的损失，同时希望验证集上的损失能够下降到一个平缓的地方，来保证泛化能力）</li></ul><h3 id=产生的原因分析>产生的原因分析<a hidden class=anchor aria-hidden=true href=#产生的原因分析>#</a></h3><ol><li>训练数据样本单一，数据量不足</li><li>噪声干扰过大：失去了真实的输入输出之间的关系</li><li>模型的复杂度太高，足够死记硬背所有训练集的数据，导致不知道变通</li></ol><h3 id=数据的复杂度分析>数据的复杂度分析:<a hidden class=anchor aria-hidden=true href=#数据的复杂度分析>#</a></h3><p>大部分情况下进行数据的对比还是一个比较直观的情况, 其实可以从这几个方面进行比较</p><ul><li>数据集的样本数, 类别</li><li>数据集的分辨率</li><li>数据的时空结构和多样性</li></ul><h3 id=常见的解决方式>常见的解决方式<a hidden class=anchor aria-hidden=true href=#常见的解决方式>#</a></h3><ol><li><p>:zap:添加正则化L1，L2（weight decay），</p><p>weight decay等权重下降的方法，需要熟练掌握在pytorch上的设置</p></li><li><p>:zap:降低模型的复杂度，对应模型的设计和问题的规模需要更好的分析。</p></li><li><p>:zap:数据增强，使得数据的多样化指标进一步上升</p></li><li><p>:zap:Dropout，Early Stop</p></li><li><p>BatchNormalization</p></li><li><p>集成学习方法，通过对多个模型进行集成来降低单一模型的过拟合风险</p></li></ol><h3 id=图像增强>图像增强<a hidden class=anchor aria-hidden=true href=#图像增强>#</a></h3><p>这里我们为图像增强另外开一个文档，图像增强的内容实际上可以考虑《数字图像处理》的这样一门课。</p><p><a href=https://mp.weixin.qq.com/s/tV5eSx73fzMovq0d7Jvu9Q target=_blank rel=noopener>自监督学习和对比学习 (qq.com)</a></p><p>文中提到对准确率提升最多的一些增强方式是如下的三种：</p><ul><li>Crop，Resize ，Flip</li><li>Colour Distortion</li><li>Gaussian Blur</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision</span> <span class=kn>import</span> <span class=n>transforms</span>
</span></span><span class=line><span class=cl><span class=c1># Size used in SimCLR</span>
</span></span><span class=line><span class=cl><span class=n>size</span> <span class=o>=</span> <span class=mi>224</span>
</span></span><span class=line><span class=cl><span class=n>crop_resize_flip</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span><span class=n>transforms</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=p>(</span><span class=mf>0.08</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>),</span> <span class=n>ratio</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=o>/</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=o>/</span><span class=mi>3</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>                                       <span class=n>transforms</span><span class=o>.</span><span class=n>RandomHorizontalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Higher means stronger </span>
</span></span><span class=line><span class=cl><span class=n>s</span> <span class=o>=</span> <span class=mf>1.0</span>
</span></span><span class=line><span class=cl><span class=c1># 0.8*s and 0.2*s are from the paper</span>
</span></span><span class=line><span class=cl><span class=n>colour_jitter</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>ColorJitter</span><span class=p>(</span><span class=n>brightness</span><span class=o>=</span><span class=mf>0.8</span><span class=o>*</span><span class=n>s</span><span class=p>,</span> <span class=n>contrast</span><span class=o>=</span><span class=mf>0.8</span><span class=o>*</span><span class=n>s</span><span class=p>,</span> <span class=n>saturation</span><span class=o>=</span><span class=mf>0.8</span><span class=o>*</span><span class=n>s</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=mf>0.2</span><span class=o>*</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>colour_jitter</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>RandomApply</span><span class=p>([</span><span class=n>colour_jitter</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>colour_distortion</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span><span class=n>colour_jitter</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                        <span class=n>transforms</span><span class=o>.</span><span class=n>RandomGrayscale</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kernel_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=mf>0.1</span><span class=o>*</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># The size of the kernel must be odd</span>
</span></span><span class=line><span class=cl><span class=n>kernel_size</span> <span class=o>=</span> <span class=n>kernel_size</span> <span class=k>if</span> <span class=n>kernel_size</span><span class=o>%</span><span class=mi>2</span> <span class=o>==</span> <span class=mi>1</span> <span class=k>else</span> <span class=n>kernel_size</span><span class=o>+</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>gaussian_blur</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>GaussianBlur</span><span class=p>(</span><span class=n>kernel_size</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>gaussian_blur</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>RandomApply</span><span class=p>([</span><span class=n>gaussian_blur</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                                       
</span></span><span class=line><span class=cl><span class=n>augment</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span><span class=n>crop_resize_flip</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>colour_distortion</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>gaussian_blur</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211118153623.png><img alt=image-20211118153622239 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211118153623.png class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/3070imgs/20211118153623.png style="display:block;margin:0 auto" alt=image-20211118153622239></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h2 id=早停法>早停法<a hidden class=anchor aria-hidden=true href=#早停法>#</a></h2><p><a href=https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/en-us/Step7%20-%20DNN/16.4-%E6%97%A9%E5%81%9C%E6%B3%95.html target=_blank rel=noopener>MicroSoft Ai 教程 ES</a></p><p>因为准确率都不再提高了，损失值反而上升了，再继续训练也是无益的，只会浪费训练的时间。那么该做法的一个重点便是怎样才认为验证集不再提高了呢？并不是说准确率一降下来便认为不再提高了，因为可能在这个Epoch上，准确率降低了，但是随后的Epoch准确率又升高了，所以不能根据一两次的连续降低就判断不再提高。</p><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降（Gradient descent）学习算法。Early stopping便是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。</p><p>更好的一个方式应该是使用一个类来进行计数</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>TrainingTrace</span><span class=p>():</span>
</span></span><span class=line><span class=cl>	<span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>need_earlystop</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>patience</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;max&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=bp>self</span><span class=o>.</span><span class=n>early_stop</span> <span class=o>=</span> <span class=n>need_earlystop</span>
</span></span><span class=line><span class=cl>		<span class=bp>self</span><span class=o>.</span><span class=n>patience</span> <span class=o>=</span> <span class=n>patience</span>
</span></span><span class=line><span class=cl>		<span class=bp>self</span><span class=o>.</span><span class=n>patience_count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>		<span class=bp>self</span><span class=o>.</span><span class=n>last_vid_metrric</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>)</span> <span class=k>if</span> <span class=n>model</span> <span class=o>==</span><span class=s1>&#39;min&#39;</span> <span class=k>else</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=bp>self</span><span class=o>.</span><span class=n>compare</span> <span class=o>=</span> <span class=n>new_min</span> <span class=k>if</span> <span class=n>model</span> <span class=o>==</span> <span class=s1>&#39;min&#39;</span> <span class=k>else</span> <span class=n>new_max</span>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	<span class=k>def</span> <span class=nf>step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>value</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		
</span></span></code></pre></td></tr></table></div></div><p>在得到早停的迭代次数和权重矩阵参数后，后续有几种方法可以选择。</p><p><strong>彻底停止</strong>
就是啥也不做了，最多再重复几次早停的试验，看看是不是稳定，然后就使用做为训练结果。</p><p><strong>再次训练</strong>
由于第一次早停是通过验证集计算loss值来实现的，所以这次不再分训练集和验证集，记住了早停时的迭代次数，可以重新初始化权重矩阵参数，使用所有数据再次训练，然后到达第一次的时停止。</p><p>但是由于样本多了，更新批次也会变多，所以可以比较两种策略：</p><ol><li>总迭代次数epoch保持不变 2) 总更新梯度的次数保持不变</li></ol><p>优点：使用更多的样本可以达到更好的泛化能力。</p><p>缺点：需要重新花时间训练。</p><p><strong>继续训练</strong>
得到后，用全部训练数据（不再分训练集和验证集），在此基础上继续训练若干轮，并且继续用以前的验证集来监控损失函数值，如果能得到比以前更低的损失值，将会是比较理想的情况。</p><p>优点：可以避免重新训练的成本。</p><p>缺点：有可能不能达到目的，损失值降不到理想位置，从而不能终止训练。</p><h2 id=效率优化>效率优化<a hidden class=anchor aria-hidden=true href=#效率优化>#</a></h2><p>and there are some tips in this <a href=https://sagivtech.com/2017/09/19/optimizing-pytorch-training-code/ target=_blank rel=noopener>article</a>
, we should read and learn about it</p><p>这一部分希望通过trick或者对应的一些代码技巧，优化训练过程中带来的资源占用和损耗，进一步提升训练时效性和资源上的有效利用</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># making relu inplace will save memory </span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>inplace_relu</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>classname</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>classname</span><span class=o>.</span><span class=n>find</span><span class=p>(</span><span class=s1>&#39;ReLU&#39;</span><span class=p>)</span> <span class=o>!=</span> <span class=o>-</span><span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>m</span><span class=o>.</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=c1># we need to learn this function</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>inplace_relu</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>relu(inplace = True)</p><h3 id=rapidai>rapidAI<a hidden class=anchor aria-hidden=true href=#rapidai>#</a></h3><p>Thanks to Nvidia, we could using np, spicy, pandas, sklearn on CUDA, which is much more faster. Achieve this by those repo: cuml for sklearn, cupy for numpy and spicy, cudf for dataframe and so on.</p><p>借助这几个仓库的文档, 我们可以学习如何调用这些库去加速和实现我们的代码.</p><p>在这里要注意的是, 使用这几个仓库的同时会<strong>引入更多的数据类型</strong>, 以及<strong>设备存储</strong>情况, 我们要在必要的时候对数据的存储位置进行<strong>分析和迁移</strong>.</p><p>过于频繁的数据移动可能反而会减慢运行速度, 但是如果是后续不需要的数据我们可以进行迁移.</p><p><strong>Install</strong></p><ol><li>如果版本和torch的匹配(old version) 10.2 可以通过以下的命令安装cuml, 但是要注意panda版本 == 1.3.0, 首先对panda版本进行修改, 这种时候可能使用pip结合conda是一个更好的选择<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell></code></pre></td></tr></table></div></div></li><li>如果版本不匹配, 我们可以首先配置rapidai的环境, 在安装pytorch即可, 或者使用nvidia发布的相同cuda版本的pytorch.</li></ol><h3 id=torchcudaamp>torch.Cuda.AMP<a hidden class=anchor aria-hidden=true href=#torchcudaamp>#</a></h3><p>使用Torch自带的AMP取代APEX的AMP进行优化，在>=1.6的情况下，Torch已经自动支持了AMP混合, 而且事实证明在大多数情况下, Torch对amp的支持相比APEX来说要更加稳定和性能友好。</p><p>使用方法：
较为简单，只需要在训练的主流程中进行如下的嵌入</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.cuda.amp</span> <span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在训练最开始的阶段实例化一个GradScaler对象</span>
</span></span><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>epochs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=n>iterators</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=o>...</span>
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		<span class=c1># model and loss</span>
</span></span><span class=line><span class=cl>		<span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>			<span class=n>out</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>			<span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fn</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		<span class=c1># and change the update and backward phas</span>
</span></span><span class=line><span class=cl>		<span class=c1># 放大loss</span>
</span></span><span class=line><span class=cl>		<span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>		<span class=c1># 对inf和nan进行判断，没有问题的话就进行step</span>
</span></span><span class=line><span class=cl>		<span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=c1># 是否对scaler进行更新</span>
</span></span><span class=line><span class=cl>		<span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		
</span></span></code></pre></td></tr></table></div></div><h3 id=apex_显存优化>APEX_显存优化<a hidden class=anchor aria-hidden=true href=#apex_显存优化>#</a></h3><p>this session is write for the nvidia module <a href=https://github.com/NVIDIA/apex target=_blank rel=noopener>APEX</a>
which can save a lot of memory and accelerate the training speed. we should learn how to use it .</p><p>通过APEX好像能优化接近50%的显存，而且在修改原框架代码中的要求很小，所以在这里有必要通过APEX去优化我们的框架</p><p>理论参考：<a href=https://zhuanlan.zhihu.com/p/79887894 target=_blank rel=noopener>基于Apex的混合精度加速</a>
；</p><p>其中<code>opt_level</code>分别表示：O0纯FP32，O1混合精度训练，O2几乎FP16除了BN，O3纯FP16很不稳定，但是速度最快</p><p><strong>安装</strong>：</p><ul><li><p>验证cuda版本，验证torch的cuda版本</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>nvcc -V
</span></span><span class=line><span class=cl><span class=c1># nvcc 很可能会找不到命令，去如下路径搜索是否cuda正确安装</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /usr/local/cuda*/bin
</span></span><span class=line><span class=cl><span class=c1># 其中若有nvcc命令的话可以直接执行</span>
</span></span><span class=line><span class=cl>nvcc -V
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span> 
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p>安装apex</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/NVIDIA/apex
</span></span><span class=line><span class=cl><span class=nb>cd</span> apex
</span></span><span class=line><span class=cl>pip install -v --no-cache-dir --global-option<span class=o>=</span><span class=s2>&#34;--cpp_ext&#34;</span> --global-option<span class=o>=</span><span class=s2>&#34;--cuda_ext&#34;</span> ./
</span></span></code></pre></td></tr></table></div></div></li><li><p>import验证安装成功</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>apex</span>
</span></span></code></pre></td></tr></table></div></div></li></ul><p><strong>使用</strong>：</p><p>参考官方示例，我们可以知道APEX的使用场景主要集中在几个部分：</p><p>model,optimizer,loss upgrade and parallel</p><p>故而我们对原始代码修改或添加如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apex</span> <span class=kn>import</span> <span class=n>amp</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apex.parallel</span> <span class=kn>import</span> <span class=n>DistributedDataParallel</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>resnet</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span><span class=n>lr</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># MODEL PART: after model and optimizer design</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span> <span class=o>=</span> <span class=n>amp</span><span class=o>.</span><span class=n>initialize</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>opt_level</span> <span class=o>=</span> <span class=s2>&#34;O1&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># DISTRIBUTION PART:</span>
</span></span><span class=line><span class=cl><span class=c1># replace nn.parallel.DistributedDataParallel()</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>DistributedDataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># LOSS PART:</span>
</span></span><span class=line><span class=cl><span class=c1># replace the loss BP process</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># loss.backward()</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>amp</span><span class=o>.</span><span class=n>scale_loss</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>)</span> <span class=k>as</span> <span class=n>scaled_loss</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>scaled_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>此外，如果我们希望使用APEX在训练过程中执行resume的话，我们还需要对代码做如下的添加</p><p>Note that we recommend restoring the model using the same <code>opt_level</code>. Also note that we recommend calling the <code>load_state_dict</code> methods after <code>amp.initialize</code>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Save checkpoint</span>
</span></span><span class=line><span class=cl><span class=n>checkpoint</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;optimizer&#39;</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;amp&#39;</span><span class=p>:</span> <span class=n>amp</span><span class=o>.</span><span class=n>state_dict</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>,</span> <span class=s1>&#39;amp_checkpoint.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Restore</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=o>...</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=o>...</span>
</span></span><span class=line><span class=cl><span class=n>checkpoint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;amp_checkpoint.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span> <span class=o>=</span> <span class=n>amp</span><span class=o>.</span><span class=n>initialize</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>opt_level</span><span class=o>=</span><span class=n>opt_level</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;model&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;optimizer&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>amp</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;amp&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Continue training</span>
</span></span><span class=line><span class=cl><span class=o>...</span>
</span></span></code></pre></td></tr></table></div></div><p>安装过程中遇到了很多的问题：</p><p><a href=https://github.com/NVIDIA/apex/issues/1043 target=_blank rel=noopener>Build error &ldquo;fatal error: ATen/cuda/CUDAGraphsUtils.cuh: No such file or directory&rdquo; · Issue #1043 · NVIDIA/apex (github.com)</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># rollback apex to the previous commit</span>
</span></span><span class=line><span class=cl>git reset --hard 3fe10b5597ba14a748ebb271a6ab97c09c5701ac
</span></span></code></pre></td></tr></table></div></div><p>cc1plus: warning: command line option &lsquo;-Wstrict-prototypes&rsquo; is valid for C/ObjC but not for C++</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install -U cpython
</span></span><span class=line><span class=cl><span class=c1># this method is not useful</span>
</span></span></code></pre></td></tr></table></div></div><p>command &lsquo;gcc&rsquo; failed with exit status 1</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git checkout f3a960f80244cf9e80558ab30f7f7e8cbf03c0a0
</span></span></code></pre></td></tr></table></div></div><h2 id=限制网络的输出范围>限制网络的输出范围<a hidden class=anchor aria-hidden=true href=#限制网络的输出范围>#</a></h2><p>实际上，这一部分的应用就属于激活函数的数学理念问题了，我们倘若需要将网络的<strong>输出限制在一定的范围</strong>内，除了<strong>自己编写相关的数据处理</strong>手段之外，<strong>激活函数</strong>实际上有一部分原因就是为了这点设置的。</p><ol><li>神经网络基于对非线性运算的需要，引入了激活函数，强化了网络的学习能力；</li><li>同时神经网络<strong>对于输出</strong>有所要求（很多时候是以一种概率表达的方式输出的）所以就会需要softmax（0，1同时<code>sum==1</code>）之类的函数，<strong>可以将分类器的原始输出映射为概率。</strong> Sigmoid tanh之类的将输出限制在（0，1），但是并没有对加和有要求，这里可以做一个区分https://www.cnblogs.com/jins-note/p/12528412.html区分sigmoid（多分类）和Softmax（单分类）</li><li>Softmax和tanh可能会出现梯度消失的问题，ReLU将输出限制在（0，1）
<a href=https://zhuanlan.zhihu.com/p/73214810 target=_blank rel=noopener>一部分激活函数的特点</a></li></ol><p>所以很显然，我们可以通过对于相应的激活函数的应用，来限制我们的网络输出范围。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/machine-learning/>Machine Learning</a></li><li><a href=https://hugotest-phi.vercel.app/tags/pytorch/>Pytorch</a></li><li><a href=https://hugotest-phi.vercel.app/tags/acceleration/>Acceleration</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/loss-smoothsharpen/><span class=title>« Prev</span><br><span>Loss-Smooth(Sharpen)</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/pytorch/><span class=title>Next »</span><br><span>PyTorch Handbook 00 （Archive）</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>