<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Image Caption Dataset | aiken's blog</title>
<meta name=keywords content="Dataset,Image Caption"><meta name=description content="Goals：
1.数据量要求
2.标注的标准
3.标注的手段
Microsoft COCO Captions:
使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。
“Each of our captions are also generated using human subjects on AMT.”
一些其他信息：(Caption Evaluation Server):
好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。
文中（section 3）包含了几种不同评价方法的介绍：

BLEU
ROUGE
METEOR
CIDEr

在进行Evaluation之前的 Tokenization and preprocessing中：
使用了工具来添加caption标记：

Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1)

这个工具是模仿的是peen treebank3.   其参考文献和相关链接如下：

“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link
"><meta name=author content="aikenhong"><link rel=canonical href=https://hugotest-phi.vercel.app/posts/imagecaptionrequirement/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://hugotest-phi.vercel.app/favicon/ghost.ico><link rel=icon type=image/png sizes=16x16 href=https://hugotest-phi.vercel.app/favicon/ghost-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hugotest-phi.vercel.app/favicon/ghost-32x32.png><link rel=apple-touch-icon href=https://hugotest-phi.vercel.app/favicon/ghost-apple-touch-icon.png><link rel=mask-icon href=https://hugotest-phi.vercel.app/favicon/ghost-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hugotest-phi.vercel.app/posts/imagecaptionrequirement/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdmirror.com/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdmirror.com/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.css><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/katex.min.js></script><script defer src=https://cdn.jsdmirror.com/npm/katex@0.16.11/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-tc-webfont@1.0.0/style.css><link rel=stylesheet href=https://cdn.jsdmirror.com/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><meta property="og:url" content="https://hugotest-phi.vercel.app/posts/imagecaptionrequirement/"><meta property="og:site_name" content="aiken's blog"><meta property="og:title" content="Image Caption Dataset"><meta property="og:description" content="Goals： 1.数据量要求
2.标注的标准
3.标注的手段
Microsoft COCO Captions: 使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。
“Each of our captions are also generated using human subjects on AMT.”
一些其他信息：(Caption Evaluation Server): 好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。
文中（section 3）包含了几种不同评价方法的介绍：
BLEU
ROUGE
METEOR
CIDEr
在进行Evaluation之前的 Tokenization and preprocessing中：
使用了工具来添加caption标记：
Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1) 这个工具是模仿的是peen treebank3. 其参考文献和相关链接如下：
“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link "><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-01-14T02:13:25+00:00"><meta property="article:modified_time" content="2020-01-14T02:13:25+00:00"><meta property="article:tag" content="Dataset"><meta property="article:tag" content="Image Caption"><meta property="og:image" content="https://hugotest-phi.vercel.app/cover/cover6.jpeg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugotest-phi.vercel.app/cover/cover6.jpeg"><meta name=twitter:title content="Image Caption Dataset"><meta name=twitter:description content="Goals：
1.数据量要求
2.标注的标准
3.标注的手段
Microsoft COCO Captions:
使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。
“Each of our captions are also generated using human subjects on AMT.”
一些其他信息：(Caption Evaluation Server):
好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。
文中（section 3）包含了几种不同评价方法的介绍：

BLEU
ROUGE
METEOR
CIDEr

在进行Evaluation之前的 Tokenization and preprocessing中：
使用了工具来添加caption标记：

Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1)

这个工具是模仿的是peen treebank3.   其参考文献和相关链接如下：

“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link
"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hugotest-phi.vercel.app/posts/"},{"@type":"ListItem","position":2,"name":"Image Caption Dataset","item":"https://hugotest-phi.vercel.app/posts/imagecaptionrequirement/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Image Caption Dataset","name":"Image Caption Dataset","description":"Goals： 1.数据量要求\n2.标注的标准\n3.标注的手段\nMicrosoft COCO Captions: 使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。\n“Each of our captions are also generated using human subjects on AMT.”\n一些其他信息：(Caption Evaluation Server): 好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。\n文中（section 3）包含了几种不同评价方法的介绍：\nBLEU\nROUGE\nMETEOR\nCIDEr\n在进行Evaluation之前的 Tokenization and preprocessing中：\n使用了工具来添加caption标记：\nStanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1) 这个工具是模仿的是peen treebank3. 其参考文献和相关链接如下：\n“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link ","keywords":["Dataset","Image Caption"],"articleBody":"Goals： 1.数据量要求\n2.标注的标准\n3.标注的手段\nMicrosoft COCO Captions: 使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。\n“Each of our captions are also generated using human subjects on AMT.”\n一些其他信息：(Caption Evaluation Server): 好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。\n文中（section 3）包含了几种不同评价方法的介绍：\nBLEU\nROUGE\nMETEOR\nCIDEr\n在进行Evaluation之前的 Tokenization and preprocessing中：\n使用了工具来添加caption标记：\nStanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1) 这个工具是模仿的是peen treebank3. 其参考文献和相关链接如下：\n“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link 数据规模： （平均1-5）\n330k image - \u003e1.5m captions;\n训练\u0026验证image : 每张照片的caption 由5个独立的人分别给出;\n对于Testing Image，收集额外的标题用来比较 人类标题的和机器生成的标题的表现。\n(MS COCO c5): 5 referenc captions for every image on MS COCO traning/ validation/ testing dataset.\nT: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-179,189)\n(MS COCO c40): 40 reference sentences for a randomly chosen 5,000 images from the MS COCO testing dataset.\n给出更多对应的句子，许多评估指标可能与人类判断，有更高的相关性。\nT: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-200,060)\n数据集搭建： none\n标注格式： #范例\nDescribtion\n原则：尽量短，只包含准确且重要的现况，不包含任何推理的部分。\nDescribe all the important parts of the scene. Do not start the sentences with “There is. Do not describe unimportant details. Do not describe things that might have happened in the future or past. Do not describe what a person might say. Do not give people proper names. The sentences should contain at least 8 words. (NOT Caption)Microsoft COCO dataset: 一些其他信息： “the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation”\n“认为以往的数据集对于background信息过于忽视，除了主要的object 作为background的object很难识别”\n应该是设计了一个便于标注的用户界面\n标注格式： (Image-对应Question)为一组，按照实例分割对对象进行标记\n对每个对象main.backgroud都留存实例级别的分割掩膜(比bounding box精确的完全分割)\n1.标注存在的类别：\n采用分层方法，先判断大类，这样逐层往下分，比较快\n结果如图a\n2.Instance Spotting：\n第一步的时候，在找到的类别上画个x，这一轮，就找更多的类别，在新类上画新x 结果图图b\n3.分割实例\n修改了Bell等人的软件？用来标注\nOpenSurfaces: A richly annotated catalog of surface appearance. SIGGRAPH 32(4) (2013)\n数据规模： 91 objects， 328k image， 250w instances\n类别少,实例多。避免long tail\nCOCO: 1 image - 7.7 object instance\nimagenet: 3\nSUN: 2.3\n数据集搭建： （COCO）基于Amazon Mechanical Turk收集数据，基于Image2text、SUNdatabase来查询图像对，从而收集。\n分层标记方法：将每个图像标记为特定的对象类别。\n选择类别：只要那些thing（人，椅子，汽车），不要专注于stuff（天空街道草地）（没有精确的边界的）\nnon-iconic \u0026 iconic图像： （举个例子，比如证件照和乱拍的生活照？）是否是中心大对象之类的。 都有，但是大部分用non-\n","wordCount":"281","inLanguage":"en","image":"https://hugotest-phi.vercel.app/cover/cover6.jpeg","datePublished":"2020-01-14T02:13:25Z","dateModified":"2020-01-14T02:13:25Z","author":[{"@type":"Person","name":"aikenhong"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hugotest-phi.vercel.app/posts/imagecaptionrequirement/"},"publisher":{"@type":"Organization","name":"aiken's blog","logo":{"@type":"ImageObject","url":"https://hugotest-phi.vercel.app/favicon/ghost.ico"}}}</script></head><body id=top><script type=module src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.esm.js defer></script><script nomodule src=https://cdn.jsdmirror.com/npm/ionicons@7.1.0/dist/ionicons/ionicons.js defer></script><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hugotest-phi.vercel.app/ accesskey=h title="aiken's blog (Alt + H)">aiken's blog</a><div class=logo-switches><button id=theme-toggle-nav accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugotest-phi.vercel.app/ title=home><span>home</span></a></li><li><a href=https://hugotest-phi.vercel.app/archives/ title=archives><span>archives</span></a></li><li><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><div class=sidebar><ul><li class=logo style=--bg:#333><a href=#><div class=logo-icon><img src=/logo/logo.png></div><div class=logo-text>Aiken's Blog</div></a></li><div class=menulist><li style=--bg:#f44336><a href=https://hugotest-phi.vercel.app/ title=home><div class=logo-icon><ion-icon name=home-outline></ion-icon></div><div class=logo-text>home</div></a></li><li style=--bg:#b145e9><a href=https://hugotest-phi.vercel.app/posts/ title=posts><div class=logo-icon><ion-icon name=newspaper-outline></ion-icon></div><div class=logo-text>posts</div></a></li><li style=--bg:#0f93c7><a href=https://hugotest-phi.vercel.app/tags/ title=tags><div class=logo-icon><ion-icon name=pricetags-outline></ion-icon></div><div class=logo-text>tags</div></a></li><li style=--bg:#ffa117><a href=https://hugotest-phi.vercel.app/categories/ title=categories><div class=logo-icon><ion-icon name=grid-outline></ion-icon></div><div class=logo-text>categories</div></a></li><li style=--bg:#0fc70f><a href=https://hugotest-phi.vercel.app/archives/ title=archives><div class=logo-icon><ion-icon name=folder-outline></ion-icon></div><div class=logo-text>archives</div></a></li><li style=--bg:#d16111><a href=https://hugotest-phi.vercel.app/about/ title=about><div class=logo-icon><ion-icon name=person></ion-icon></div><div class=logo-text>about</div></a></li><li style=--bg:#15c095><a href=https://hugotest-phi.vercel.app/search title="search (Alt + /)" accesskey=/><div class=logo-icon><ion-icon name=search></ion-icon></div><div class=logo-text>search</div></a></li></div><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt +T)"><li><div class=logo-icon id=moon><ion-icon name=moon-outline></ion-icon></div><div class=logo-icon id=sun><ion-icon name=sunny-outline></ion-icon></div></li></button></div></ul></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hugotest-phi.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=https://hugotest-phi.vercel.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Image Caption Dataset</h1><div class=post-meta><span title='2020-01-14 02:13:25 +0000 UTC'>January 14, 2020</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;281 words&nbsp;·&nbsp;aikenhong&nbsp;·&nbsp;<a href=/tags/dataset> Dataset</a>&nbsp;·&nbsp;<a href=/tags/image-caption> Image Caption</a>&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/ImageCaptionRequirement.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><figure class=entry-cover><img loading=eager src=https://hugotest-phi.vercel.app/cover/cover6.jpeg alt></figure><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#goals aria-label=Goals：>Goals：</a></li><li><a href=#microsoft-coco-captions aria-label="Microsoft COCO Captions:">Microsoft COCO Captions:</a><ul class=header-level-2><li><a href=#%e4%b8%80%e4%ba%9b%e5%85%b6%e4%bb%96%e4%bf%a1%e6%81%afcaption-evaluation-server aria-label="一些其他信息：(Caption Evaluation Server):">一些其他信息：(Caption Evaluation Server):</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e8%a7%84%e6%a8%a1 aria-label=数据规模：>数据规模：</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e9%9b%86%e6%90%ad%e5%bb%ba aria-label=数据集搭建：>数据集搭建：</a></li><li><a href=#%e6%a0%87%e6%b3%a8%e6%a0%bc%e5%bc%8f aria-label=标注格式：>标注格式：</a></li></ul></li><li><a href=#not-captionmicrosoft-coco-dataset aria-label="(NOT Caption)Microsoft COCO dataset:">(NOT Caption)Microsoft COCO dataset:</a><ul class=header-level-2><li><a href=#%e4%b8%80%e4%ba%9b%e5%85%b6%e4%bb%96%e4%bf%a1%e6%81%af aria-label=一些其他信息：>一些其他信息：</a></li><li><a href=#%e6%a0%87%e6%b3%a8%e6%a0%bc%e5%bc%8f-1 aria-label=标注格式：>标注格式：</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e8%a7%84%e6%a8%a1-1 aria-label=数据规模：>数据规模：</a></li><li><a href=#%e6%95%b0%e6%8d%ae%e9%9b%86%e6%90%ad%e5%bb%ba-1 aria-label=数据集搭建：>数据集搭建：</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;document.addEventListener("DOMContentLoaded",function(){if(checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),elements.length>0){activeElement=elements[0];const e=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${e}"]`).classList.add("active")}const t=document.getElementById("top-link");t&&t.addEventListener("click",e=>{e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})})},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{const e=window.pageYOffset||document.documentElement.scrollTop;if(e===0)return;elements&&elements.length>0&&(elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase(),n=document.querySelector(`.inner ul li a[href="#${t}"]`);n.classList.remove("read")}),activeElement=Array.from(elements).find(t=>{if(getOffsetTop(t)-e>0&&getOffsetTop(t)-e<window.innerHeight/2)return t})||activeElement,elements.forEach((t)=>{const o=encodeURI(t.getAttribute("id")).toLowerCase(),s=document.querySelector(`.inner ul li a[href="#${o}"]`);if(t===activeElement){s.classList.add("active");const e=document.querySelector(".toc .inner"),t=s.offsetTop,n=e.clientHeight,o=s.clientHeight,i=t-n/2+o/2;e.scrollTo({top:i,behavior:"smooth"})}else getOffsetTop(t)<e&&s.classList.add("read"),s.classList.remove("active")}))},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return!document.querySelector(".hugo-encryptor-prompt")&&elements.length!=0&&(elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),console.log("Elements re-queried:",elements)),0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=goals>Goals：<a hidden class=anchor aria-hidden=true href=#goals>#</a></h2><p>1.数据量要求<br>2.标注的标准<br>3.标注的手段</p><h2 id=microsoft-coco-captions>Microsoft COCO Captions:<a hidden class=anchor aria-hidden=true href=#microsoft-coco-captions>#</a></h2><p>使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。<br>“Each of our captions are also generated using human subjects on AMT.”</p><h3 id=一些其他信息caption-evaluation-server>一些其他信息：(Caption Evaluation Server):<a hidden class=anchor aria-hidden=true href=#一些其他信息caption-evaluation-server>#</a></h3><p>好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。<br>文中（section 3）包含了几种不同评价方法的介绍：</p><blockquote><p>BLEU<br>ROUGE<br>METEOR<br>CIDEr</p></blockquote><p>在进行Evaluation之前的 Tokenization and preprocessing中：<br>使用了工具来添加caption标记：</p><ul><li>Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1)</li></ul><p>这个工具是模仿的是peen treebank3. 其参考文献和相关链接如下：</p><blockquote><p>“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. <a href=http://www.aclweb.org/anthology/P/P14/P14-5010 target=_blank rel=noopener>related-link</a></p></blockquote><h3 id=数据规模>数据规模：<a hidden class=anchor aria-hidden=true href=#数据规模>#</a></h3><p><strong>（平均1-5）</strong><br>330k image - >1.5m captions;<br>训练&验证image : 每张照片的caption 由5个独立的人分别给出;<br>对于Testing Image，收集额外的标题用来比较 人类标题的和机器生成的标题的表现。</p><blockquote><p>(MS COCO c5): 5 referenc captions for every image on MS COCO traning/ validation/ testing dataset.<br>T: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-179,189)</p></blockquote><blockquote><p>(MS COCO c40): 40 reference sentences for a randomly chosen 5,000 images from the MS COCO testing dataset.<br>给出更多对应的句子，许多评估指标可能与人类判断，有更高的相关性。<br>T: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-200,060)</p></blockquote><h3 id=数据集搭建>数据集搭建：<a hidden class=anchor aria-hidden=true href=#数据集搭建>#</a></h3><p>none</p><h3 id=标注格式>标注格式：<a hidden class=anchor aria-hidden=true href=#标注格式>#</a></h3><p><code>#范例</code></p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211210.jpg><img alt=3 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211210.jpg class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211210.jpg style="display:block;margin:0 auto" alt=3></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script><strong>Describtion</strong><br>原则：尽量短，只包含准确且重要的现况，不包含任何推理的部分。</p><blockquote><ol><li>Describe all the important parts of the scene.</li><li>Do not start the sentences with “There is.</li><li>Do not describe unimportant details.</li><li>Do not describe things that might have happened in the future or past.</li><li>Do not describe what a person might say.</li><li>Do not give people proper names.</li><li>The sentences should contain at least 8 words.</li></ol></blockquote><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211229.jpg><img alt=figure2 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211229.jpg class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211229.jpg style="display:block;margin:0 auto" alt=figure2></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script></p><h2 id=not-captionmicrosoft-coco-dataset>(NOT Caption)Microsoft COCO dataset:<a hidden class=anchor aria-hidden=true href=#not-captionmicrosoft-coco-dataset>#</a></h2><h3 id=一些其他信息>一些其他信息：<a hidden class=anchor aria-hidden=true href=#一些其他信息>#</a></h3><p>“the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation”</p><p>“认为以往的数据集对于background信息过于忽视，除了主要的object 作为background的object很难识别”</p><p>应该是设计了一个便于标注的用户界面</p><h3 id=标注格式-1>标注格式：<a hidden class=anchor aria-hidden=true href=#标注格式-1>#</a></h3><p>(Image-对应Question)为一组，按照实例分割对<strong>对象</strong>进行标记<br>对每个对象main.backgroud都留存实例级别的分割掩膜(比bounding box精确的完全分割)</p><p><div class=post-img-view><a data-fancybox=gallery href=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211319.jpg><img alt=figure1 loading=lazy src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211319.jpg class=responsive-image src=https://picture-bed-001-1310572365.cos.ap-guangzhou.myqcloud.com/imgs/img/20210911211319.jpg style="display:block;margin:0 auto" alt=figure1></a></div><script>document.addEventListener("DOMContentLoaded",function(){var e=document.querySelectorAll(".responsive-image"),t=window.innerHeight/2.5;e.forEach(function(e){e.style.maxHeight=t+"px"})})</script><br>1.标注存在的类别：</p><blockquote><p>采用分层方法，先判断大类，这样逐层往下分，比较快<br>结果如图a</p></blockquote><p>2.Instance Spotting：</p><blockquote><p>第一步的时候，在找到的类别上画个x，这一轮，就找更多的类别，在新类上画新x
结果图图b</p></blockquote><p>3.分割实例</p><blockquote><p>修改了Bell等人的软件？用来标注<br>OpenSurfaces: A richly annotated catalog of surface appearance. SIGGRAPH 32(4) (2013)</p></blockquote><h3 id=数据规模-1>数据规模：<a hidden class=anchor aria-hidden=true href=#数据规模-1>#</a></h3><p>91 objects， 328k image， 250w instances<br>类别少,实例多。避免long tail</p><blockquote><p>COCO: 1 image - 7.7 object instance<br>imagenet: 3<br>SUN: 2.3</p></blockquote><h3 id=数据集搭建-1>数据集搭建：<a hidden class=anchor aria-hidden=true href=#数据集搭建-1>#</a></h3><p>（COCO）基于Amazon Mechanical Turk收集数据，基于Image2text、SUNdatabase来查询图像对，从而收集。<br><strong>分层标记方法</strong>：将每个图像标记为特定的对象类别。</p><p>选择类别：只要那些thing（人，椅子，汽车），不要专注于stuff（天空街道草地）（没有精确的边界的）</p><p>non-iconic & iconic图像：
（举个例子，比如证件照和乱拍的生活照？）是否是中心大对象之类的。
都有，但是大部分用non-</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hugotest-phi.vercel.app/tags/dataset/>Dataset</a></li><li><a href=https://hugotest-phi.vercel.app/tags/image-caption/>Image Caption</a></li></ul><nav class=paginav><a class=prev href=https://hugotest-phi.vercel.app/posts/hyper_resolution/><span class=title>« Prev</span><br><span>Hyper-Resolution</span>
</a><a class=next href=https://hugotest-phi.vercel.app/posts/emotion_dataset/><span class=title>Next »</span><br><span>表情数据集</span></a></nav></footer><div id=disqus_thread></div><script>function loadDisqus(){var e=document,t=e.createElement("script");t.src="https://aiken-hugo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t),window.disqus_config=function(){this.page.url=window.location.href,this.page.identifier=window.location.href.substring(18)}}var runningOnBrowser=typeof window!="undefined",isBot=runningOnBrowser&&!("onscroll"in window)||typeof navigator!="undefined"&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver(function(t){t[0].isIntersecting&&(loadDisqus(),e.disconnect())},{threshold:[0]});e.observe(document.getElementById("disqus_thread"))}else loadDisqus()},1)</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2024 <a href=https://hugotest-phi.vercel.app/>aiken's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a>
</span><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span id=busuanzi_container>Visitors: <span id=busuanzi_value_site_uv></span>
Views: <span id=busuanzi_value_site_pv></span></span></footer><script>document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("busuanzi_value_site_uv"),t=document.getElementById("busuanzi_value_site_pv"),o=13863,i=16993;if(!e||!t){console.error("Busuanzi elements not found.");return}const n=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){n.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+o;break}}),s=new MutationObserver(e=>{for(let t of e)if(t.type==="childList"){s.disconnect(),t.target.innerHTML=parseInt(t.target.innerHTML||0)+i;break}});n.observe(e,{childList:!0}),s.observe(t,{childList:!0})})</script><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))}),document.getElementById("theme-toggle-nav").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.js",function(){pangu.spacingPage()})</script></body></html>